{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCGKeZ2gyuoQ"
      },
      "source": [
        "_Importing Required Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-6LN-zXiLcM",
        "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
            "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
            "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
            "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install hampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "By_d9uXpaFvZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from hampel import hampel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyOjBMFayuoR"
      },
      "source": [
        "## Pretraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5QqIY_GyuoR"
      },
      "source": [
        "The `horton_intermittency.dat` feeds the model with the dynamics of the Horton Chaotics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9dV4a8yfyuoR"
      },
      "outputs": [],
      "source": [
        "data = np.genfromtxt('horton_intermittency.dat')\n",
        "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
        "training_set = training_set.iloc[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7easoxByuoR"
      },
      "source": [
        "## Computing the Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SnyolJTyuoR"
      },
      "source": [
        "_Calculating the value of_ $\\frac{dx}{dt}$, $\\frac{d^2x}{dt^2}$, _and_ $\\frac{d^3x}{dt^3}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmIbVfIvyuoR",
        "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "1       -0.000011\n",
            "2        0.003571\n",
            "3        0.005754\n",
            "4        0.006818\n",
            "5       -0.000807\n",
            "           ...   \n",
            "9996    -0.129763\n",
            "9997    -0.118735\n",
            "9998    -0.105414\n",
            "9999    -0.090338\n",
            "10000   -0.074048\n",
            "Name: 1, Length: 10000, dtype: float64\n",
            "2        0.003582\n",
            "3        0.002183\n",
            "4        0.001064\n",
            "5       -0.007625\n",
            "6       -0.006999\n",
            "           ...   \n",
            "9996     0.008219\n",
            "9997     0.011028\n",
            "9998     0.013321\n",
            "9999     0.015076\n",
            "10000    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n",
            "2        0.003582\n",
            "3        0.002183\n",
            "4        0.001064\n",
            "5       -0.007625\n",
            "6       -0.006999\n",
            "           ...   \n",
            "9996     0.008219\n",
            "9997     0.011028\n",
            "9998     0.013321\n",
            "9999     0.015076\n",
            "10000    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "t_diff = 1\n",
        "print(training_set.max())\n",
        "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
        "print(gradient_t)\n",
        "gradient_tt = (gradient_t.diff()/t_diff).iloc[1:] # d2x/dt2\n",
        "print(gradient_tt)\n",
        "gradient_ttt = (gradient_tt.diff()/t_diff).iloc[1:] # d3x/dt3\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2eVeeoxyuoS"
      },
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0J-NKyIEyuoS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       0.116134\n",
              "1       0.159976\n",
              "2       0.145809\n",
              "3       0.145829\n",
              "4       0.118201\n",
              "          ...   \n",
              "2010    0.144958\n",
              "2011    0.173800\n",
              "2012    0.101393\n",
              "2013    0.159424\n",
              "2014    0.174057\n",
              "Name: flux, Length: 2015, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"differential-electrons-7-day.csv\")\n",
        "training_set = data.iloc[:, 1]\n",
        "training_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CbNUhJ74UqF",
        "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       0.116134\n",
              "1       0.159976\n",
              "2       0.145809\n",
              "3       0.145829\n",
              "4       0.118201\n",
              "          ...   \n",
              "1999    0.247162\n",
              "2000    0.174463\n",
              "2001    0.290773\n",
              "2002    0.261675\n",
              "2003    0.188936\n",
              "Name: flux, Length: 2004, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = training_set.tail(10)\n",
        "test\n",
        "training_set = training_set.head(2004) # (2013 - 10) + 1\n",
        "training_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0TwTcq0yuoS",
        "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      -0.000011\n",
            "1       0.003571\n",
            "2       0.005754\n",
            "3       0.006818\n",
            "4      -0.000807\n",
            "          ...   \n",
            "9995   -0.129763\n",
            "9996   -0.118735\n",
            "9997   -0.105414\n",
            "9998   -0.090338\n",
            "9999   -0.074048\n",
            "Name: 1, Length: 10000, dtype: float64\n",
            "0       0.003582\n",
            "1       0.002183\n",
            "2       0.001064\n",
            "3      -0.007625\n",
            "4      -0.006999\n",
            "          ...   \n",
            "9994    0.008219\n",
            "9995    0.011028\n",
            "9996    0.013321\n",
            "9997    0.015076\n",
            "9998    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n",
            "0      -0.001400\n",
            "1      -0.001118\n",
            "2      -0.008690\n",
            "3       0.000626\n",
            "4       0.000763\n",
            "          ...   \n",
            "9993    0.003290\n",
            "9994    0.002810\n",
            "9995    0.002293\n",
            "9996    0.001755\n",
            "9997    0.001214\n",
            "Name: 1, Length: 9998, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "training_set = training_set.reset_index(drop=True) # sets a list of integer ranging from 0 to length of training_set as index\n",
        "gradient_t = gradient_t.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_t as index\n",
        "gradient_tt = gradient_tt.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_tt as index\n",
        "gradient_ttt = gradient_ttt.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_ttt as index\n",
        "print(gradient_t)\n",
        "print(gradient_tt)\n",
        "print(gradient_ttt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O2biznZQyuoS"
      },
      "outputs": [],
      "source": [
        "df = pd.concat((training_set, gradient_t), axis=1) ##########[:-1]\n",
        "gradient_tt.columns = [\"grad_tt\"]\n",
        "df = pd.concat((df, gradient_tt), axis=1) ################[:-1]\n",
        "gradient_tt.columns = [\"grad_ttt\"]\n",
        "df = pd.concat((df, gradient_ttt), axis=1) ################[:-1]\n",
        "df.columns = ['y_t', 'grad_t', 'grad_tt', 'grad_ttt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sk_a5v3tyuoS",
        "outputId": "17563625-e550-45ae-faab-fafa353e44da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_t</th>\n",
              "      <th>grad_t</th>\n",
              "      <th>grad_tt</th>\n",
              "      <th>grad_ttt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.116134</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>0.003582</td>\n",
              "      <td>-0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.159976</td>\n",
              "      <td>0.003571</td>\n",
              "      <td>0.002183</td>\n",
              "      <td>-0.001118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.145809</td>\n",
              "      <td>0.005754</td>\n",
              "      <td>0.001064</td>\n",
              "      <td>-0.008690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.145829</td>\n",
              "      <td>0.006818</td>\n",
              "      <td>-0.007625</td>\n",
              "      <td>0.000626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.118201</td>\n",
              "      <td>-0.000807</td>\n",
              "      <td>-0.006999</td>\n",
              "      <td>0.000763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.129763</td>\n",
              "      <td>0.011028</td>\n",
              "      <td>0.002293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.118735</td>\n",
              "      <td>0.013321</td>\n",
              "      <td>0.001755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.105414</td>\n",
              "      <td>0.015076</td>\n",
              "      <td>0.001214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.090338</td>\n",
              "      <td>0.016290</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.074048</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           y_t    grad_t   grad_tt  grad_ttt\n",
              "0     0.116134 -0.000011  0.003582 -0.001400\n",
              "1     0.159976  0.003571  0.002183 -0.001118\n",
              "2     0.145809  0.005754  0.001064 -0.008690\n",
              "3     0.145829  0.006818 -0.007625  0.000626\n",
              "4     0.118201 -0.000807 -0.006999  0.000763\n",
              "...        ...       ...       ...       ...\n",
              "9995       NaN -0.129763  0.011028  0.002293\n",
              "9996       NaN -0.118735  0.013321  0.001755\n",
              "9997       NaN -0.105414  0.015076  0.001214\n",
              "9998       NaN -0.090338  0.016290       NaN\n",
              "9999       NaN -0.074048       NaN       NaN\n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df # DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5esyHu5aFvg"
      },
      "source": [
        "## Plot of the External Forcing from Chaotic Differential Equation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "hGnE43tOh-4p",
        "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAz6UlEQVR4nO2dd5wU9fnHP9/dvX4cd8cdSDk4UCwICIIUBUURBdHYWxI1JgY11vyiCbbEXmNMMxqjxo7GjoKAIoIi7Y7eOTrXObhetn1/f+zM7MzszO7O1pnb5/168WL2O7Ozz83ufvaZ5/t8n4dxzkEQBEFYD1uyDSAIgiAigwScIAjCopCAEwRBWBQScIIgCItCAk4QBGFRHIl8saKiIl5aWprIlyQIgrA85eXlhznnxerxhAp4aWkpysrKEvmSBEEQlocxtl9rnEIoBEEQFoUEnCAIwqKQgBMEQVgUEnCCIAiLQgJOEARhUUjACYIgLAoJOEEQhEUhAScIk9PudOPTdYeSbQZhQhK6kIcgCOM8MncrPig7iAEF2TittDDZ5hAmgjxwgjA5tS2dAIDWTneSLSHMBgk4QZgcG2MAAI+XumcRSkjACcLkSAJO7Q8JFSTgBGFy7MK31EseOKGCBJwgTI7d5vPASb8JNSTgBGFyGIVQCB1IwAnC5NgFAacQCqGGBJwgTI4/hEICTighAScIkyM44JRGSARAAk4QJkcKoZAHTqggAScIk0NZKIQeJOAEYXIYrcQkdCABJwiTIy3koRAKoSKkgDPGShhjSxhjWxljWxhjdwnjhYyxrxlju4T/C+JvLkGkHpRGSOgRjgfuBvA7zvkwABMA3MYYGwZgNoDFnPOhABYLjwmCiDH+hTxJNoQwHSEFnHNezTlfK2y3ANgGoD+AiwG8KRz2JoBL4mQjQaQ04iSm2+NNsiWE2TAUA2eMlQIYDWAVgD6c82phVw2APjrPmcUYK2OMldXX10djK0GkJJKAUwiFUBG2gDPGcgF8DOBuznmzfB/nnAPQ/HRxzl/hnI/lnI8tLi6OyliCSEXEhTwu8sAJFWEJOGMsDT7xfpdz/okwXMsY6yvs7wugLj4mEgQBAG4KghMqwslCYQBeA7CNc/4X2a65AG4Qtm8A8HnszSMIQswedHnJAyeUhNPU+AwA1wHYxBhbL4zdD+BpAP9jjP0KwH4AV8XFQoJIccQFPOSBE2pCCjjn/AcATGf31NiaQxCEGnEBD2WhEGpoJSZBmBx/CIU8cEIJCThBmBx/CIU8cEIJCThBmBx/CIU8cEIJCThBmBwvhVAIHUjACcIk7K5vxdjHv0F1U4di3EshFEIHEnCCMAnvrNyPw61dmLexWjEuhlBcFEIhVJCAE4RJSBcKfx9udSrGxciJmxbyECpIwAnCJNiEolUvL90tjXm9HIu21ACgSUwiEBJwgjAJHU5PwNhlL/2Ili43ACpmRQRCAk4QJqGkMFva5kLce/3BRmmMyskSakjACcIkFOakSdt/X1yBpg6XYj9loRBqwilmRRBEApDr8wvf7MSrP+xR7KcsFEINeeAEYRLUTYtbOt2Kx5SFQqghAScIk+DhwT1sykIh1JCAE4RJ8ISYpKSGDoQaEnCCMAle8sAJg5CAE4RJCOWBt2vkiROpDQk4QZiEUALe3OkKmOgkUhsScIIwCcFCKOMHF4JzoM3p1j2GSD1IwAnCJOit0/nstjMwffgxACgOTighAScIk+DRyTJx2BgcQqVCykQh5JCAE4RJ0PPAHXaGNKFSIXnghBwScIIwCXoLedLsNskDJwEn5JCAE4RJaGjt0hzPTrcjze7zwCmEQsghAScIE7DhYCPeXXVAc192mgMOG3ngRCAk4ARhArbXNOvuy0izwSF64FRSlpBB5WQJwgSIHrbIoF7ZeOdX47FiTwMy0+xwCJOYoRb7EKkFCThBmADRwxaZfvIxKCnMlrr0iP0yQ9VLIVILEnCCMAFyD3ztQ9PQMytNsd/GRAFPqFmEySEBJwgTkOHwC3hhTnrAfsEBJw+cUECTmARhAsQQyvjBhZr77aIHTi44IYMEnCBMgOhZ33/BSZr7GYVQCA1IwAnCBPzyjTIAgN3GNPdTCIXQggScIEyEOFmpxk5ZKIQGJOAEkWR217dK2+p0QhExhPLt9rqE2ERYAxJwgkgyLy6pkLb1PHCR/y7fF2drCCsRUsAZY68zxuoYY5tlYw8zxioZY+uFfxfE10yC6J64PF58srZSeuzQiYFzCp0QGoTjgb8BYLrG+Auc81HCv/mxNYsgUgOnW1nbJN2h/ZWkJfSEFiEFnHO+DMCRBNhCECmHurpgml37K0n6TWgRTQz8dsbYRiHEUqB3EGNsFmOsjDFWVl9fH8XLEUT3Y2Nlo+Jxuq6Ak4ITgUQq4C8BOBbAKADVAJ7XO5Bz/grnfCznfGxxcXGEL0cQ3ZPrXluteKwXQiEBJ7SISMA557Wccw/n3AvgPwDGxdYsgkhN0nTSCCkGTmgRkYAzxvrKHl4KYLPesQRBhI/eSsz87MACVwQRshohY2wOgCkAihhjhwD8CcAUxtgoABzAPgA3x89EgkgNTuqbJy3YUTOqJB8AcOWYAQm0iDA7IQWcc36txvBrcbCFIFKa564YGXR/7x4Zuis1idSEVmISRBK5fuIgabukIDvosTbGKBZOKKCGDgSRRLLS7Mhw2LDt0elS2zQ97DYG6mlMyCEPnCCSiJdz2G0spHgDQFOHC9VNHQmwirAKJOAEkUQ83tAFrERau9z4cXdDnC0irAQJOEEkES/nCMP5JghNSMAJIol4OQ8rfCKHKhMSIiTgBJFEvJxLDYvDZUtVc5ysIawGCThBJBEvh+7iHT06XZ44WUNYDRJwgkgiXq/xGDilghMiJOAEkUTENEIjUAycEKGFPASRRD5eW2l4dSV54IQIeeAEkUQiWRpPHjghQh44QSSRIUU5KMrNMPQcDwk4IUAeOEEkEbuNoVeusVrfboqhEAIk4ASRRNxeDodOH0w9XG6qaEX4IAEniCTi8niRFmYWyt+vHQ0AmPV2OaoaqagVQQJOEEnF7eFhN2kY0b+ntL1675F4mURYCBJwgkgibq837BCKXsNjInUhASeIJOJ0hx9CSTMYKye6P/SJIIgkYmQS0yETeoPlU4huCgk4QSQRIzFwo0vuie4PCThBJBGX14s0W3hfQ6NVC4nuDwk4QSQJj5eDc5AHTkQMCThBJAmX0GI+3MlJ0m9CDQk4QSQJcUm8I0xlDrf5MZE6kIATRJJwCx54uFkocgF3e6geCkHVCAki4by7aj96ZKZhdEk+ACA9ghi420v1UAgScIJIOA98uhkAcObxxQCAysbOsJ4nj7S4yAMnQCEUgkgay3bWAwAG9coO63imCKGQB06QgBNE3Fi990hYRadmDD/G8Ln1aoJ3uT149fs9UoYL0b2hEApBxImr/r0CAHDGcb3wl6tGoU9epuZxRuuBA/oC/taP+/HE/G2wMYZfThps+LyEtSAPnCDizPKKBox/cjG+3Fil2c8y3DRCOc0dLs1xUdhrm8OLqxPWhjxwgkgQX26oRqcrMLQRSZVBrYYOlY0deGbBdgBAS5fbuIGE5SAPnCASxPqDjbjnww0B45GssNRKQlmxu0HaDjbJubziMEpnz8Pu+lbjL0yYChJwgkgQNTphjUiKVHk08sC9srh4sMbHn62rBACU7aOuPlaHBJwgLMS7N41HXqZDcyWmVxZf9wQRcI9wnD3MKoiEeQn5DjLGXmeM1THGNsvGChljXzPGdgn/F8TXTIKwFrPeKgvruOIeGYbOe8ZxRRjUK0dToOVDwTxw0VOnBj/WJ5y38A0A01VjswEs5pwPBbBYeEwQhMCirbVhHffuTeMNn9tmY5oCrfDAg6zUFHdRcSzrE1LAOefLAKiDZRcDeFPYfhPAJbE1iyCsy8Ej7WEfmx6BG+ywMR0PPLwYuN8DJwG3OpHeRPXhnFcL2zUA+ugdyBibxRgrY4yV1dfXR/hyhNk4eKQdCzbXJNsM07H+YCMmP7tEMRYsTBKJF2y3Mc1iVvJJTK1JThHxuXbywC1P1FEw7luZoPtzzzl/hXM+lnM+tri4ONqXI0yAx8sx+dkluOWd8mSbYjoq6pSpeTefNQRv3jhO9/hI5hH1PXD/djAPXMwwtJEHbnkiFfBaxlhfABD+r4udSYTZ+dNcaT5b4fURyjAGALjcHMP65eEvV52iGBe98sg98MizUMTjyAO3PpEK+FwANwjbNwD4PDbmEFbgnZUHpG2nBYomHWhoR+nsedhe0xz311IvlReLSv3klH6ax0ci4NHGwEUbSb+tTzhphHMArABwAmPsEGPsVwCeBjCNMbYLwLnCYyIFKJ09T/G4y21+AV+01Rer/9+aQ2ho7ZLKuMYD9e9ZXpavWoVewapIRNRus4UMoQTzwInuQ8haKJzza3V2TY2xLYQF6XJ7AKQl2wxN2rrcqGrskLIt3F4vfvbqKmyvaUHFEzMiqgIYCo/KA7/t7OOCHh+JExyWBx7GnRF54NaHUvmJsNGqpPff5fsSb0iY3PRmGaa9sEwS6jmrD2B7TQuA4CGGaFBfo+x0v4/05R2TZMdF/hrqGHi7040tVU2KczrD6NgTjQ2EOSABJ8LmxjfWBIy99N3uJFgSHiv2NCgey9uQxSt2L/eMn7l8hGJfSaFG552IQihKD/zu99dj5t9/UJSYpY49qQEJOBEWbV1ufLfDmnn8CzXy1V1xit3LHfurTxuo2Kes+x25++tQ5YGX7T8KAGh3eqSxcDryUAjF+pCAE2ERr5BDIvih4nDAmFzsYkmwtMrMNLu0fdfUoQCAnlnG5w/sNqa5VF4u6uE0PaYQivWhhg5EWKw/2Ki7r7XLjdwMa32UXlxSgacvHxnz86onMeXYbQy/n34ChhTlYvrwY3DdxNKIXsNuY+jUuIPocskFPLQHTgJufcgDJ8Li5SCx7uF/Woi/fbMrgdZEz9F2Z8CYx8vxr+8q0O6MvJtNqPS930w5DtMjaGIs5/01B3GkzYkjbcq/QZ7SGZaAR2UFYQZIwImwUK8wVPPCNzsTZEl41DQF7wk5eWhgWYcvN1bh2QU78OeFkf8tzy3cEfFzjbL3sHLZfqdLHgMPLc+h3lPC/JCAE2Gh/rJve1RdYTj5dLo8uOgfP+Dlpbsx4anFQY91aoUghLF9DW1R2/Lq9WOjPoces2ecCMAfMhFTF/ce9tsdXgiFBNzqkIATYaGODGSl27UPTCJ/+XonNlU24emvtgfsO6UkX/H4n0sqpBBEh9ODTpdHyhL5dnv0pX3OHaZboDNqTiv19U9xCW+KOMG8x7CAx8E4IqGQgBO6lO8/itLZ87BoSw32y7zSdIc5PzaNGnFtkccvHo4Xf3oqPr71dADAkTYnTn3sawDASX9cgBMfWoAmWR61loceijmrD4Q+KAY4hBKGYq63dns1/eeLPTgtnFhECJjzm0iYgjveWwsAmPV2OQ63+sWxKCdd8/jNlU0JsUsLp9uL+pYu3f0jBvTEzJF9MWaQsvtfnazR8CNfbJW2Dx71NWU4dLQdtTrNiJ1uL0pnz8P7gnDf98mmiO03gsPuE+AfhS70WrXBgyGGTigGbn1IwAld9Lql98vPAgDce/4JivEL//EDSmfPQ1tX5FkckXL3B+uwJIKFRuOe1I6VT31+KfbUt2LSM0sw/snF+OUba7CztkVxTKvwdz7yxVY8/uVWrdPEhTShNMBrP+wFEOhJ5wjhrS82VAU9D8m39SEBJ3TRazYglkDVK9S0IUjOeLyYvyn23YHOeX6ptP3t9jo88KnSwxbDSh0uD14VxDQZqFujtQvZKKKHrkb8YaZJTOtjrdUXRELpdIW+NS/KTVeEVwBEVmIvCoKtfiwpzMJFI7VrcUfLpf/6MS7nDYU6Pq9uzJBmt8Hp9uoKNIVQug8k4IQuwWLKIr1yMgIEnCVYwYMVplp279m6oSCjhPt3Lb13SkxeT4/+QghLxKHywDMcooAHPw/pt/UhAScMw2XRUy1tTHSrxWBNJWIl3r6ThXfYoF45sXtNDQpy0jFmUAGyhNoq6t6WGQ4bWqB8n7SgLBTrQzFwIubEVDTDwNdUIpCnLhuhOR4p8iybZMeP7cxfkVAdA79TKJTVIzN4oSwKoVgfEvBuzJcbq1BR1xL6wCj4509HB4zd9t5aNHe6NI6OD2+v2K85fu24gZrj6/84DWsfmmb4ddqdHpTtOwIgvKXq8UReE1wt4NcLRbJ21bWqn6aE9NvykIB3Y25/bx3O/cuymJ2vKNfXSf2BmcOkseN698BzVyir+tW3dGHOqsQsagGABUK97+H98wAA+dlpGKVaeSknPzsdhTnpWP2A8a6AV7y8Akt21OGDNYn7+7Rw2P0Cro6BiyzbWR90cRN54NaHYuBE2FxzWgnuUeV+A9qO3FNfbceVY0tQqLPoJ5ZcNbYET8zfhvd+PQF5IcIGcoqFHySRlfdNDVlDBQBu/G9gZ6JEI/fAq4MU7go2P0DybX3IAyfCRm9F4lnHB1b2A4ADR9rjaU4ANoOxd8YYtjxyPgDgqrEDcEzPTGlf2YPn4sGZJxm24cKRfQ0/JxIcQl/Mo6qSso/85OSQz/UvpScJtzrkgRNhc9YJ2kLdJy8T3//+bEx+doliPFHZKKIQRfJ6ORkO7Ht6pvR4/p2TwcFRlJuBmyYPwaBeOfj1W2Vhn++Fq0cZNyICRA+8TVW7fGjvXMVjLZH254HHzz4iMZCAd1NCNRYwytJ7pwRNjyspzMafrzwF93y4QRqLJB/84JF2fL/rMK4dVxJ2Nov4pxr1wLUY1i9P8XjasD54cOZJeHzeNs3j1z40Dav2NGDUwHzYGJOWucebhVtqAQROYKpTCt0ejk6XR9HOTYI8cMtDIZRuitECR6HITg/9W6+Wz0j09NXv9+D+Tzfhy43VYT8n3qGAG88YrLuvMCcdM0b0Rd+eWeiTl6l7XLzoUq2WVQv6R+WHcOJDC7Cjxp+NRNUIuw8k4N0UrRKj0ZCZFvqj8pNRyiXrkQj43gZf3PyOOesA+Opaz3qrLKxKh7HwwLVQi6IZ+N204wH4C2qJqK/B3xb7Wt1tPNQojdFS+u4DCXg3Jdou8psO+QWzuEdGyEUhgK8Gx+r7/al5keiDeoFMRV0rFm2txay3ynRT4sRaKPHU2f75WXjowmGhD0wQBUJ2j1rA9X5svthYjZl//15xfUm/rQ8JeDclnI4swdhY2ShtX2CgCW9vWRhhd32IhSQqOOdYr6pkKOY4VzV1YtSjX2s+T/ytiucK0OWzz8GvJg1Gtkk6EYkxbXXpXrGw1U2TlGGfZTvrsaWqGduqWygLpRtBAt5N2S+EItLskYnaA59ulraNCuPvp/tyxe96f72h5732w160dPoFyZdloVwmf+ecdSidPU8xJtb8SESk4/g+PeL/ImGQIXRFeuizzYpxsQTw784LzNcHgGteWSFtk35bHxLwborYoTwWS76NxpZH9s+P6HXUmR7H3j8fl7y4XDE2V6NJQSI8cJHHLxkubSczNC6/M5EjhlCy0u2are86ZJ3rQxW7IswPpRF2U6INoUTDlqr4t1ZbuKUGN79djmF98+D0eBMmpvJMk5yM5H199GLd8h9brb6e8h90ykKxPuSBm5SDR9qjak0Wjectz1iIhJmy1Yjh/A0eL8en6w4Zeo2b3y4HAGytbkZFXWvCKiAW98jAt787C3dNHSo1SE4GevnmRu6WKAZufUjATcrkZ5dgyp+/i/j57ig88K1VzRE/FwCOkXmpl4XRteb5RTvw2w82hDxOToYqPJDIcMaQ4lz8dtrxSY2H63ngRlIeSb+tDwm4ialv6cLibbURPdcVxf2x2ou7buIgQ893yLzDHbWhy9ku22W8GbG6SFOia5AnG4fO5LS6vZqavEx/2CfZNc2J6CEBNznvrjqA91cbL10ajQcuX1L5p4uGYXBRdB1mQgmFetHRxaMi6GGZYlrk0Ok4rdeIWmTaMH9KKMXArQ8JuAmRN+n9dnsdZn+yybC3FM1KTLkPN2ZQQUTnuHXKsdL2oq3B7yK21yi99F45/jKvdwndZUIRrC9mdySSEEqGw6aY3CYH3PqQgJsQl0YdE6MrK7XOES6fra+UtkcOyI/oHH+YfqK0XRGqM4yKa8aVIDvdjuWzz8Fvpx2PS0f3j8iG7oxefn+wYlq98zLg8nhpKX03ggTchGhVEgxWmF8Ll8Hj5SyvaIj4uXJeuPoUAIETjqE4vk8PbH10utR9/YGZJ+EXp5di4d1nKmqyFOWm42ydErfdHXnt8hmylbJaud8iB4904KvNNdJniWLg1ieqRFbG2D4ALQA8ANyc87GxMCrV0fK2u1we5BrIO462FgoATD85/CX0Wozo3xOAb4HOTZOHaB6jFpFxgwsDjinKzcDDQqOC7Y/NAOccr/2wFxeO7Ic7haJXqUbvHn4Bl4dN0mUe+D9/OhoNrU5MOaEYO2tbpbrmlY0dAFJu2qBbEouVCGdzzg/H4DyEQIczsMu60RivPA+ccx5RlsZPx2s3BQ6XDIe/bsjBI+3YUtWM6aq6KoeOdigez/n1hJDnZYxJPwirhSbDqcjxfXKxs7ZVETaRb1840j8ZLK/l3tThazhNIRTrQyEUE/Kgqr4FEFj3ORTyLJQfKiL7fe2ZFX5/SS3kTQTOem4JbnmnPOAYdRcfM5ZuNSt2IeVEfs2CXb/JQ4sAAI3tPgEn/bY+0Qo4B7CIMVbOGJuldQBjbBZjrIwxVlZfbzzfNxVZuScwBm04Bi4LoUTaneeUIJ3dw0Eer6aUtdgj1kNx2FhYP7aPXjxc8ZjeE+sTrYBP4pyfCmAGgNsYY2eqD+Ccv8I5H8s5H1tcnJoTTkbwermiIp+IVl2LYMg98DwDnnRU+eMqtNp4fa+zaIcx4KWfnWr4NYpUneVTCdHbdtgZ5t81GW/+clzQ49WZKzSJaX2iEnDOeaXwfx2ATwEE/wQRIXlzxT7N8ce+3GroPJEWs2rW+PGIFK2UtuteWy1tL9leBwDIz07D3qdmYsYI4x3dP7plIkoKsxR556mCJOA2G/rnZ+Gs44M7SOrwCsm39Yl4EpMxlgPAxjlvEbbPA/BozCxLUcQ63mqMTtbJJzGNhFDErjdXjBlg6PX0cNiYbkbMjW+sAQAUR+FFlxbl4PvfnxPx862MXRZCCet41US2l2IolicaD7wPgB8YYxsArAYwj3O+IDZmpS5a8e9IkDc1NiLgYobCzAi8YS0+uHliyGN2GVzoQ/gQhdseZtMOdSYS6bf1idgD55zvAXBKDG0hoFxW/tRlI/D9rnrM31QDwFeaNdwa1O5IPXBBwHtmR5eBIjKoV7bmuBg+ISJH9MDTQhVAUR0vQg0drA+lEZqUwUU5uHbcQPzrZ2OkMSOZKJGGUJqEFLP8KFMIRfQmGcXwCRE5oiCHm3qpPozmMK0PCbhJ+eKOSQFjXe7ABT56yCcxIwmhRJsDHgx1T0siOsLte2qzqUMopOBWhwTcRMiFNkfW/VxskGBkMU+kMfCqJt/KyFgK+LOXj9TdN6QoB/PvnByz10ol2rt8P+j2MEMo6jrvpN/WhwTcRLQ7/Sl88gmnP140DADQacgD9387jdRFWbnbN4nqCFLVzihXnVaiu+/be6ZgWL+8mL1WKiFmJomZQ6EIyEIhBbc8JOAm4j/L9miO9+7hiyPvO6ydYqiF2+OVqgAa+aLmZjqkKoCENQh3bkTtqFMWivUhATcReu3HxNKhzR0urNl3BMs1apv8e+luzJF17nF5uCTgRjxwl4djQEFiBDxLY6UmET8CGx6TglsdEnATsXCLducaUeg6XB5c+fIK/OzVVQHHPPXVdtz3ySbsrvflVLs8Xmkpu96CDXnIRsTj5UGbAkTKf64PrDQcrHY1ET7hznEELuSJhzVEIkn5b9Bn6yqxv6ENu8JovhtP5F/Cj29VLn7JSvcLeCh+Loi728slAdfywLdVN2PYHxfiiw1VinG3x6vbMDcapg3rEzD2TJDJTSJ8wr3DUjvgFAO3PrGoB25Zdte34u4P1kuP7z3/BNx29nFJseXAEX98e8wgZVODTKGudmcYAl7d1AnAJ8RiNUAtD3xTZRMA4Lsd9bjoFH/daLeXh700OxpO7pcXUBucMMbJ/fKwpaoZt58T3mdWvRKT5Nv6pLSAqws+PbdwR9IE/Kn52wBAM/5sszGkO2wKD9zr5QF5vQBw1VhfDROXJ7gH3izke6tP4fZw3Y7nseQRocMOETkf33o62p0eFOakR/R88sCtT0qHUNSeZrgLImKBvJTnnvpWqXN7X1mvQzlZaXZ0yjr17GtoU+wXJyzFLjguj1fy3D0aX9TH523T3OfyxieEImfOrydgbGlg6zTCGJlpdsPi/bdrRvkfkH5bnpQWcPWsvDx3WqSl0yX1EIwVH5UfwuD75uPz9ZXYdKgJ5zy/VNpXkK39hcxKs+OgrP2YfKLR6+VSKlmny4PtNc3YVdcqrar0qO40PlijzFaR40lACGXisb3ien5CnynH95a2yQO3Pikt4OH0ibz4xeU44+lvY/q693y4Qfr/on/+oNj3yMXaoYWsdDu+lRWAeneVX4TlecBuL8dbK/YD8KclqkMof/h4k/94lbh3OD3SpGms0WpYTCQWeXSM8sCtT0oLeDjpV3vq20IeEylaHn/fnto52OruNv8rOyhty2PjTo8XaQZqXqjnAdq63MhJj8/UyHs3jceOx6fH5dxEeMjnNyJttUeYh5QWcLPdQs69/QzdffL+kgBwpM2/fFqeneL2eCWPW6ynEizNzCn7EfF6OdqcHmSHWbLWKA67TdGpnkg88sqFRvusEuaDBDxB1LV0wuvlmP7XZbrHjByQr7sv2KpFuQfu8nDpsdgL0+XW/zuPLc6RttuF5+VmkMh2V+QCHmnbPcI8pLSAq28h0+wsLo1eN1c2YdwTi/HUV9sUDRuM4NYIt4h0OOUC7sXQ3j0AAL84vRRpdha0DO3AQn/DhbYu38rMcJtGENZDHl0z2iibMB8pLeDypcTThvWBy8Pjclt54T98E5X/+X6v5v73bhqvTO/SIFhPzHUHG6Vtl8eLYqH41YzhfZHhsAf9m+Q/Yv9e6iumRTVKui/yiXsneeCWJ6VdrcYOfxx5a1UzAODEhxZgwpBCvD8rdC/HWLDyvqlSsapIOSDkhPfIcMDl4dLKS5vNFzuXx8g/X1+peK5cwF9f7vuBMdnUABEnKIRifVJawGfL0ulOOKaHlO+9co+xDvDB+MfiXZrj0S7bly/46SeUfz22dy7cHq+0OMduY8hw2NEpawSh7kWptcgnjOxKohtAIRTrk9IhFLH7DADcNHmwYl9zpyvq8zvdXjz/9U7Nfbecdayhc/UQ4tIOG8OEIYUoKfDHrkUvOivNDqeHS4/tjMFuY/DIYkVi02IRrTop4fZYJKxNqgr4nvpWvPr9HnQ4PSidPQ8vLqlItkkRk9ICLu/mrV4BWd3YGVbxqGA8Pm+r7j6jIvmPn44G4EsJtNsYPJzjm621KJ09D4dbfaGgzDQbXB6vlF1jswkCLtNocQXnteNKpPOJnFZaAABUZCpFSNUY+FX/XoHH523D4dYuAMB/l+9LrkFRkNIhlCvHDpBWNOZnK3tAnv/XZRjWN7pWX+KKSJFV90/F1qpm1DR3Gj5XriwzxMYYnG4vbnqrDICvNCzgW63p9ngVHriNKb3spTvqAQCPXTwcc1YfVOzLz07HSX3zKFc7RUhVD7y5w5dtJTovHgsXRk9pAe+VmyFt52UGNvHdKghjLJg2rA/65GWiT15kE5YlsnQ/u41J5WABfz57psMOlzyEYhdDKH6RFr0uh90mefIiHi9HHHo5ECZj48Pn4cl527BgS02yTUkKXKjiJdYKMtKxymyk9NdVnIXPzXCETJ2LNj9cqyONEeRV5xpalU1sxRzxjDQbnLIQis8DZ5oTleJ++V20T8BT+iOREuRlpiEnwwFXinrgol5f8uJy32MScPPS7nRj6APzsWBzdcA+p9uL3AwHNj9yvmZtbTnJTq1Ls9uQmWbDlBOKFd434MskcdgY0u2+GLgoynYhBq73AVVPcC7dWY8NspxyovuS7rClZAx82c76gAV8bc7o5rqSSbcX8ENHO+DycDy/aCd+2HUY1U0d+GDNASzZXgeXx6uoAf7Xq0fhyzsmaZ5H9GpX7WnA7e+tDemRxyO+WP7gNLx+w2kB4xV1rXB7ue9L6ZZNYopZKHoeuE3pgROpg+/HnuORL7Yk25SEcv3rqwPG8jIdOCjriGUlur2Ai3AAP39tFWb87Xv84eNNuPGNNYKA+y/BJaP7Y3j/nhg9MD/g+eKP9i/+uwZfbqxGe4hf7Yq6Vml7zQPnxuJPQE6GQ/NOQSxsJa66lGLgNiGEIjxW/+jYmPkKehGJQWwobeUMjFjR3OnG5GeXhHTKOl2esNOLvV4eUKo5HnRLAT90tF3ygEW5E+Pdje3+N6DL7dXsjN6hIc6i0IndakKtYvtx92EAwNe/PVNa2h4r7tDpgZjusMHj5ZJtNubLG/d4OXbWtuChzzcDAP5v2vEAfBOZbiGEQqvyUot0mq0OYH9DcC/8xIcWYOTDi4LWFgKA91cfwJD75+PEhxbEpbaSnG73LrY73Zj0zBLc/+kmxXhrpzvgWJeHa36Qtbxr8X0Qu9WEqpkitizrm69d3zsaemT6kofkzvjAwmyprVq70wMb89W9sAkC/pt31+KdlQcUz7PJJjHF9EIiNdByXLo7odZ1XPKv5br75E7dwi21usdVN3Vg9ic+7XF7uaLsczzodu+imOP5Ufkh7KlvlZaFt2gIeKfLowihiGgJuN8D9x3f5dIXcPkHJTcOlf3ETBF584fBRTnSl7Ld6ZEWCtkZg5dzRT1xUcjtNv8M/G/eWwsAuGvq0JjbS5iPVFxtK7/71tuvN4lf2ej3zoOFRtSOYnWT8TUfRuh2At7a5b+Ad3+wXhJjrRn3vYfbND2RS0b1CxgTb4TSJA9c/9f8nZX7dffFAnHeNd1hk+p5/2H6idICnA6nW+r3KeaBy39IxIVEtc1d+KDsIGqaOjHpuCIAwM8nDIqr7YQ5UPeDjYRFW2pw3yebQh9oEo62K73hiidmYM6vJyjG9h7W7sB1SNaPNti1U8fI9c4XK7qdgLfILuDGQ034yT/1b4sq6lo1O9Hfd8FJePaKkYoxtQfeqeOB3/PhBil80j8O4RMAsAs2ZKfbsfh3U7Dv6ZkY1i9P0wPvmZ2GupYu5Gb4Fyq9/PMxivNNeGoxvt1eh749M2MeryfMSaQO+NwNVbjl7XLsrm/FrLfLMWf1AXi9vgqY602egvr9Ll+Y8IWrT8Hq+6fCYbdh4rG9sPahadIxencmcgEPlmHWpKo1tGJPQzQmh6RbCfiCzdW49F8/GnqOVgjFbmPomaVcmSmGGhw6Hnh9SxdKZ8/DR+WHpLF3bhpvyJZwsQsegHxxDwApBt7h8kjHDCzMRk1TpxQ3B/zNhW+YqPS2UzEumqpE4oB3ujy4c846LNhSg6nPL5XGv9lWi0tf+hGXvLgcC7fU4Gic477h0OH0wO3xornThbvfX4fS2fPw5PztAICT+/VEb9mK6MKcdHx86+kA/E1N1ByQpRkGy58XQ7if/OZ0ZKbZsKWqGfM3Ba5BiRWW/cZ2uT0BCfm3vLPW8Hk6dCY2HKpfYjHZX8xCUU9i3vpOueLxgzNPwuCiHMQD8TdHXYBLFOAOp0dKN+yZlQa3lytu+0Qxv3f6iYrnq70HovvC4P88iJkSGw81onT2PMzdUCWVVpZzmY5zNOvtcil2fPPb5Rj92NeYu6EKVY0deHFJRULS6TxejqrGDtQ1d+Ku99fhpD8uwKX/+hEjH16Ez9ZXKY5V1z0CgNEl+chOt2NnbWvAPgD4uPwQegkOUzAPXAyhDCzMxpCiXGw42IjfvGtcl8LFkrVQOOc44cEFmHJCMd64cRw4D+ykk2Znml3fP7xlIkoKsjHhqcUA9EXLofLMmztc6J+fJU0gPv3VdnxxxyQs2V6HYf3y0L8gC2X7j0rH/2qSsjxtLBEnY9QeuNi5vk0WQhGzZz5e678zEO861BOsoSZ5iO5Dm9PvaR5udcLp8UrhxjvnrAMAbH7kfHDO0UOoE6SuDTRxSC/dEIF4DgB4buEOPHv5SHyxsQr3nHcC+vbMRE1zp9QDtra5E5zDUGOT6qYOHG1zYf6malQ2duDTdZUBx6hXLIv0ygkME9psDIN65WBfQ2DM2uPlaO50YcygAjTuO4p6oYqhFmJp2rzMNJx3ch/pmn1UfghXjBkQ1t9mhKgEnDE2HcDfANgBvMo5fzomVqnweDnWHzyKvy+uwOShRVgpfGi+21GP0tnzcNXYAfhf2SHFc5bcMwWTnlkScK6xgwoUbaX0cj/V6YXNHS50OD1SXe5NlU0o338UN76xRnGcjQHr/nie4jVizYj+PZFut+GCEX0V42LY52ibU/K4W7uCi/IVYwZIYZ9XrhsT9Fii+3Byv57S9mlPfKN5zPA/LZS2l917tmLfT8cPxJOXjkDp7Hlhvd7vP94IAPh+1+Ggx112an/cePpgjBjQM2Cfx8sxb1M1vtlai7kbqjSerc/Q3rn4xRmlmH7yMbpx7sw0G77dXif9TUN75+LVG8bC7eVweTguHd0fje0u7KxpQUVdKzYcbMTlKlGubfaJe7rDhl9PHoK/fuNr6HLPhxswfnChoihdLIhYwBljdgAvApgG4BCANYyxuZxz/SLYEfLSdxX48yJfY4SlOwPzldXiffqxvaSO7HJP/KNbJoYtrEW5Su/26ldWBhxz+UvKW8qnLxuBa8YNDOv80XD6cUXY9tj0gA+ieItX09wpTaCOLikIeq4/X3kKnr18JFq63AFxf6L7Mm5wIb67Zwqm/Pm7sI4/8zmfM3RaaQE+vOV0aXzro+djT30b+uVn4dTHvgbgmyTvn5+FIcU5WLW3Ab98oyxsuz5ZW4lP1vq9aRsDinIzUNei7/WqKe2VjesmluL6iYPw1or9aO10465zQ6fHDizMxroDjdLjXXWtOOu572TnzcHgohx8tbkGi4XOVr/7cEPAecQ745wMBz68ZSKufHkFAKCivtU8Ag5gHIAKzvkeAGCMvQ/gYgAxF/D+BeFnc0w9sTeeuHQE8jLTsOaBc1GYkw4b8/0yym/RPr/tDOxraMPEY3tpnmdQL2Px65vPHJIQ8RbR8iIGyK6T6BmcO6wPzj+5DxZuqcXYQQUB2TWA7/aRxDv1KC3Kwde/PRPTXlgmjeVmOKRU3CcuHY4HPt2seM4r1ymramanOzC8v89bfn/WBPTJy1TM/ZxzYh/se3omNhxshMvjxcBe2fiw7BCqGjvwzbZa5KQ7sCdIqp2XI6h4P3fFSFw5tgRNHS7c+N/VuO3s4zD1pD7SfiOhzKcuG4HVe49o5m6PKsnHqYMKsLO2BV9tDl6G95Nb/T9wp5UWYveTF8Aj1CqKNSzSpZ6MsSsATOec3yQ8vg7AeM757arjZgGYBQADBw4cs39/5DnStc2d2N/QjpP69kC70yPV1l574Cj21rchLysN04b1CXGW8HG6vViyw/dL2+nyoDg3AwePtuPsE3ujfN9RFOako19+FtqdHpxwTI+YvW407G9ow4ZDTbhwRF9F3ZTGdid6ZKal5AIOIjg7alqwqbIJFXWtuPnMIWho68JxvX2fZ5fHi5qmTny1uRo3nF4al2Yf4hyWw8bg9nIcONKO/Ow0/GNxBXbUtOCCEcegICcdQ4pyMWJAT3S6PHDYWMA8Vaxo63IjJ8OB/Q1tKN9/FBeM6CvNL3HO8c22OpT2ysZn6ytRkJ2OrVXNuPq0Eqw72IjLTx0Ql1Rcxlg55zygJnXcBVzO2LFjeVlZ+LdTBEEQhL6AR/MTVgmgRPZ4gDBGEARBJIBoBHwNgKGMscGMsXQA1wCYGxuzCIIgiFBEPInJOXczxm4HsBC+NMLXOeepVR2eIAgiiUSVB845nw9gfoxsIQiCIAxg2aX0BEEQqQ4JOEEQhEUhAScIgrAoJOAEQRAWJeKFPBG9GGP1ACJdilkEIHglnORAdhmD7DIG2WWM7mrXIM55sXowoQIeDYyxMq2VSMmG7DIG2WUMsssYqWYXhVAIgiAsCgk4QRCERbGSgL+SbAN0ILuMQXYZg+wyRkrZZZkYOEEQBKHESh44QRAEIYMEnCAIwqJYQsAZY9MZYzsYYxWMsdkJfN0SxtgSxthWxtgWxthdwvjDjLFKxth64d8FsufcJ9i5gzF2fpzt28cY2yTYUCaMFTLGvmaM7RL+LxDGGWPs74JtGxljp8bBnhNk12Q9Y6yZMXZ3sq4XY+x1xlgdY2yzbMzw9WGM3SAcv4sxdkOc7HqOMbZdeO1PGWP5wngpY6xDdu1elj1njPD+Vwi2R9VuSccuw+9drL+vOnZ9ILNpH2NsvTCekOsVRBsS+/ninJv6H3ylancDGAIgHcAGAMMS9Np9AZwqbPcAsBPAMAAPA7hH4/hhgn0ZAAYLdtvjaN8+AEWqsWcBzBa2ZwN4Rti+AMBXABiACQBWJeB9qwEwKFnXC8CZAE4FsDnS6wOgEMAe4f8CYbsgDnadB8AhbD8js6tUfpzqPKsFW5lg+4w42GXovYvH91XLLtX+5wH8MZHXK4g2JPTzZQUPXGqezDl3AhCbJ8cdznk153ytsN0CYBuA/kGecjGA9znnXZzzvQAq4LM/kVwM4E1h+00Al8jG3+I+VgLIZ4z1jaMdUwHs5pwHW3kb1+vFOV8G4IjGaxq5PucD+JpzfoRzfhTA1wCmx9ouzvkizrlbeLgSvg5Xugi25XHOV3KfErwl+1tiZlcQ9N67mH9fg9kleNFXAZgT7Byxvl5BtCGhny8rCHh/AAdljw8huIjGBcZYKYDRAFYJQ7cLt0Kvi7dJSLytHMAixlg58zWPBoA+nPNqYbsGgNjlOdG2XQPll8oM1wswfn2SYeMv4fPWRAYzxtYxxpYyxiYLY/0FWxJhl5H3LtHXazKAWs75LtlYQq+XShsS+vmygoAnHcZYLoCPAdzNOW8G8BKAYwGMAlAN3y1cMpjEOT8VwAwAtzHGzpTvFDyNhOeJMl+LvZ8A+FAYMsv1UpCs6xMMxtgDANwA3hWGqgEM5JyPBvB/AN5jjOUl0CRTvncyroXSUUjo9dLQBolEfL6sIOBJbZ7MGEuD7w16l3P+CQBwzms55x7OuRfAf+C/7U+orZzzSuH/OgCfCnbUiqER4f+6JNg2A8BaznmtYJ8prpeA0euTMBsZY78AcCGAnwlffgghigZhuxy++PLxgg3yMEtc7IrgvUvk9XIAuAzABzJ7E3a9tLQBCf58WUHAk9Y8WYivvQZgG+f8L7Jxeez4UgDi7PhcANcwxjIYY4MBDIVv4iQetuUwxnqI2/BNgm0WbBBnsm8A8LnMtuuF2fAJAJpkt3qxRuEVmeF6yTB6fRYCOI8xViCED84TxmIKY2w6gN8D+AnnvF02XswYswvbQ+C7RnsE25oZYxOEz+n1sr8llnYZfe8S+X09F8B2zrkUGknU9dLTBiT68xXpLGwi/8E3g7sTvl/TBxL4upPguwXaCGC98O8CAG8D2CSMzwXQV/acBwQ7dyDKrIAQtg2Bb4Z/A4At4nUB0AvAYgC7AHwDoFAYZwBeFGzbBGBsnOzKAdAAoKdsLCnXC74fkWoALvhii7+K5PrAF5OuEP7dGCe7KuCLhYqfs5eFYy8X3t/1ANYCuEh2nrHwCepuAP+EsLI6xnYZfu9i/X3VsksYfwPALapjE3K9oK8NCf180VJ6giAIi2KFEApBEAShAQk4QRCERSEBJwiCsCgk4ARBEBaFBJwgCMKikIATBEFYFBJwgiAIi/L/qs4rVBCN8lUAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.iloc[:, 0].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ym4xWUUxaFvg",
        "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "c1=2.6676\n",
        "c2=7000\n",
        "c3=20000\n",
        "b3=1.06\n",
        "L = df.iloc[:, 3] + (c1 * df.iloc[:, 1] + b3 * df.iloc[:, 2] + c2 + c3*np.tanh(df.iloc[:,0]))\n",
        "L.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyEywnwaFvh"
      },
      "source": [
        "## Preprocessing the data into supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6V9dXqzdaFvh"
      },
      "outputs": [],
      "source": [
        "# split a sequence into samples\n",
        "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n_in, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n_out)\n",
        "    for i in range(0, n_out):\n",
        "      cols.append(df.shift(-i))\n",
        "      if i == 0:\n",
        "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "      else:\n",
        "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "       agg.dropna(inplace=True)\n",
        "    return agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrzSrT1HnyfH",
        "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    var1(t-35)  var1(t-34)  var1(t-33)  var1(t-32)  var1(t-31)  var1(t-30)  \\\n",
            "35    0.116134    0.159976    0.145809    0.145829    0.118201    0.102154   \n",
            "36    0.159976    0.145809    0.145829    0.118201    0.102154    0.135091   \n",
            "37    0.145809    0.145829    0.118201    0.102154    0.135091    0.075362   \n",
            "38    0.145829    0.118201    0.102154    0.135091    0.075362    0.074492   \n",
            "39    0.118201    0.102154    0.135091    0.075362    0.074492    0.214121   \n",
            "\n",
            "    var1(t-29)  var1(t-28)  var1(t-27)  var1(t-26)  ...  var3(t+7)  var4(t+7)  \\\n",
            "35    0.135091    0.075362    0.074492    0.214121  ...   0.010170  -0.000639   \n",
            "36    0.075362    0.074492    0.214121    0.218214  ...   0.009532  -0.000842   \n",
            "37    0.074492    0.214121    0.218214    0.122469  ...   0.008689  -0.001007   \n",
            "38    0.214121    0.218214    0.122469    0.119180  ...   0.007682   0.019338   \n",
            "39    0.218214    0.122469    0.119180    0.030099  ...   0.027020  -0.003387   \n",
            "\n",
            "    var1(t+8)  var2(t+8)  var3(t+8)  var4(t+8)  var1(t+9)  var2(t+9)  \\\n",
            "35   0.131719  -0.006297   0.009532  -0.000842   0.191796   0.003235   \n",
            "36   0.191796   0.003235   0.008689  -0.001007   0.091012   0.011924   \n",
            "37   0.091012   0.011924   0.007682   0.019338   0.119433   0.019606   \n",
            "38   0.119433   0.019606   0.027020  -0.003387   0.133928   0.046626   \n",
            "39   0.133928   0.046626   0.023633  -0.003749   0.149037   0.070258   \n",
            "\n",
            "    var3(t+9)  var4(t+9)  \n",
            "35   0.008689  -0.001007  \n",
            "36   0.007682   0.019338  \n",
            "37   0.027020  -0.003387  \n",
            "38   0.023633  -0.003749  \n",
            "39   0.019884  -0.003982  \n",
            "\n",
            "[5 rows x 78 columns]\n",
            "Index(['var1(t-35)', 'var1(t-34)', 'var1(t-33)', 'var1(t-32)', 'var1(t-31)',\n",
            "       'var1(t-30)', 'var1(t-29)', 'var1(t-28)', 'var1(t-27)', 'var1(t-26)',\n",
            "       'var1(t-25)', 'var1(t-24)', 'var1(t-23)', 'var1(t-22)', 'var1(t-21)',\n",
            "       'var1(t-20)', 'var1(t-19)', 'var1(t-18)', 'var1(t-17)', 'var1(t-16)',\n",
            "       'var1(t-15)', 'var1(t-14)', 'var1(t-13)', 'var1(t-12)', 'var1(t-11)',\n",
            "       'var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)', 'var1(t-6)',\n",
            "       'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)',\n",
            "       'var2(t-1)', 'var3(t-1)', 'var4(t-1)', 'var1(t)', 'var2(t)', 'var3(t)',\n",
            "       'var4(t)', 'var1(t+1)', 'var2(t+1)', 'var3(t+1)', 'var4(t+1)',\n",
            "       'var1(t+2)', 'var2(t+2)', 'var3(t+2)', 'var4(t+2)', 'var1(t+3)',\n",
            "       'var2(t+3)', 'var3(t+3)', 'var4(t+3)', 'var1(t+4)', 'var2(t+4)',\n",
            "       'var3(t+4)', 'var4(t+4)', 'var1(t+5)', 'var2(t+5)', 'var3(t+5)',\n",
            "       'var4(t+5)', 'var1(t+6)', 'var2(t+6)', 'var3(t+6)', 'var4(t+6)',\n",
            "       'var1(t+7)', 'var2(t+7)', 'var3(t+7)', 'var4(t+7)', 'var1(t+8)',\n",
            "       'var2(t+8)', 'var3(t+8)', 'var4(t+8)', 'var1(t+9)', 'var2(t+9)',\n",
            "       'var3(t+9)', 'var4(t+9)'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "data = Supervised(df.values, n_in = 35, n_out = 10)\n",
        "\n",
        "\n",
        "cols_to_drop = []\n",
        "for i in range(2, 36):\n",
        "    cols_to_drop.extend([f'var2(t-{i})', f'var3(t-{i})', f'var4(t-{i})'])\n",
        "\n",
        "data.drop(cols_to_drop, axis=1, inplace=True)\n",
        "\n",
        "print(data.head())\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AfPf60oy6Pe4"
      },
      "outputs": [],
      "source": [
        "train = np.array(data[0:len(data)-1])\n",
        "forecast = np.array(data.tail(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WSAafzI37KiT"
      },
      "outputs": [],
      "source": [
        "trainy = train[:,-30:]\n",
        "trainX = train[:,:-30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2SrOqVJA7f50"
      },
      "outputs": [],
      "source": [
        "forecasty = forecast[:,-30:]\n",
        "forecastX = forecast[:,:-30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qno_k8Nw7saY",
        "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1959, 1, 48) (1959, 30) (1, 1, 48)\n"
          ]
        }
      ],
      "source": [
        "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
        "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
        "print(trainX.shape, trainy.shape, forecastX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Jp2DvNuNFx",
        "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "25/25 [==============================] - 3s 39ms/step - loss: 9788077.0000 - val_loss: 9795190.0000\n",
            "Epoch 2/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9770937.0000 - val_loss: 9789691.0000\n",
            "Epoch 3/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9758455.0000 - val_loss: 9783224.0000\n",
            "Epoch 4/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9744509.0000 - val_loss: 9775306.0000\n",
            "Epoch 5/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9730658.0000 - val_loss: 9766053.0000\n",
            "Epoch 6/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9714675.0000 - val_loss: 9755333.0000\n",
            "Epoch 7/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9698956.0000 - val_loss: 9743744.0000\n",
            "Epoch 8/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9683880.0000 - val_loss: 9731671.0000\n",
            "Epoch 9/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9669087.0000 - val_loss: 9719194.0000\n",
            "Epoch 10/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9654457.0000 - val_loss: 9706377.0000\n",
            "Epoch 11/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9639931.0000 - val_loss: 9693274.0000\n",
            "Epoch 12/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9625484.0000 - val_loss: 9679935.0000\n",
            "Epoch 13/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9611099.0000 - val_loss: 9666397.0000\n",
            "Epoch 14/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9596770.0000 - val_loss: 9652700.0000\n",
            "Epoch 15/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9582492.0000 - val_loss: 9638873.0000\n",
            "Epoch 16/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9568263.0000 - val_loss: 9624946.0000\n",
            "Epoch 17/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9554085.0000 - val_loss: 9610943.0000\n",
            "Epoch 18/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9539955.0000 - val_loss: 9596881.0000\n",
            "Epoch 19/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9525875.0000 - val_loss: 9582779.0000\n",
            "Epoch 20/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9511842.0000 - val_loss: 9568652.0000\n",
            "Epoch 21/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9497861.0000 - val_loss: 9554510.0000\n",
            "Epoch 22/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9483930.0000 - val_loss: 9540362.0000\n",
            "Epoch 23/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9470045.0000 - val_loss: 9526220.0000\n",
            "Epoch 24/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 9456209.0000 - val_loss: 9512088.0000\n",
            "Epoch 25/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9442422.0000 - val_loss: 9497973.0000\n",
            "Epoch 26/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9428681.0000 - val_loss: 9483878.0000\n",
            "Epoch 27/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9414985.0000 - val_loss: 9469808.0000\n",
            "Epoch 28/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9401337.0000 - val_loss: 9455766.0000\n",
            "Epoch 29/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9387732.0000 - val_loss: 9441753.0000\n",
            "Epoch 30/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9374170.0000 - val_loss: 9427771.0000\n",
            "Epoch 31/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9360653.0000 - val_loss: 9413824.0000\n",
            "Epoch 32/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9347175.0000 - val_loss: 9399911.0000\n",
            "Epoch 33/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9333737.0000 - val_loss: 9386032.0000\n",
            "Epoch 34/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9320341.0000 - val_loss: 9372188.0000\n",
            "Epoch 35/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9306982.0000 - val_loss: 9358381.0000\n",
            "Epoch 36/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9293662.0000 - val_loss: 9344609.0000\n",
            "Epoch 37/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9280378.0000 - val_loss: 9330874.0000\n",
            "Epoch 38/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9267130.0000 - val_loss: 9317174.0000\n",
            "Epoch 39/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9253918.0000 - val_loss: 9303512.0000\n",
            "Epoch 40/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9240739.0000 - val_loss: 9289883.0000\n",
            "Epoch 41/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9227593.0000 - val_loss: 9276291.0000\n",
            "Epoch 42/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9214481.0000 - val_loss: 9262732.0000\n",
            "Epoch 43/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9201402.0000 - val_loss: 9249208.0000\n",
            "Epoch 44/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9188353.0000 - val_loss: 9235719.0000\n",
            "Epoch 45/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9175333.0000 - val_loss: 9222262.0000\n",
            "Epoch 46/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9162344.0000 - val_loss: 9208840.0000\n",
            "Epoch 47/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9149384.0000 - val_loss: 9195449.0000\n",
            "Epoch 48/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9136453.0000 - val_loss: 9182090.0000\n",
            "Epoch 49/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9123547.0000 - val_loss: 9168765.0000\n",
            "Epoch 50/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9110674.0000 - val_loss: 9155469.0000\n",
            "Epoch 51/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9097824.0000 - val_loss: 9142204.0000\n",
            "Epoch 52/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9084999.0000 - val_loss: 9128970.0000\n",
            "Epoch 53/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9072203.0000 - val_loss: 9115765.0000\n",
            "Epoch 54/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9059430.0000 - val_loss: 9102589.0000\n",
            "Epoch 55/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9046683.0000 - val_loss: 9089443.0000\n",
            "Epoch 56/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9033957.0000 - val_loss: 9076323.0000\n",
            "Epoch 57/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9021257.0000 - val_loss: 9063233.0000\n",
            "Epoch 58/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9008582.0000 - val_loss: 9050169.0000\n",
            "Epoch 59/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8995928.0000 - val_loss: 9037133.0000\n",
            "Epoch 60/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8983296.0000 - val_loss: 9024124.0000\n",
            "Epoch 61/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8970687.0000 - val_loss: 9011141.0000\n",
            "Epoch 62/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8958099.0000 - val_loss: 8998182.0000\n",
            "Epoch 63/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8945533.0000 - val_loss: 8985250.0000\n",
            "Epoch 64/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8932987.0000 - val_loss: 8972342.0000\n",
            "Epoch 65/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8920462.0000 - val_loss: 8959458.0000\n",
            "Epoch 66/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8907958.0000 - val_loss: 8946600.0000\n",
            "Epoch 67/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8895472.0000 - val_loss: 8933764.0000\n",
            "Epoch 68/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8883007.0000 - val_loss: 8920952.0000\n",
            "Epoch 69/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8870562.0000 - val_loss: 8908163.0000\n",
            "Epoch 70/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 8858135.0000 - val_loss: 8895398.0000\n",
            "Epoch 71/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8845728.0000 - val_loss: 8882653.0000\n",
            "Epoch 72/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8833339.0000 - val_loss: 8869932.0000\n",
            "Epoch 73/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8820967.0000 - val_loss: 8857232.0000\n",
            "Epoch 74/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8808614.0000 - val_loss: 8844554.0000\n",
            "Epoch 75/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8796280.0000 - val_loss: 8831897.0000\n",
            "Epoch 76/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8783962.0000 - val_loss: 8819261.0000\n",
            "Epoch 77/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8771661.0000 - val_loss: 8806646.0000\n",
            "Epoch 78/500\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 8759378.0000 - val_loss: 8794051.0000\n",
            "Epoch 79/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8747112.0000 - val_loss: 8781476.0000\n",
            "Epoch 80/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8734862.0000 - val_loss: 8768921.0000\n",
            "Epoch 81/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8722629.0000 - val_loss: 8756385.0000\n",
            "Epoch 82/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8710411.0000 - val_loss: 8743869.0000\n",
            "Epoch 83/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8698211.0000 - val_loss: 8731372.0000\n",
            "Epoch 84/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8686025.0000 - val_loss: 8718894.0000\n",
            "Epoch 85/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8673854.0000 - val_loss: 8706434.0000\n",
            "Epoch 86/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8661700.0000 - val_loss: 8693993.0000\n",
            "Epoch 87/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8649562.0000 - val_loss: 8681570.0000\n",
            "Epoch 88/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8637437.0000 - val_loss: 8669166.0000\n",
            "Epoch 89/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8625330.0000 - val_loss: 8656778.0000\n",
            "Epoch 90/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8613235.0000 - val_loss: 8644409.0000\n",
            "Epoch 91/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8601156.0000 - val_loss: 8632056.0000\n",
            "Epoch 92/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8589090.0000 - val_loss: 8619722.0000\n",
            "Epoch 93/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8577042.0000 - val_loss: 8607404.0000\n",
            "Epoch 94/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8565006.0000 - val_loss: 8595102.0000\n",
            "Epoch 95/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8552981.0000 - val_loss: 8582819.0000\n",
            "Epoch 96/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8540976.0000 - val_loss: 8570551.0000\n",
            "Epoch 97/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8528982.0000 - val_loss: 8558299.0000\n",
            "Epoch 98/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8517000.0000 - val_loss: 8546064.0000\n",
            "Epoch 99/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8505034.0000 - val_loss: 8533845.0000\n",
            "Epoch 100/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8493080.0000 - val_loss: 8521640.0000\n",
            "Epoch 101/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8481140.0000 - val_loss: 8509454.0000\n",
            "Epoch 102/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8469213.0000 - val_loss: 8497281.0000\n",
            "Epoch 103/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8457300.0000 - val_loss: 8485124.0000\n",
            "Epoch 104/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8445399.0000 - val_loss: 8472984.0000\n",
            "Epoch 105/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8433512.0000 - val_loss: 8460857.0000\n",
            "Epoch 106/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8421637.0000 - val_loss: 8448746.0000\n",
            "Epoch 107/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8409775.0000 - val_loss: 8436649.0000\n",
            "Epoch 108/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8397925.0000 - val_loss: 8424568.0000\n",
            "Epoch 109/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8386090.0000 - val_loss: 8412500.0000\n",
            "Epoch 110/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8374263.5000 - val_loss: 8400447.0000\n",
            "Epoch 111/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8362452.0000 - val_loss: 8388409.0000\n",
            "Epoch 112/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8350652.0000 - val_loss: 8376385.5000\n",
            "Epoch 113/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8338864.0000 - val_loss: 8364375.5000\n",
            "Epoch 114/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 8327088.5000 - val_loss: 8352380.0000\n",
            "Epoch 115/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8315325.0000 - val_loss: 8340397.5000\n",
            "Epoch 116/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8303573.0000 - val_loss: 8328430.5000\n",
            "Epoch 117/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8291833.0000 - val_loss: 8316476.0000\n",
            "Epoch 118/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8280104.5000 - val_loss: 8304535.0000\n",
            "Epoch 119/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8268388.5000 - val_loss: 8292608.5000\n",
            "Epoch 120/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8256683.0000 - val_loss: 8280695.0000\n",
            "Epoch 121/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8244991.0000 - val_loss: 8268795.0000\n",
            "Epoch 122/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8233308.5000 - val_loss: 8256908.0000\n",
            "Epoch 123/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8221639.0000 - val_loss: 8245034.0000\n",
            "Epoch 124/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8209980.5000 - val_loss: 8233173.0000\n",
            "Epoch 125/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8198333.0000 - val_loss: 8221326.5000\n",
            "Epoch 126/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8186694.5000 - val_loss: 8209490.5000\n",
            "Epoch 127/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8175069.5000 - val_loss: 8197668.5000\n",
            "Epoch 128/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8163456.0000 - val_loss: 8185858.5000\n",
            "Epoch 129/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8151851.0000 - val_loss: 8174063.0000\n",
            "Epoch 130/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8140259.0000 - val_loss: 8162278.0000\n",
            "Epoch 131/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8128678.0000 - val_loss: 8150507.0000\n",
            "Epoch 132/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 8117107.5000 - val_loss: 8138748.0000\n",
            "Epoch 133/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8105548.0000 - val_loss: 8127000.0000\n",
            "Epoch 134/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8093998.0000 - val_loss: 8115266.5000\n",
            "Epoch 135/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8082462.0000 - val_loss: 8103543.5000\n",
            "Epoch 136/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8070932.0000 - val_loss: 8091834.0000\n",
            "Epoch 137/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8059416.5000 - val_loss: 8080135.0000\n",
            "Epoch 138/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8047909.5000 - val_loss: 8068449.5000\n",
            "Epoch 139/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8036414.0000 - val_loss: 8056775.0000\n",
            "Epoch 140/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8024926.5000 - val_loss: 8045113.0000\n",
            "Epoch 141/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8013453.0000 - val_loss: 8033463.5000\n",
            "Epoch 142/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8001987.5000 - val_loss: 8021824.5000\n",
            "Epoch 143/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7990533.5000 - val_loss: 8010197.5000\n",
            "Epoch 144/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7979091.0000 - val_loss: 7998581.5000\n",
            "Epoch 145/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 7967656.0000 - val_loss: 7986978.0000\n",
            "Epoch 146/500\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7956233.0000 - val_loss: 7975386.0000\n",
            "Epoch 147/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7944819.5000 - val_loss: 7963805.5000\n",
            "Epoch 148/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7933415.5000 - val_loss: 7952236.5000\n",
            "Epoch 149/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7922023.0000 - val_loss: 7940678.0000\n",
            "Epoch 150/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7910640.0000 - val_loss: 7929132.0000\n",
            "Epoch 151/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7899266.0000 - val_loss: 7917596.5000\n",
            "Epoch 152/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7887902.5000 - val_loss: 7906073.0000\n",
            "Epoch 153/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 7876548.5000 - val_loss: 7894560.0000\n",
            "Epoch 154/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 7865205.5000 - val_loss: 7883058.5000\n",
            "Epoch 155/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7853873.0000 - val_loss: 7871567.0000\n",
            "Epoch 156/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7842549.5000 - val_loss: 7860088.0000\n",
            "Epoch 157/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 7831235.0000 - val_loss: 7848620.0000\n",
            "Epoch 158/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 7819931.0000 - val_loss: 7837162.0000\n",
            "Epoch 159/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 7808637.0000 - val_loss: 7825714.5000\n",
            "Epoch 160/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 7797351.5000 - val_loss: 7814279.0000\n",
            "Epoch 161/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 7786077.0000 - val_loss: 7802854.0000\n",
            "Epoch 162/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 7774812.5000 - val_loss: 7791439.5000\n",
            "Epoch 163/500\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 7763556.5000 - val_loss: 7780036.5000\n",
            "Epoch 164/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7752311.5000 - val_loss: 7768644.0000\n",
            "Epoch 165/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7741073.5000 - val_loss: 7757261.0000\n",
            "Epoch 166/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7729848.0000 - val_loss: 7745890.0000\n",
            "Epoch 167/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7718629.5000 - val_loss: 7734530.0000\n",
            "Epoch 168/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7707422.0000 - val_loss: 7723179.0000\n",
            "Epoch 169/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7696224.0000 - val_loss: 7711840.0000\n",
            "Epoch 170/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7685035.0000 - val_loss: 7700510.5000\n",
            "Epoch 171/500\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 7673855.5000 - val_loss: 7689191.0000\n",
            "Epoch 172/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7662684.0000 - val_loss: 7677883.0000\n",
            "Epoch 173/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7651524.5000 - val_loss: 7666585.0000\n",
            "Epoch 174/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7640373.0000 - val_loss: 7655297.5000\n",
            "Epoch 175/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7629230.0000 - val_loss: 7644021.0000\n",
            "Epoch 176/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 7618098.0000 - val_loss: 7632753.5000\n",
            "Epoch 177/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7606976.0000 - val_loss: 7621497.5000\n",
            "Epoch 178/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7595861.0000 - val_loss: 7610251.0000\n",
            "Epoch 179/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7584755.5000 - val_loss: 7599014.5000\n",
            "Epoch 180/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7573659.5000 - val_loss: 7587789.0000\n",
            "Epoch 181/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7562574.0000 - val_loss: 7576573.5000\n",
            "Epoch 182/500\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7551497.0000 - val_loss: 7565367.0000\n",
            "Epoch 183/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7540429.0000 - val_loss: 7554171.5000\n",
            "Epoch 184/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7529370.0000 - val_loss: 7542986.0000\n",
            "Epoch 185/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7518319.0000 - val_loss: 7531810.0000\n",
            "Epoch 186/500\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 7507279.0000 - val_loss: 7520645.0000\n",
            "Epoch 187/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7496248.5000 - val_loss: 7509490.5000\n",
            "Epoch 188/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7485226.5000 - val_loss: 7498344.5000\n",
            "Epoch 189/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7474212.5000 - val_loss: 7487209.0000\n",
            "Epoch 190/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7463207.5000 - val_loss: 7476084.0000\n",
            "Epoch 191/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7452212.0000 - val_loss: 7464968.0000\n",
            "Epoch 192/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7441227.0000 - val_loss: 7453862.5000\n",
            "Epoch 193/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7430249.0000 - val_loss: 7442766.5000\n",
            "Epoch 194/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7419280.5000 - val_loss: 7431680.5000\n",
            "Epoch 195/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7408321.0000 - val_loss: 7420604.5000\n",
            "Epoch 196/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7397371.0000 - val_loss: 7409537.5000\n",
            "Epoch 197/500\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7386429.5000 - val_loss: 7398481.0000\n",
            "Epoch 198/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 7375497.5000 - val_loss: 7387434.5000\n",
            "Epoch 199/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7364574.0000 - val_loss: 7376397.5000\n",
            "Epoch 200/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7353659.5000 - val_loss: 7365371.0000\n",
            "Epoch 201/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7342754.5000 - val_loss: 7354352.5000\n",
            "Epoch 202/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7331856.5000 - val_loss: 7343344.5000\n",
            "Epoch 203/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7320969.5000 - val_loss: 7332345.5000\n",
            "Epoch 204/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7310090.5000 - val_loss: 7321357.5000\n",
            "Epoch 205/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7299219.5000 - val_loss: 7310378.5000\n",
            "Epoch 206/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7288358.0000 - val_loss: 7299409.0000\n",
            "Epoch 207/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7277506.5000 - val_loss: 7288448.5000\n",
            "Epoch 208/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7266663.5000 - val_loss: 7277499.0000\n",
            "Epoch 209/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7255828.5000 - val_loss: 7266558.0000\n",
            "Epoch 210/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 7245002.0000 - val_loss: 7255627.0000\n",
            "Epoch 211/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7234183.5000 - val_loss: 7244705.5000\n",
            "Epoch 212/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7223375.5000 - val_loss: 7233793.5000\n",
            "Epoch 213/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7212575.5000 - val_loss: 7222889.0000\n",
            "Epoch 214/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7201786.0000 - val_loss: 7211996.5000\n",
            "Epoch 215/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7191002.5000 - val_loss: 7201113.5000\n",
            "Epoch 216/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7180231.0000 - val_loss: 7190238.5000\n",
            "Epoch 217/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7169464.0000 - val_loss: 7179375.0000\n",
            "Epoch 218/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7158709.5000 - val_loss: 7168520.0000\n",
            "Epoch 219/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7147962.0000 - val_loss: 7157673.0000\n",
            "Epoch 220/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7137223.0000 - val_loss: 7146836.0000\n",
            "Epoch 221/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7126493.0000 - val_loss: 7136008.5000\n",
            "Epoch 222/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 7115771.0000 - val_loss: 7125190.5000\n",
            "Epoch 223/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7105057.5000 - val_loss: 7114382.5000\n",
            "Epoch 224/500\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 7094354.5000 - val_loss: 7103582.5000\n",
            "Epoch 225/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7083658.0000 - val_loss: 7092793.5000\n",
            "Epoch 226/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7072973.0000 - val_loss: 7082013.5000\n",
            "Epoch 227/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7062294.5000 - val_loss: 7071242.5000\n",
            "Epoch 228/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7051624.5000 - val_loss: 7060480.0000\n",
            "Epoch 229/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7040964.5000 - val_loss: 7049727.5000\n",
            "Epoch 230/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7030312.0000 - val_loss: 7038983.0000\n",
            "Epoch 231/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7019669.0000 - val_loss: 7028249.0000\n",
            "Epoch 232/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7009033.0000 - val_loss: 7017524.0000\n",
            "Epoch 233/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 6998407.0000 - val_loss: 7006807.5000\n",
            "Epoch 234/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6987789.5000 - val_loss: 6996102.0000\n",
            "Epoch 235/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6977181.0000 - val_loss: 6985404.5000\n",
            "Epoch 236/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6966580.5000 - val_loss: 6974716.0000\n",
            "Epoch 237/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6955988.0000 - val_loss: 6964038.0000\n",
            "Epoch 238/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6945406.0000 - val_loss: 6953368.0000\n",
            "Epoch 239/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6934829.5000 - val_loss: 6942707.5000\n",
            "Epoch 240/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6924264.0000 - val_loss: 6932055.5000\n",
            "Epoch 241/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6913705.5000 - val_loss: 6921412.5000\n",
            "Epoch 242/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6903157.0000 - val_loss: 6910779.5000\n",
            "Epoch 243/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6892615.0000 - val_loss: 6900155.5000\n",
            "Epoch 244/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6882083.0000 - val_loss: 6889540.0000\n",
            "Epoch 245/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6871559.5000 - val_loss: 6878935.0000\n",
            "Epoch 246/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6861045.0000 - val_loss: 6868338.5000\n",
            "Epoch 247/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6850539.0000 - val_loss: 6857751.0000\n",
            "Epoch 248/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6840041.5000 - val_loss: 6847172.5000\n",
            "Epoch 249/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6829551.5000 - val_loss: 6836603.5000\n",
            "Epoch 250/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6819071.0000 - val_loss: 6826043.0000\n",
            "Epoch 251/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6808598.0000 - val_loss: 6815491.5000\n",
            "Epoch 252/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6798133.5000 - val_loss: 6804948.0000\n",
            "Epoch 253/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6787678.0000 - val_loss: 6794415.0000\n",
            "Epoch 254/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6777230.0000 - val_loss: 6783889.5000\n",
            "Epoch 255/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6766790.0000 - val_loss: 6773373.5000\n",
            "Epoch 256/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6756360.5000 - val_loss: 6762867.5000\n",
            "Epoch 257/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6745939.0000 - val_loss: 6752370.5000\n",
            "Epoch 258/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6735525.5000 - val_loss: 6741883.5000\n",
            "Epoch 259/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6725121.0000 - val_loss: 6731404.5000\n",
            "Epoch 260/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6714726.0000 - val_loss: 6720934.0000\n",
            "Epoch 261/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6704339.0000 - val_loss: 6710473.0000\n",
            "Epoch 262/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6693960.0000 - val_loss: 6700021.5000\n",
            "Epoch 263/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6683589.0000 - val_loss: 6689578.0000\n",
            "Epoch 264/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6673227.0000 - val_loss: 6679142.5000\n",
            "Epoch 265/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6662871.5000 - val_loss: 6668716.5000\n",
            "Epoch 266/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6652525.5000 - val_loss: 6658299.5000\n",
            "Epoch 267/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6642187.0000 - val_loss: 6647891.0000\n",
            "Epoch 268/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6631859.0000 - val_loss: 6637491.5000\n",
            "Epoch 269/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6621537.5000 - val_loss: 6627100.5000\n",
            "Epoch 270/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6611225.0000 - val_loss: 6616720.5000\n",
            "Epoch 271/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6600922.5000 - val_loss: 6606349.5000\n",
            "Epoch 272/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6590627.5000 - val_loss: 6595987.0000\n",
            "Epoch 273/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6580341.5000 - val_loss: 6585632.5000\n",
            "Epoch 274/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6570064.5000 - val_loss: 6575289.0000\n",
            "Epoch 275/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6559795.5000 - val_loss: 6564952.0000\n",
            "Epoch 276/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6549534.5000 - val_loss: 6554624.5000\n",
            "Epoch 277/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6539282.5000 - val_loss: 6544306.5000\n",
            "Epoch 278/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6529037.0000 - val_loss: 6533996.5000\n",
            "Epoch 279/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6518800.5000 - val_loss: 6523693.5000\n",
            "Epoch 280/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6508573.0000 - val_loss: 6513402.0000\n",
            "Epoch 281/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6498351.5000 - val_loss: 6503116.0000\n",
            "Epoch 282/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6488138.5000 - val_loss: 6492842.5000\n",
            "Epoch 283/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6477936.5000 - val_loss: 6482575.0000\n",
            "Epoch 284/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6467740.0000 - val_loss: 6472318.0000\n",
            "Epoch 285/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6457555.0000 - val_loss: 6462069.0000\n",
            "Epoch 286/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6447378.0000 - val_loss: 6451831.0000\n",
            "Epoch 287/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6437209.5000 - val_loss: 6441601.5000\n",
            "Epoch 288/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6427050.0000 - val_loss: 6431381.5000\n",
            "Epoch 289/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6416898.5000 - val_loss: 6421169.0000\n",
            "Epoch 290/500\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 6406754.5000 - val_loss: 6410965.5000\n",
            "Epoch 291/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6396620.0000 - val_loss: 6400770.5000\n",
            "Epoch 292/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6386492.5000 - val_loss: 6390584.0000\n",
            "Epoch 293/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6376374.0000 - val_loss: 6380405.5000\n",
            "Epoch 294/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6366264.0000 - val_loss: 6370237.5000\n",
            "Epoch 295/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6356161.0000 - val_loss: 6360076.5000\n",
            "Epoch 296/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 6346066.0000 - val_loss: 6349924.0000\n",
            "Epoch 297/500\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 6335979.5000 - val_loss: 6339780.0000\n",
            "Epoch 298/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6325901.0000 - val_loss: 6329644.5000\n",
            "Epoch 299/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6315830.5000 - val_loss: 6319518.0000\n",
            "Epoch 300/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6305770.0000 - val_loss: 6309401.0000\n",
            "Epoch 301/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6295717.5000 - val_loss: 6299293.5000\n",
            "Epoch 302/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6285674.0000 - val_loss: 6289196.5000\n",
            "Epoch 303/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6275640.0000 - val_loss: 6279107.5000\n",
            "Epoch 304/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6265614.0000 - val_loss: 6269026.5000\n",
            "Epoch 305/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6255595.5000 - val_loss: 6258954.5000\n",
            "Epoch 306/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6245586.0000 - val_loss: 6248892.0000\n",
            "Epoch 307/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6235586.0000 - val_loss: 6238837.5000\n",
            "Epoch 308/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6225592.5000 - val_loss: 6228790.0000\n",
            "Epoch 309/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 6215607.0000 - val_loss: 6218752.0000\n",
            "Epoch 310/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6205629.5000 - val_loss: 6208723.0000\n",
            "Epoch 311/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6195660.0000 - val_loss: 6198702.5000\n",
            "Epoch 312/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6185698.5000 - val_loss: 6188689.0000\n",
            "Epoch 313/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6175745.5000 - val_loss: 6178685.5000\n",
            "Epoch 314/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6165800.5000 - val_loss: 6168689.0000\n",
            "Epoch 315/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6155863.0000 - val_loss: 6158701.5000\n",
            "Epoch 316/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6145935.0000 - val_loss: 6148723.0000\n",
            "Epoch 317/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6136014.5000 - val_loss: 6138754.0000\n",
            "Epoch 318/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6126104.0000 - val_loss: 6128794.0000\n",
            "Epoch 319/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6116201.5000 - val_loss: 6118843.0000\n",
            "Epoch 320/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 6106307.5000 - val_loss: 6108899.5000\n",
            "Epoch 321/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6096420.5000 - val_loss: 6098964.0000\n",
            "Epoch 322/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6086541.5000 - val_loss: 6089037.0000\n",
            "Epoch 323/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 6076670.0000 - val_loss: 6079117.5000\n",
            "Epoch 324/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6066807.5000 - val_loss: 6069207.5000\n",
            "Epoch 325/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6056952.0000 - val_loss: 6059306.0000\n",
            "Epoch 326/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6047107.0000 - val_loss: 6049416.0000\n",
            "Epoch 327/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 6037272.5000 - val_loss: 6039537.0000\n",
            "Epoch 328/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6027448.5000 - val_loss: 6029666.0000\n",
            "Epoch 329/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6017632.5000 - val_loss: 6019805.5000\n",
            "Epoch 330/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 6007823.5000 - val_loss: 6009952.0000\n",
            "Epoch 331/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5998025.5000 - val_loss: 6000108.0000\n",
            "Epoch 332/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5988233.0000 - val_loss: 5990272.5000\n",
            "Epoch 333/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5978450.5000 - val_loss: 5980444.0000\n",
            "Epoch 334/500\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 5968675.0000 - val_loss: 5970625.5000\n",
            "Epoch 335/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5958909.0000 - val_loss: 5960814.5000\n",
            "Epoch 336/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5949148.5000 - val_loss: 5951012.5000\n",
            "Epoch 337/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5939397.5000 - val_loss: 5941218.0000\n",
            "Epoch 338/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 5929656.0000 - val_loss: 5931432.5000\n",
            "Epoch 339/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5919920.5000 - val_loss: 5921655.0000\n",
            "Epoch 340/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5910194.0000 - val_loss: 5911885.5000\n",
            "Epoch 341/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5900474.0000 - val_loss: 5902125.0000\n",
            "Epoch 342/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5890763.0000 - val_loss: 5892372.0000\n",
            "Epoch 343/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5881060.0000 - val_loss: 5882628.0000\n",
            "Epoch 344/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5871365.5000 - val_loss: 5872892.5000\n",
            "Epoch 345/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5861678.5000 - val_loss: 5863164.5000\n",
            "Epoch 346/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5852000.5000 - val_loss: 5853446.0000\n",
            "Epoch 347/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5842329.0000 - val_loss: 5843735.0000\n",
            "Epoch 348/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5832666.0000 - val_loss: 5834032.5000\n",
            "Epoch 349/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5823011.5000 - val_loss: 5824337.5000\n",
            "Epoch 350/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5813365.0000 - val_loss: 5814651.5000\n",
            "Epoch 351/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5803725.5000 - val_loss: 5804973.5000\n",
            "Epoch 352/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5794094.5000 - val_loss: 5795304.5000\n",
            "Epoch 353/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5784472.0000 - val_loss: 5785644.0000\n",
            "Epoch 354/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5774857.5000 - val_loss: 5775990.0000\n",
            "Epoch 355/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5765250.5000 - val_loss: 5766346.0000\n",
            "Epoch 356/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5755650.5000 - val_loss: 5756708.5000\n",
            "Epoch 357/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5746061.5000 - val_loss: 5747081.0000\n",
            "Epoch 358/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5736478.0000 - val_loss: 5737462.0000\n",
            "Epoch 359/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5726904.0000 - val_loss: 5727851.0000\n",
            "Epoch 360/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5717337.5000 - val_loss: 5718250.0000\n",
            "Epoch 361/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5707785.0000 - val_loss: 5708663.0000\n",
            "Epoch 362/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5698242.5000 - val_loss: 5699085.5000\n",
            "Epoch 363/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5688709.0000 - val_loss: 5689517.0000\n",
            "Epoch 364/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5679184.5000 - val_loss: 5679955.5000\n",
            "Epoch 365/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5669666.5000 - val_loss: 5670403.5000\n",
            "Epoch 366/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5660157.5000 - val_loss: 5660859.5000\n",
            "Epoch 367/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 5650655.5000 - val_loss: 5651323.5000\n",
            "Epoch 368/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5641162.5000 - val_loss: 5641796.0000\n",
            "Epoch 369/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5631676.0000 - val_loss: 5632275.5000\n",
            "Epoch 370/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5622199.0000 - val_loss: 5622764.5000\n",
            "Epoch 371/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5612730.0000 - val_loss: 5613261.5000\n",
            "Epoch 372/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5603268.5000 - val_loss: 5603767.0000\n",
            "Epoch 373/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5593815.5000 - val_loss: 5594280.5000\n",
            "Epoch 374/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5584370.0000 - val_loss: 5584803.5000\n",
            "Epoch 375/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5574932.5000 - val_loss: 5575332.0000\n",
            "Epoch 376/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5565503.5000 - val_loss: 5565871.0000\n",
            "Epoch 377/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5556081.5000 - val_loss: 5556416.5000\n",
            "Epoch 378/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5546668.0000 - val_loss: 5546971.5000\n",
            "Epoch 379/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5537262.5000 - val_loss: 5537534.5000\n",
            "Epoch 380/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5527864.5000 - val_loss: 5528106.0000\n",
            "Epoch 381/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5518475.0000 - val_loss: 5518684.5000\n",
            "Epoch 382/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5509094.0000 - val_loss: 5509272.0000\n",
            "Epoch 383/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5499719.5000 - val_loss: 5499868.0000\n",
            "Epoch 384/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5490355.5000 - val_loss: 5490472.5000\n",
            "Epoch 385/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5480997.5000 - val_loss: 5481084.5000\n",
            "Epoch 386/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5471647.5000 - val_loss: 5471705.5000\n",
            "Epoch 387/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5462306.0000 - val_loss: 5462333.5000\n",
            "Epoch 388/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5452973.0000 - val_loss: 5452970.0000\n",
            "Epoch 389/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5443646.5000 - val_loss: 5443615.5000\n",
            "Epoch 390/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5434329.0000 - val_loss: 5434268.5000\n",
            "Epoch 391/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5425020.5000 - val_loss: 5424930.0000\n",
            "Epoch 392/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5415718.0000 - val_loss: 5415600.0000\n",
            "Epoch 393/500\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 5406423.5000 - val_loss: 5406278.0000\n",
            "Epoch 394/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5397138.5000 - val_loss: 5396964.5000\n",
            "Epoch 395/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5387865.5000 - val_loss: 5387666.5000\n",
            "Epoch 396/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5378604.0000 - val_loss: 5378379.0000\n",
            "Epoch 397/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5369352.0000 - val_loss: 5369097.5000\n",
            "Epoch 398/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5360107.5000 - val_loss: 5359825.5000\n",
            "Epoch 399/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5350870.0000 - val_loss: 5350562.5000\n",
            "Epoch 400/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5341642.0000 - val_loss: 5341306.5000\n",
            "Epoch 401/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5332421.0000 - val_loss: 5332059.0000\n",
            "Epoch 402/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5323209.0000 - val_loss: 5322819.5000\n",
            "Epoch 403/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5314002.5000 - val_loss: 5313588.5000\n",
            "Epoch 404/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5304806.5000 - val_loss: 5304365.5000\n",
            "Epoch 405/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5295618.5000 - val_loss: 5295150.5000\n",
            "Epoch 406/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5286437.0000 - val_loss: 5285944.5000\n",
            "Epoch 407/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5277263.5000 - val_loss: 5276745.5000\n",
            "Epoch 408/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5268099.0000 - val_loss: 5267555.5000\n",
            "Epoch 409/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5258942.0000 - val_loss: 5258373.5000\n",
            "Epoch 410/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5249794.0000 - val_loss: 5249199.5000\n",
            "Epoch 411/500\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 5240652.0000 - val_loss: 5240034.0000\n",
            "Epoch 412/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5231520.0000 - val_loss: 5230876.5000\n",
            "Epoch 413/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5222394.0000 - val_loss: 5221727.0000\n",
            "Epoch 414/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5213277.0000 - val_loss: 5212586.0000\n",
            "Epoch 415/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5204168.0000 - val_loss: 5203452.0000\n",
            "Epoch 416/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5195066.5000 - val_loss: 5194327.5000\n",
            "Epoch 417/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5185973.0000 - val_loss: 5185211.0000\n",
            "Epoch 418/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5176889.0000 - val_loss: 5176102.0000\n",
            "Epoch 419/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5167811.5000 - val_loss: 5167001.0000\n",
            "Epoch 420/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5158742.0000 - val_loss: 5157909.0000\n",
            "Epoch 421/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 5149681.0000 - val_loss: 5148825.0000\n",
            "Epoch 422/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5140627.5000 - val_loss: 5139749.0000\n",
            "Epoch 423/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5131582.0000 - val_loss: 5130681.0000\n",
            "Epoch 424/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5122545.0000 - val_loss: 5121621.0000\n",
            "Epoch 425/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5113515.0000 - val_loss: 5112570.5000\n",
            "Epoch 426/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5104494.0000 - val_loss: 5103527.0000\n",
            "Epoch 427/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5095481.5000 - val_loss: 5094491.0000\n",
            "Epoch 428/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5086478.0000 - val_loss: 5085470.5000\n",
            "Epoch 429/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5077487.0000 - val_loss: 5076460.0000\n",
            "Epoch 430/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5068507.0000 - val_loss: 5067458.0000\n",
            "Epoch 431/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5059534.0000 - val_loss: 5058463.5000\n",
            "Epoch 432/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5050568.5000 - val_loss: 5049478.0000\n",
            "Epoch 433/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 5041612.5000 - val_loss: 5040500.0000\n",
            "Epoch 434/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 5032663.5000 - val_loss: 5031531.5000\n",
            "Epoch 435/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 5023723.0000 - val_loss: 5022569.0000\n",
            "Epoch 436/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5014789.5000 - val_loss: 5013616.5000\n",
            "Epoch 437/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5005865.0000 - val_loss: 5004671.5000\n",
            "Epoch 438/500\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 4996947.5000 - val_loss: 4995734.0000\n",
            "Epoch 439/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4988038.5000 - val_loss: 4986805.0000\n",
            "Epoch 440/500\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 4979137.5000 - val_loss: 4977884.0000\n",
            "Epoch 441/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4970244.0000 - val_loss: 4968972.5000\n",
            "Epoch 442/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4961358.5000 - val_loss: 4960067.5000\n",
            "Epoch 443/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4952482.0000 - val_loss: 4951170.5000\n",
            "Epoch 444/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4943612.5000 - val_loss: 4942282.0000\n",
            "Epoch 445/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4934751.0000 - val_loss: 4933401.5000\n",
            "Epoch 446/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4925897.5000 - val_loss: 4924530.0000\n",
            "Epoch 447/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4917052.5000 - val_loss: 4915666.0000\n",
            "Epoch 448/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4908214.5000 - val_loss: 4906809.5000\n",
            "Epoch 449/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 4899385.0000 - val_loss: 4897962.0000\n",
            "Epoch 450/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4890563.0000 - val_loss: 4889122.5000\n",
            "Epoch 451/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4881750.5000 - val_loss: 4880290.5000\n",
            "Epoch 452/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 4872943.5000 - val_loss: 4871468.0000\n",
            "Epoch 453/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 4864146.5000 - val_loss: 4862652.0000\n",
            "Epoch 454/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4855356.0000 - val_loss: 4853844.0000\n",
            "Epoch 455/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4846574.0000 - val_loss: 4845045.0000\n",
            "Epoch 456/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4837801.0000 - val_loss: 4836253.5000\n",
            "Epoch 457/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4829035.0000 - val_loss: 4827471.0000\n",
            "Epoch 458/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 4820276.0000 - val_loss: 4818696.0000\n",
            "Epoch 459/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 4811526.5000 - val_loss: 4809929.5000\n",
            "Epoch 460/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 4802788.5000 - val_loss: 4801179.0000\n",
            "Epoch 461/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 4794063.0000 - val_loss: 4792436.0000\n",
            "Epoch 462/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4785345.0000 - val_loss: 4783703.0000\n",
            "Epoch 463/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4776635.5000 - val_loss: 4774976.5000\n",
            "Epoch 464/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4767933.0000 - val_loss: 4766259.5000\n",
            "Epoch 465/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4759240.0000 - val_loss: 4757549.5000\n",
            "Epoch 466/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4750554.0000 - val_loss: 4748847.5000\n",
            "Epoch 467/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4741876.5000 - val_loss: 4740154.0000\n",
            "Epoch 468/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4733206.0000 - val_loss: 4731468.5000\n",
            "Epoch 469/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4724544.5000 - val_loss: 4722791.0000\n",
            "Epoch 470/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4715890.5000 - val_loss: 4714121.5000\n",
            "Epoch 471/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4707244.0000 - val_loss: 4705460.0000\n",
            "Epoch 472/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4698605.5000 - val_loss: 4696806.0000\n",
            "Epoch 473/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4689975.5000 - val_loss: 4688161.5000\n",
            "Epoch 474/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4681353.0000 - val_loss: 4679524.5000\n",
            "Epoch 475/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4672738.0000 - val_loss: 4670895.5000\n",
            "Epoch 476/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4664132.5000 - val_loss: 4662274.5000\n",
            "Epoch 477/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4655532.5000 - val_loss: 4653662.0000\n",
            "Epoch 478/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4646943.0000 - val_loss: 4645056.5000\n",
            "Epoch 479/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4638360.0000 - val_loss: 4636460.0000\n",
            "Epoch 480/500\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 4629785.5000 - val_loss: 4627870.5000\n",
            "Epoch 481/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4621218.0000 - val_loss: 4619290.5000\n",
            "Epoch 482/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 4612660.5000 - val_loss: 4610717.5000\n",
            "Epoch 483/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4604109.0000 - val_loss: 4602153.0000\n",
            "Epoch 484/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4595566.0000 - val_loss: 4593596.5000\n",
            "Epoch 485/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4587031.0000 - val_loss: 4585048.0000\n",
            "Epoch 486/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4578503.5000 - val_loss: 4576508.0000\n",
            "Epoch 487/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4569985.0000 - val_loss: 4567976.0000\n",
            "Epoch 488/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4561473.0000 - val_loss: 4559451.0000\n",
            "Epoch 489/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4552970.5000 - val_loss: 4550935.0000\n",
            "Epoch 490/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4544476.0000 - val_loss: 4542431.5000\n",
            "Epoch 491/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 4535995.0000 - val_loss: 4533939.5000\n",
            "Epoch 492/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4527524.5000 - val_loss: 4525456.0000\n",
            "Epoch 493/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4519061.5000 - val_loss: 4516980.5000\n",
            "Epoch 494/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4510606.0000 - val_loss: 4508511.5000\n",
            "Epoch 495/500\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4502158.5000 - val_loss: 4500052.0000\n",
            "Epoch 496/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4493719.0000 - val_loss: 4491601.5000\n",
            "Epoch 497/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4485287.5000 - val_loss: 4483157.5000\n",
            "Epoch 498/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4476864.5000 - val_loss: 4474722.5000\n",
            "Epoch 499/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 4468448.5000 - val_loss: 4466294.0000\n",
            "Epoch 500/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 4460040.0000 - val_loss: 4457874.5000\n"
          ]
        }
      ],
      "source": [
        "c1 = tf.Variable(2.6676, name=\"c1\", trainable=True, dtype=tf.float32)\n",
        "c2 = tf.Variable(7000, name=\"c2\", trainable=True, dtype=tf.float32)\n",
        "c3 = tf.Variable(20000, name=\"c3\", trainable=True, dtype=tf.float32)\n",
        "b3 = tf.Variable(1.06, name=\"b3\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "splitr = 0.8\n",
        "\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
        "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
        "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
        "    squared_difference3 = tf.square(\n",
        "        y_pred[:, 3] + (c1 * y_pred[:, 1] + b3 * y_pred[:, 2] + c2))\n",
        "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "model.add(Dense(30))\n",
        "model.compile(loss=loss_fn, optimizer='adam')\n",
        "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJL101rPyuoT",
        "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 812ms/step\n"
          ]
        }
      ],
      "source": [
        "forecast_without_mc = forecastX\n",
        "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
        "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9dQELcJ8wbp",
        "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1, 48)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forecastX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS2kyIKG1Kbr",
        "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 48)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forecast_without_mc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0u6VIzaDyuoT"
      },
      "outputs": [],
      "source": [
        "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
        "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUEcw0LX07oU",
        "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 78)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat_without_mc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "31OWVbSh_305"
      },
      "outputs": [],
      "source": [
        "fforecast = inv_yhat_without_mc[:,-30:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BlpGH2FOAiRF"
      },
      "outputs": [],
      "source": [
        "final_forecast = fforecast[:,0:29:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CXkgkj_LBk_t"
      },
      "outputs": [],
      "source": [
        "# code to replace all negative value with 0\n",
        "final_forecast[final_forecast<0] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.18502365, 0.        , 0.54514933,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.46319175]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_set = np.array(training_set)\n",
        "test = np.array(test)\n",
        "final_forecast = np.array(final_forecast.squeeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2132211698586025\n",
            "0.19184193387627602\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
        "rsme = math.sqrt(MSE)\n",
        "print(rsme)  \n",
        "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
        "mae = MAE\n",
        "print(mae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
