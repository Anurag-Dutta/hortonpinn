{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCGKeZ2gyuoQ"
      },
      "source": [
        "_Importing Required Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-6LN-zXiLcM",
        "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
            "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
            "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
            "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install hampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "By_d9uXpaFvZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from hampel import hampel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyOjBMFayuoR"
      },
      "source": [
        "## Pretraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5QqIY_GyuoR"
      },
      "source": [
        "The `horton_intermittency.dat` feeds the model with the dynamics of the Horton Chaotics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9dV4a8yfyuoR"
      },
      "outputs": [],
      "source": [
        "data = np.genfromtxt('horton_intermittency.dat')\n",
        "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
        "training_set = training_set.iloc[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7easoxByuoR"
      },
      "source": [
        "## Computing the Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SnyolJTyuoR"
      },
      "source": [
        "_Calculating the value of_ $\\frac{dx}{dt}$, $\\frac{d^2x}{dt^2}$, _and_ $\\frac{d^3x}{dt^3}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmIbVfIvyuoR",
        "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "1       -0.000011\n",
            "2        0.003571\n",
            "3        0.005754\n",
            "4        0.006818\n",
            "5       -0.000807\n",
            "           ...   \n",
            "9996    -0.129763\n",
            "9997    -0.118735\n",
            "9998    -0.105414\n",
            "9999    -0.090338\n",
            "10000   -0.074048\n",
            "Name: 1, Length: 10000, dtype: float64\n",
            "2        0.003582\n",
            "3        0.002183\n",
            "4        0.001064\n",
            "5       -0.007625\n",
            "6       -0.006999\n",
            "           ...   \n",
            "9996     0.008219\n",
            "9997     0.011028\n",
            "9998     0.013321\n",
            "9999     0.015076\n",
            "10000    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n",
            "2        0.003582\n",
            "3        0.002183\n",
            "4        0.001064\n",
            "5       -0.007625\n",
            "6       -0.006999\n",
            "           ...   \n",
            "9996     0.008219\n",
            "9997     0.011028\n",
            "9998     0.013321\n",
            "9999     0.015076\n",
            "10000    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "t_diff = 1\n",
        "print(training_set.max())\n",
        "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
        "print(gradient_t)\n",
        "gradient_tt = (gradient_t.diff()/t_diff).iloc[1:] # d2x/dt2\n",
        "print(gradient_tt)\n",
        "gradient_ttt = (gradient_tt.diff()/t_diff).iloc[1:] # d3x/dt3\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2eVeeoxyuoS"
      },
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0J-NKyIEyuoS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       0.116134\n",
              "1       0.159976\n",
              "2       0.145809\n",
              "3       0.145829\n",
              "4       0.118201\n",
              "          ...   \n",
              "2010    0.144958\n",
              "2011    0.173800\n",
              "2012    0.101393\n",
              "2013    0.159424\n",
              "2014    0.174057\n",
              "Name: flux, Length: 2015, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"differential-electrons-7-day.csv\")\n",
        "training_set = data.iloc[:, 1]\n",
        "training_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CbNUhJ74UqF",
        "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       0.116134\n",
              "1       0.159976\n",
              "2       0.145809\n",
              "3       0.145829\n",
              "4       0.118201\n",
              "          ...   \n",
              "1959    0.043422\n",
              "1960    0.043423\n",
              "1961    0.057897\n",
              "1962    0.086842\n",
              "1963    0.086841\n",
              "Name: flux, Length: 1964, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = training_set.tail(50)\n",
        "test\n",
        "training_set = training_set.head(1964) # (2013 - 50) + 1\n",
        "training_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0TwTcq0yuoS",
        "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      -0.000011\n",
            "1       0.003571\n",
            "2       0.005754\n",
            "3       0.006818\n",
            "4      -0.000807\n",
            "          ...   \n",
            "9995   -0.129763\n",
            "9996   -0.118735\n",
            "9997   -0.105414\n",
            "9998   -0.090338\n",
            "9999   -0.074048\n",
            "Name: 1, Length: 10000, dtype: float64\n",
            "0       0.003582\n",
            "1       0.002183\n",
            "2       0.001064\n",
            "3      -0.007625\n",
            "4      -0.006999\n",
            "          ...   \n",
            "9994    0.008219\n",
            "9995    0.011028\n",
            "9996    0.013321\n",
            "9997    0.015076\n",
            "9998    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n",
            "0      -0.001400\n",
            "1      -0.001118\n",
            "2      -0.008690\n",
            "3       0.000626\n",
            "4       0.000763\n",
            "          ...   \n",
            "9993    0.003290\n",
            "9994    0.002810\n",
            "9995    0.002293\n",
            "9996    0.001755\n",
            "9997    0.001214\n",
            "Name: 1, Length: 9998, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "training_set = training_set.reset_index(drop=True) # sets a list of integer ranging from 0 to length of training_set as index\n",
        "gradient_t = gradient_t.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_t as index\n",
        "gradient_tt = gradient_tt.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_tt as index\n",
        "gradient_ttt = gradient_ttt.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_ttt as index\n",
        "print(gradient_t)\n",
        "print(gradient_tt)\n",
        "print(gradient_ttt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O2biznZQyuoS"
      },
      "outputs": [],
      "source": [
        "df = pd.concat((training_set, gradient_t), axis=1) ##########[:-1]\n",
        "gradient_tt.columns = [\"grad_tt\"]\n",
        "df = pd.concat((df, gradient_tt), axis=1) ################[:-1]\n",
        "gradient_tt.columns = [\"grad_ttt\"]\n",
        "df = pd.concat((df, gradient_ttt), axis=1) ################[:-1]\n",
        "df.columns = ['y_t', 'grad_t', 'grad_tt', 'grad_ttt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sk_a5v3tyuoS",
        "outputId": "17563625-e550-45ae-faab-fafa353e44da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_t</th>\n",
              "      <th>grad_t</th>\n",
              "      <th>grad_tt</th>\n",
              "      <th>grad_ttt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.116134</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>0.003582</td>\n",
              "      <td>-0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.159976</td>\n",
              "      <td>0.003571</td>\n",
              "      <td>0.002183</td>\n",
              "      <td>-0.001118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.145809</td>\n",
              "      <td>0.005754</td>\n",
              "      <td>0.001064</td>\n",
              "      <td>-0.008690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.145829</td>\n",
              "      <td>0.006818</td>\n",
              "      <td>-0.007625</td>\n",
              "      <td>0.000626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.118201</td>\n",
              "      <td>-0.000807</td>\n",
              "      <td>-0.006999</td>\n",
              "      <td>0.000763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.129763</td>\n",
              "      <td>0.011028</td>\n",
              "      <td>0.002293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.118735</td>\n",
              "      <td>0.013321</td>\n",
              "      <td>0.001755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.105414</td>\n",
              "      <td>0.015076</td>\n",
              "      <td>0.001214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.090338</td>\n",
              "      <td>0.016290</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.074048</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           y_t    grad_t   grad_tt  grad_ttt\n",
              "0     0.116134 -0.000011  0.003582 -0.001400\n",
              "1     0.159976  0.003571  0.002183 -0.001118\n",
              "2     0.145809  0.005754  0.001064 -0.008690\n",
              "3     0.145829  0.006818 -0.007625  0.000626\n",
              "4     0.118201 -0.000807 -0.006999  0.000763\n",
              "...        ...       ...       ...       ...\n",
              "9995       NaN -0.129763  0.011028  0.002293\n",
              "9996       NaN -0.118735  0.013321  0.001755\n",
              "9997       NaN -0.105414  0.015076  0.001214\n",
              "9998       NaN -0.090338  0.016290       NaN\n",
              "9999       NaN -0.074048       NaN       NaN\n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df # DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5esyHu5aFvg"
      },
      "source": [
        "## Plot of the External Forcing from Chaotic Differential Equation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "hGnE43tOh-4p",
        "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.iloc[:, 0].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ym4xWUUxaFvg",
        "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "c1=2.6676\n",
        "c2=7000\n",
        "c3=20000\n",
        "b3=1.06\n",
        "L = df.iloc[:, 3] + (c1 * df.iloc[:, 1] + b3 * df.iloc[:, 2] + c2 + c3*np.tanh(df.iloc[:,0]))\n",
        "L.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyEywnwaFvh"
      },
      "source": [
        "## Preprocessing the data into supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6V9dXqzdaFvh"
      },
      "outputs": [],
      "source": [
        "# split a sequence into samples\n",
        "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n_in, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n_out)\n",
        "    for i in range(0, n_out):\n",
        "      cols.append(df.shift(-i))\n",
        "      if i == 0:\n",
        "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "      else:\n",
        "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "       agg.dropna(inplace=True)\n",
        "    return agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrzSrT1HnyfH",
        "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     var1(t-175)  var1(t-174)  var1(t-173)  var1(t-172)  var1(t-171)  \\\n",
            "175     0.116134     0.159976     0.145809     0.145829     0.118201   \n",
            "176     0.159976     0.145809     0.145829     0.118201     0.102154   \n",
            "177     0.145809     0.145829     0.118201     0.102154     0.135091   \n",
            "178     0.145829     0.118201     0.102154     0.135091     0.075362   \n",
            "179     0.118201     0.102154     0.135091     0.075362     0.074492   \n",
            "\n",
            "     var1(t-170)  var1(t-169)  var1(t-168)  var1(t-167)  var1(t-166)  ...  \\\n",
            "175     0.102154     0.135091     0.075362     0.074492     0.214121  ...   \n",
            "176     0.135091     0.075362     0.074492     0.214121     0.218214  ...   \n",
            "177     0.075362     0.074492     0.214121     0.218214     0.122469  ...   \n",
            "178     0.074492     0.214121     0.218214     0.122469     0.119180  ...   \n",
            "179     0.214121     0.218214     0.122469     0.119180     0.030099  ...   \n",
            "\n",
            "     var3(t+47)  var4(t+47)  var1(t+48)  var2(t+48)  var3(t+48)  var4(t+48)  \\\n",
            "175   -0.036885    0.002002    0.116292    0.034651   -0.034883    0.002773   \n",
            "176   -0.034883    0.002773    0.043479   -0.000232   -0.032110    0.003410   \n",
            "177   -0.032110    0.003410    0.087054   -0.032342   -0.028700    0.003905   \n",
            "178   -0.028700    0.003905    0.057936   -0.061043   -0.024795    0.004257   \n",
            "179   -0.024795    0.004257    0.086868   -0.085838   -0.020539    0.004467   \n",
            "\n",
            "     var1(t+49)  var2(t+49)  var3(t+49)  var4(t+49)  \n",
            "175    0.043479   -0.000232   -0.032110    0.003410  \n",
            "176    0.087054   -0.032342   -0.028700    0.003905  \n",
            "177    0.057936   -0.061043   -0.024795    0.004257  \n",
            "178    0.086868   -0.085838   -0.020539    0.004467  \n",
            "179    0.028954   -0.106376   -0.016072    0.004541  \n",
            "\n",
            "[5 rows x 378 columns]\n",
            "Index(['var1(t-175)', 'var1(t-174)', 'var1(t-173)', 'var1(t-172)',\n",
            "       'var1(t-171)', 'var1(t-170)', 'var1(t-169)', 'var1(t-168)',\n",
            "       'var1(t-167)', 'var1(t-166)',\n",
            "       ...\n",
            "       'var3(t+47)', 'var4(t+47)', 'var1(t+48)', 'var2(t+48)', 'var3(t+48)',\n",
            "       'var4(t+48)', 'var1(t+49)', 'var2(t+49)', 'var3(t+49)', 'var4(t+49)'],\n",
            "      dtype='object', length=378)\n"
          ]
        }
      ],
      "source": [
        "data = Supervised(df.values, n_in = 175, n_out = 50)\n",
        "\n",
        "\n",
        "cols_to_drop = []\n",
        "for i in range(2, 176):\n",
        "    cols_to_drop.extend([f'var2(t-{i})', f'var3(t-{i})', f'var4(t-{i})'])\n",
        "\n",
        "data.drop(cols_to_drop, axis=1, inplace=True)\n",
        "\n",
        "print(data.head())\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AfPf60oy6Pe4"
      },
      "outputs": [],
      "source": [
        "train = np.array(data[0:len(data)-1])\n",
        "forecast = np.array(data.tail(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WSAafzI37KiT"
      },
      "outputs": [],
      "source": [
        "trainy = train[:,-150:]\n",
        "trainX = train[:,:-150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2SrOqVJA7f50"
      },
      "outputs": [],
      "source": [
        "forecasty = forecast[:,-150:]\n",
        "forecastX = forecast[:,:-150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qno_k8Nw7saY",
        "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1739, 1, 228) (1739, 150) (1, 1, 228)\n"
          ]
        }
      ],
      "source": [
        "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
        "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
        "print(trainX.shape, trainy.shape, forecastX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Jp2DvNuNFx",
        "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "22/22 [==============================] - 2s 25ms/step - loss: 9783521.0000 - val_loss: 9789967.0000\n",
            "Epoch 2/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9764423.0000 - val_loss: 9780332.0000\n",
            "Epoch 3/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9750199.0000 - val_loss: 9770617.0000\n",
            "Epoch 4/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9736830.0000 - val_loss: 9760915.0000\n",
            "Epoch 5/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9724325.0000 - val_loss: 9750838.0000\n",
            "Epoch 6/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9709067.0000 - val_loss: 9739128.0000\n",
            "Epoch 7/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9693918.0000 - val_loss: 9727058.0000\n",
            "Epoch 8/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9679594.0000 - val_loss: 9715240.0000\n",
            "Epoch 9/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9666056.0000 - val_loss: 9703840.0000\n",
            "Epoch 10/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9653015.0000 - val_loss: 9692614.0000\n",
            "Epoch 11/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9640297.0000 - val_loss: 9681482.0000\n",
            "Epoch 12/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9627807.0000 - val_loss: 9670418.0000\n",
            "Epoch 13/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9615486.0000 - val_loss: 9659406.0000\n",
            "Epoch 14/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9603304.0000 - val_loss: 9648434.0000\n",
            "Epoch 15/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9591230.0000 - val_loss: 9637498.0000\n",
            "Epoch 16/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9579250.0000 - val_loss: 9626589.0000\n",
            "Epoch 17/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9567349.0000 - val_loss: 9615703.0000\n",
            "Epoch 18/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9555517.0000 - val_loss: 9604839.0000\n",
            "Epoch 19/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9543744.0000 - val_loss: 9593993.0000\n",
            "Epoch 20/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9532028.0000 - val_loss: 9583163.0000\n",
            "Epoch 21/500\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 9520356.0000 - val_loss: 9572345.0000\n",
            "Epoch 22/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9508732.0000 - val_loss: 9561542.0000\n",
            "Epoch 23/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9497148.0000 - val_loss: 9550750.0000\n",
            "Epoch 24/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9485599.0000 - val_loss: 9539969.0000\n",
            "Epoch 25/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 9474085.0000 - val_loss: 9529197.0000\n",
            "Epoch 26/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 9462602.0000 - val_loss: 9518435.0000\n",
            "Epoch 27/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 9451150.0000 - val_loss: 9507681.0000\n",
            "Epoch 28/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 9439725.0000 - val_loss: 9496936.0000\n",
            "Epoch 29/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9428328.0000 - val_loss: 9486197.0000\n",
            "Epoch 30/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9416955.0000 - val_loss: 9475467.0000\n",
            "Epoch 31/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9405606.0000 - val_loss: 9464744.0000\n",
            "Epoch 32/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9394279.0000 - val_loss: 9454028.0000\n",
            "Epoch 33/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9382975.0000 - val_loss: 9443317.0000\n",
            "Epoch 34/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9371689.0000 - val_loss: 9432614.0000\n",
            "Epoch 35/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9360428.0000 - val_loss: 9421917.0000\n",
            "Epoch 36/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9349182.0000 - val_loss: 9411225.0000\n",
            "Epoch 37/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 9337955.0000 - val_loss: 9400541.0000\n",
            "Epoch 38/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9326747.0000 - val_loss: 9389862.0000\n",
            "Epoch 39/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9315556.0000 - val_loss: 9379190.0000\n",
            "Epoch 40/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9304382.0000 - val_loss: 9368521.0000\n",
            "Epoch 41/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9293225.0000 - val_loss: 9357859.0000\n",
            "Epoch 42/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9282084.0000 - val_loss: 9347204.0000\n",
            "Epoch 43/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9270957.0000 - val_loss: 9336552.0000\n",
            "Epoch 44/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9259846.0000 - val_loss: 9325908.0000\n",
            "Epoch 45/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9248750.0000 - val_loss: 9315268.0000\n",
            "Epoch 46/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9237668.0000 - val_loss: 9304634.0000\n",
            "Epoch 47/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9226600.0000 - val_loss: 9294006.0000\n",
            "Epoch 48/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9215547.0000 - val_loss: 9283382.0000\n",
            "Epoch 49/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9204506.0000 - val_loss: 9272766.0000\n",
            "Epoch 50/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 9193479.0000 - val_loss: 9262153.0000\n",
            "Epoch 51/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9182466.0000 - val_loss: 9251547.0000\n",
            "Epoch 52/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9171465.0000 - val_loss: 9240945.0000\n",
            "Epoch 53/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9160477.0000 - val_loss: 9230349.0000\n",
            "Epoch 54/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9149501.0000 - val_loss: 9219757.0000\n",
            "Epoch 55/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9138537.0000 - val_loss: 9209173.0000\n",
            "Epoch 56/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9127586.0000 - val_loss: 9198591.0000\n",
            "Epoch 57/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9116648.0000 - val_loss: 9188017.0000\n",
            "Epoch 58/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9105718.0000 - val_loss: 9177448.0000\n",
            "Epoch 59/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9094803.0000 - val_loss: 9166883.0000\n",
            "Epoch 60/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9083900.0000 - val_loss: 9156325.0000\n",
            "Epoch 61/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9073003.0000 - val_loss: 9145771.0000\n",
            "Epoch 62/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9062121.0000 - val_loss: 9135223.0000\n",
            "Epoch 63/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9051250.0000 - val_loss: 9124680.0000\n",
            "Epoch 64/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9040390.0000 - val_loss: 9114144.0000\n",
            "Epoch 65/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9029539.0000 - val_loss: 9103611.0000\n",
            "Epoch 66/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9018701.0000 - val_loss: 9093084.0000\n",
            "Epoch 67/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 9007873.0000 - val_loss: 9082563.0000\n",
            "Epoch 68/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8997055.0000 - val_loss: 9072046.0000\n",
            "Epoch 69/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8986246.0000 - val_loss: 9061536.0000\n",
            "Epoch 70/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8975450.0000 - val_loss: 9051031.0000\n",
            "Epoch 71/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8964661.0000 - val_loss: 9040530.0000\n",
            "Epoch 72/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8953885.0000 - val_loss: 9030036.0000\n",
            "Epoch 73/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8943118.0000 - val_loss: 9019546.0000\n",
            "Epoch 74/500\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8932359.0000 - val_loss: 9009063.0000\n",
            "Epoch 75/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8921613.0000 - val_loss: 8998584.0000\n",
            "Epoch 76/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8910875.0000 - val_loss: 8988111.0000\n",
            "Epoch 77/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8900148.0000 - val_loss: 8977643.0000\n",
            "Epoch 78/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8889429.0000 - val_loss: 8967181.0000\n",
            "Epoch 79/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8878720.0000 - val_loss: 8956723.0000\n",
            "Epoch 80/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8868021.0000 - val_loss: 8946272.0000\n",
            "Epoch 81/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8857331.0000 - val_loss: 8935826.0000\n",
            "Epoch 82/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8846650.0000 - val_loss: 8925386.0000\n",
            "Epoch 83/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8835977.0000 - val_loss: 8914950.0000\n",
            "Epoch 84/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8825316.0000 - val_loss: 8904520.0000\n",
            "Epoch 85/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8814662.0000 - val_loss: 8894095.0000\n",
            "Epoch 86/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8804018.0000 - val_loss: 8883675.0000\n",
            "Epoch 87/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8793382.0000 - val_loss: 8873262.0000\n",
            "Epoch 88/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 8782757.0000 - val_loss: 8862853.0000\n",
            "Epoch 89/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8772141.0000 - val_loss: 8852451.0000\n",
            "Epoch 90/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8761532.0000 - val_loss: 8842053.0000\n",
            "Epoch 91/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8750933.0000 - val_loss: 8831661.0000\n",
            "Epoch 92/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8740341.0000 - val_loss: 8821274.0000\n",
            "Epoch 93/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8729760.0000 - val_loss: 8810893.0000\n",
            "Epoch 94/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8719186.0000 - val_loss: 8800516.0000\n",
            "Epoch 95/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8708622.0000 - val_loss: 8790147.0000\n",
            "Epoch 96/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8698068.0000 - val_loss: 8779781.0000\n",
            "Epoch 97/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8687521.0000 - val_loss: 8769423.0000\n",
            "Epoch 98/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8676980.0000 - val_loss: 8759068.0000\n",
            "Epoch 99/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8666451.0000 - val_loss: 8748719.0000\n",
            "Epoch 100/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8655929.0000 - val_loss: 8738376.0000\n",
            "Epoch 101/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8645416.0000 - val_loss: 8728039.0000\n",
            "Epoch 102/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8634911.0000 - val_loss: 8717706.0000\n",
            "Epoch 103/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8624414.0000 - val_loss: 8707379.0000\n",
            "Epoch 104/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8613926.0000 - val_loss: 8697059.0000\n",
            "Epoch 105/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8603444.0000 - val_loss: 8686743.0000\n",
            "Epoch 106/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8592973.0000 - val_loss: 8676433.0000\n",
            "Epoch 107/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8582508.0000 - val_loss: 8666128.0000\n",
            "Epoch 108/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8572054.0000 - val_loss: 8655829.0000\n",
            "Epoch 109/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8561606.0000 - val_loss: 8645535.0000\n",
            "Epoch 110/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8551167.0000 - val_loss: 8635247.0000\n",
            "Epoch 111/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8540735.0000 - val_loss: 8624964.0000\n",
            "Epoch 112/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8530312.0000 - val_loss: 8614687.0000\n",
            "Epoch 113/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8519896.0000 - val_loss: 8604415.0000\n",
            "Epoch 114/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8509489.0000 - val_loss: 8594150.0000\n",
            "Epoch 115/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8499090.0000 - val_loss: 8583887.0000\n",
            "Epoch 116/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8488698.0000 - val_loss: 8573632.0000\n",
            "Epoch 117/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8478315.0000 - val_loss: 8563382.0000\n",
            "Epoch 118/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8467940.0000 - val_loss: 8553138.0000\n",
            "Epoch 119/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8457572.0000 - val_loss: 8542899.0000\n",
            "Epoch 120/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8447212.0000 - val_loss: 8532666.0000\n",
            "Epoch 121/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8436859.0000 - val_loss: 8522439.0000\n",
            "Epoch 122/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8426514.0000 - val_loss: 8512216.0000\n",
            "Epoch 123/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8416179.0000 - val_loss: 8502000.0000\n",
            "Epoch 124/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 8405850.0000 - val_loss: 8491789.0000\n",
            "Epoch 125/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8395529.0000 - val_loss: 8481582.0000\n",
            "Epoch 126/500\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 8385215.0000 - val_loss: 8471382.0000\n",
            "Epoch 127/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8374909.5000 - val_loss: 8461188.0000\n",
            "Epoch 128/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8364610.0000 - val_loss: 8450998.0000\n",
            "Epoch 129/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8354319.0000 - val_loss: 8440814.0000\n",
            "Epoch 130/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 8344037.0000 - val_loss: 8430637.0000\n",
            "Epoch 131/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8333762.0000 - val_loss: 8420464.0000\n",
            "Epoch 132/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8323494.0000 - val_loss: 8410297.0000\n",
            "Epoch 133/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8313233.0000 - val_loss: 8400135.0000\n",
            "Epoch 134/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8302980.5000 - val_loss: 8389980.0000\n",
            "Epoch 135/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8292735.5000 - val_loss: 8379829.5000\n",
            "Epoch 136/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8282497.5000 - val_loss: 8369684.5000\n",
            "Epoch 137/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8272267.5000 - val_loss: 8359545.5000\n",
            "Epoch 138/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8262043.5000 - val_loss: 8349412.0000\n",
            "Epoch 139/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8251828.0000 - val_loss: 8339284.0000\n",
            "Epoch 140/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 8241620.0000 - val_loss: 8329162.5000\n",
            "Epoch 141/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 8231418.5000 - val_loss: 8319044.5000\n",
            "Epoch 142/500\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 8221224.0000 - val_loss: 8308933.0000\n",
            "Epoch 143/500\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8211040.0000 - val_loss: 8298828.5000\n",
            "Epoch 144/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 8200861.0000 - val_loss: 8288727.5000\n",
            "Epoch 145/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8190689.0000 - val_loss: 8278633.0000\n",
            "Epoch 146/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8180524.5000 - val_loss: 8268544.5000\n",
            "Epoch 147/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8170370.0000 - val_loss: 8258460.5000\n",
            "Epoch 148/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8160219.0000 - val_loss: 8248384.0000\n",
            "Epoch 149/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8150077.0000 - val_loss: 8238311.0000\n",
            "Epoch 150/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8139942.5000 - val_loss: 8228245.5000\n",
            "Epoch 151/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8129813.5000 - val_loss: 8218184.0000\n",
            "Epoch 152/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8119693.5000 - val_loss: 8208129.5000\n",
            "Epoch 153/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8109580.0000 - val_loss: 8198079.5000\n",
            "Epoch 154/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8099474.0000 - val_loss: 8188035.0000\n",
            "Epoch 155/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8089376.0000 - val_loss: 8177996.5000\n",
            "Epoch 156/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8079283.5000 - val_loss: 8167964.5000\n",
            "Epoch 157/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 8069199.5000 - val_loss: 8157937.5000\n",
            "Epoch 158/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8059120.5000 - val_loss: 8147914.5000\n",
            "Epoch 159/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8049051.0000 - val_loss: 8137899.5000\n",
            "Epoch 160/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8038987.5000 - val_loss: 8127889.0000\n",
            "Epoch 161/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 8028932.0000 - val_loss: 8117884.5000\n",
            "Epoch 162/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8018883.0000 - val_loss: 8107884.0000\n",
            "Epoch 163/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 8008841.0000 - val_loss: 8097891.5000\n",
            "Epoch 164/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7998805.5000 - val_loss: 8087903.0000\n",
            "Epoch 165/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7988778.5000 - val_loss: 8077921.0000\n",
            "Epoch 166/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7978757.0000 - val_loss: 8067945.0000\n",
            "Epoch 167/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7968743.0000 - val_loss: 8057973.0000\n",
            "Epoch 168/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7958736.5000 - val_loss: 8048008.0000\n",
            "Epoch 169/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7948737.0000 - val_loss: 8038049.0000\n",
            "Epoch 170/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7938743.5000 - val_loss: 8028095.5000\n",
            "Epoch 171/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7928758.5000 - val_loss: 8018146.5000\n",
            "Epoch 172/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7918779.5000 - val_loss: 8008204.0000\n",
            "Epoch 173/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7908807.5000 - val_loss: 7998267.0000\n",
            "Epoch 174/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7898843.0000 - val_loss: 7988336.0000\n",
            "Epoch 175/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7888884.0000 - val_loss: 7978410.5000\n",
            "Epoch 176/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 7878934.5000 - val_loss: 7968490.5000\n",
            "Epoch 177/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7868990.0000 - val_loss: 7958576.5000\n",
            "Epoch 178/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7859053.0000 - val_loss: 7948668.5000\n",
            "Epoch 179/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7849123.5000 - val_loss: 7938766.0000\n",
            "Epoch 180/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7839199.0000 - val_loss: 7928869.0000\n",
            "Epoch 181/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7829283.0000 - val_loss: 7918978.0000\n",
            "Epoch 182/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7819374.5000 - val_loss: 7909092.0000\n",
            "Epoch 183/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7809471.0000 - val_loss: 7899212.0000\n",
            "Epoch 184/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7799574.5000 - val_loss: 7889336.5000\n",
            "Epoch 185/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7789686.5000 - val_loss: 7879469.0000\n",
            "Epoch 186/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7779803.5000 - val_loss: 7869605.5000\n",
            "Epoch 187/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7769928.5000 - val_loss: 7859749.5000\n",
            "Epoch 188/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7760061.0000 - val_loss: 7849898.5000\n",
            "Epoch 189/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7750199.5000 - val_loss: 7840052.0000\n",
            "Epoch 190/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7740347.0000 - val_loss: 7830213.0000\n",
            "Epoch 191/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7730499.0000 - val_loss: 7820379.0000\n",
            "Epoch 192/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7720656.5000 - val_loss: 7810549.5000\n",
            "Epoch 193/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7710821.5000 - val_loss: 7800727.0000\n",
            "Epoch 194/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7700994.0000 - val_loss: 7790909.0000\n",
            "Epoch 195/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7691173.5000 - val_loss: 7781098.0000\n",
            "Epoch 196/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7681359.0000 - val_loss: 7771292.5000\n",
            "Epoch 197/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7671552.5000 - val_loss: 7761493.5000\n",
            "Epoch 198/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7661753.5000 - val_loss: 7751700.0000\n",
            "Epoch 199/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7651959.5000 - val_loss: 7741912.5000\n",
            "Epoch 200/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7642174.0000 - val_loss: 7732130.0000\n",
            "Epoch 201/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7632394.5000 - val_loss: 7722352.5000\n",
            "Epoch 202/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7622620.0000 - val_loss: 7712581.0000\n",
            "Epoch 203/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7612854.0000 - val_loss: 7702815.5000\n",
            "Epoch 204/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7603093.5000 - val_loss: 7693056.0000\n",
            "Epoch 205/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7593340.0000 - val_loss: 7683301.5000\n",
            "Epoch 206/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7583593.0000 - val_loss: 7673553.0000\n",
            "Epoch 207/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7573853.5000 - val_loss: 7663811.5000\n",
            "Epoch 208/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7564121.5000 - val_loss: 7654075.5000\n",
            "Epoch 209/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7554396.0000 - val_loss: 7644344.5000\n",
            "Epoch 210/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 7544677.5000 - val_loss: 7634619.5000\n",
            "Epoch 211/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7534964.5000 - val_loss: 7624900.5000\n",
            "Epoch 212/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7525258.0000 - val_loss: 7615187.0000\n",
            "Epoch 213/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7515560.0000 - val_loss: 7605479.5000\n",
            "Epoch 214/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7505867.5000 - val_loss: 7595777.5000\n",
            "Epoch 215/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7496180.5000 - val_loss: 7586080.5000\n",
            "Epoch 216/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7486499.5000 - val_loss: 7576390.0000\n",
            "Epoch 217/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7476828.5000 - val_loss: 7566704.0000\n",
            "Epoch 218/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7467160.5000 - val_loss: 7557024.5000\n",
            "Epoch 219/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7457500.5000 - val_loss: 7547352.5000\n",
            "Epoch 220/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7447848.5000 - val_loss: 7537686.0000\n",
            "Epoch 221/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7438203.5000 - val_loss: 7528025.5000\n",
            "Epoch 222/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7428565.5000 - val_loss: 7518372.0000\n",
            "Epoch 223/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7418933.0000 - val_loss: 7508723.0000\n",
            "Epoch 224/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7409308.5000 - val_loss: 7499079.5000\n",
            "Epoch 225/500\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 7399688.5000 - val_loss: 7489442.0000\n",
            "Epoch 226/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 7390075.5000 - val_loss: 7479810.0000\n",
            "Epoch 227/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7380469.5000 - val_loss: 7470183.5000\n",
            "Epoch 228/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7370870.0000 - val_loss: 7460562.5000\n",
            "Epoch 229/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7361274.5000 - val_loss: 7450947.5000\n",
            "Epoch 230/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7351687.5000 - val_loss: 7441338.0000\n",
            "Epoch 231/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7342108.0000 - val_loss: 7431736.5000\n",
            "Epoch 232/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7332534.0000 - val_loss: 7422140.5000\n",
            "Epoch 233/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7322968.5000 - val_loss: 7412550.5000\n",
            "Epoch 234/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7313409.5000 - val_loss: 7402967.0000\n",
            "Epoch 235/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7303858.0000 - val_loss: 7393388.0000\n",
            "Epoch 236/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7294311.0000 - val_loss: 7383816.0000\n",
            "Epoch 237/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7284770.0000 - val_loss: 7374249.0000\n",
            "Epoch 238/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7275239.0000 - val_loss: 7364687.5000\n",
            "Epoch 239/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 7265710.0000 - val_loss: 7355133.0000\n",
            "Epoch 240/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7256191.5000 - val_loss: 7345583.0000\n",
            "Epoch 241/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7246675.0000 - val_loss: 7336039.0000\n",
            "Epoch 242/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7237169.0000 - val_loss: 7326501.0000\n",
            "Epoch 243/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7227665.0000 - val_loss: 7316968.5000\n",
            "Epoch 244/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7218173.0000 - val_loss: 7307442.0000\n",
            "Epoch 245/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7208683.0000 - val_loss: 7297921.5000\n",
            "Epoch 246/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7199202.0000 - val_loss: 7288407.0000\n",
            "Epoch 247/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7189728.0000 - val_loss: 7278901.0000\n",
            "Epoch 248/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7180261.0000 - val_loss: 7269399.5000\n",
            "Epoch 249/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7170800.5000 - val_loss: 7259903.5000\n",
            "Epoch 250/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7161346.5000 - val_loss: 7250413.5000\n",
            "Epoch 251/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7151898.5000 - val_loss: 7240930.0000\n",
            "Epoch 252/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7142458.0000 - val_loss: 7231451.0000\n",
            "Epoch 253/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 7133024.5000 - val_loss: 7221979.0000\n",
            "Epoch 254/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7123595.0000 - val_loss: 7212512.5000\n",
            "Epoch 255/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7114173.5000 - val_loss: 7203053.0000\n",
            "Epoch 256/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 7104757.0000 - val_loss: 7193598.0000\n",
            "Epoch 257/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7095347.5000 - val_loss: 7184149.5000\n",
            "Epoch 258/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7085944.5000 - val_loss: 7174706.0000\n",
            "Epoch 259/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 7076547.5000 - val_loss: 7165269.5000\n",
            "Epoch 260/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7067157.5000 - val_loss: 7155839.5000\n",
            "Epoch 261/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7057772.5000 - val_loss: 7146413.5000\n",
            "Epoch 262/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 7048396.5000 - val_loss: 7136994.5000\n",
            "Epoch 263/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7039027.5000 - val_loss: 7127583.5000\n",
            "Epoch 264/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7029664.5000 - val_loss: 7118178.5000\n",
            "Epoch 265/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 7020308.5000 - val_loss: 7108778.5000\n",
            "Epoch 266/500\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7010959.0000 - val_loss: 7099384.5000\n",
            "Epoch 267/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 7001615.0000 - val_loss: 7089997.0000\n",
            "Epoch 268/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6992277.5000 - val_loss: 7080615.5000\n",
            "Epoch 269/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6982948.5000 - val_loss: 7071238.5000\n",
            "Epoch 270/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6973626.0000 - val_loss: 7061869.5000\n",
            "Epoch 271/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6964307.0000 - val_loss: 7052506.5000\n",
            "Epoch 272/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6954996.0000 - val_loss: 7043148.5000\n",
            "Epoch 273/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6945691.0000 - val_loss: 7033796.5000\n",
            "Epoch 274/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6936393.5000 - val_loss: 7024450.0000\n",
            "Epoch 275/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6927101.0000 - val_loss: 7015109.0000\n",
            "Epoch 276/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6917814.0000 - val_loss: 7005774.0000\n",
            "Epoch 277/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6908534.0000 - val_loss: 6996446.0000\n",
            "Epoch 278/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6899260.5000 - val_loss: 6987122.0000\n",
            "Epoch 279/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6889994.0000 - val_loss: 6977806.0000\n",
            "Epoch 280/500\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6880734.5000 - val_loss: 6968496.5000\n",
            "Epoch 281/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6871481.5000 - val_loss: 6959194.5000\n",
            "Epoch 282/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6862236.5000 - val_loss: 6949897.5000\n",
            "Epoch 283/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6852997.5000 - val_loss: 6940607.5000\n",
            "Epoch 284/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6843765.0000 - val_loss: 6931322.0000\n",
            "Epoch 285/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 6834539.0000 - val_loss: 6922045.0000\n",
            "Epoch 286/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 6825318.5000 - val_loss: 6912772.5000\n",
            "Epoch 287/500\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6816107.0000 - val_loss: 6903506.5000\n",
            "Epoch 288/500\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6806900.0000 - val_loss: 6894245.5000\n",
            "Epoch 289/500\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 6797699.0000 - val_loss: 6884992.0000\n",
            "Epoch 290/500\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 6788504.0000 - val_loss: 6875743.0000\n",
            "Epoch 291/500\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6779316.0000 - val_loss: 6866499.5000\n",
            "Epoch 292/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 6770133.5000 - val_loss: 6857263.0000\n",
            "Epoch 293/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6760958.0000 - val_loss: 6848033.0000\n",
            "Epoch 294/500\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6751787.0000 - val_loss: 6838807.5000\n",
            "Epoch 295/500\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 6742623.5000 - val_loss: 6829588.5000\n",
            "Epoch 296/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6733468.5000 - val_loss: 6820376.5000\n",
            "Epoch 297/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 6724317.0000 - val_loss: 6811168.5000\n",
            "Epoch 298/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 6715172.0000 - val_loss: 6801968.5000\n",
            "Epoch 299/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6706036.0000 - val_loss: 6792777.0000\n",
            "Epoch 300/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6696907.0000 - val_loss: 6783591.0000\n",
            "Epoch 301/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6687785.0000 - val_loss: 6774411.0000\n",
            "Epoch 302/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6678670.0000 - val_loss: 6765239.0000\n",
            "Epoch 303/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6669560.0000 - val_loss: 6756071.5000\n",
            "Epoch 304/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6660456.5000 - val_loss: 6746910.0000\n",
            "Epoch 305/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6651360.5000 - val_loss: 6737755.0000\n",
            "Epoch 306/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6642269.0000 - val_loss: 6728605.5000\n",
            "Epoch 307/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 6633185.5000 - val_loss: 6719462.5000\n",
            "Epoch 308/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6624106.5000 - val_loss: 6710325.5000\n",
            "Epoch 309/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6615035.0000 - val_loss: 6701194.5000\n",
            "Epoch 310/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6605970.0000 - val_loss: 6692069.5000\n",
            "Epoch 311/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6596910.5000 - val_loss: 6682949.0000\n",
            "Epoch 312/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6587857.5000 - val_loss: 6673836.0000\n",
            "Epoch 313/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6578810.5000 - val_loss: 6664729.0000\n",
            "Epoch 314/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6569769.0000 - val_loss: 6655627.0000\n",
            "Epoch 315/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6560734.0000 - val_loss: 6646531.5000\n",
            "Epoch 316/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6551706.5000 - val_loss: 6637441.5000\n",
            "Epoch 317/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6542684.0000 - val_loss: 6628358.0000\n",
            "Epoch 318/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6533670.0000 - val_loss: 6619282.5000\n",
            "Epoch 319/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6524662.0000 - val_loss: 6610213.5000\n",
            "Epoch 320/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6515662.5000 - val_loss: 6601150.5000\n",
            "Epoch 321/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6506669.5000 - val_loss: 6592095.5000\n",
            "Epoch 322/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6497682.5000 - val_loss: 6583046.0000\n",
            "Epoch 323/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6488703.0000 - val_loss: 6574003.5000\n",
            "Epoch 324/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6479729.0000 - val_loss: 6564965.0000\n",
            "Epoch 325/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6470760.5000 - val_loss: 6555932.5000\n",
            "Epoch 326/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6461798.5000 - val_loss: 6546907.0000\n",
            "Epoch 327/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6452843.0000 - val_loss: 6537887.5000\n",
            "Epoch 328/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6443893.5000 - val_loss: 6528873.0000\n",
            "Epoch 329/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6434950.5000 - val_loss: 6519864.5000\n",
            "Epoch 330/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6426013.0000 - val_loss: 6510862.5000\n",
            "Epoch 331/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6417082.0000 - val_loss: 6501866.5000\n",
            "Epoch 332/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6408159.0000 - val_loss: 6492877.0000\n",
            "Epoch 333/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6399241.0000 - val_loss: 6483893.0000\n",
            "Epoch 334/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6390328.5000 - val_loss: 6474914.5000\n",
            "Epoch 335/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6381423.0000 - val_loss: 6465942.0000\n",
            "Epoch 336/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6372523.0000 - val_loss: 6456977.0000\n",
            "Epoch 337/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6363629.0000 - val_loss: 6448017.5000\n",
            "Epoch 338/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6354742.5000 - val_loss: 6439065.5000\n",
            "Epoch 339/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6345864.0000 - val_loss: 6430122.0000\n",
            "Epoch 340/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6336992.0000 - val_loss: 6421184.0000\n",
            "Epoch 341/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6328128.0000 - val_loss: 6412253.5000\n",
            "Epoch 342/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6319269.5000 - val_loss: 6403328.5000\n",
            "Epoch 343/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6310418.0000 - val_loss: 6394410.0000\n",
            "Epoch 344/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6301572.5000 - val_loss: 6385498.5000\n",
            "Epoch 345/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6292733.0000 - val_loss: 6376591.5000\n",
            "Epoch 346/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6283899.5000 - val_loss: 6367691.0000\n",
            "Epoch 347/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6275072.0000 - val_loss: 6358796.5000\n",
            "Epoch 348/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6266253.0000 - val_loss: 6349909.5000\n",
            "Epoch 349/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6257438.0000 - val_loss: 6341026.5000\n",
            "Epoch 350/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6248629.0000 - val_loss: 6332151.0000\n",
            "Epoch 351/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6239827.0000 - val_loss: 6323281.5000\n",
            "Epoch 352/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 6231030.5000 - val_loss: 6314417.5000\n",
            "Epoch 353/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6222240.5000 - val_loss: 6305559.5000\n",
            "Epoch 354/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6213458.5000 - val_loss: 6296707.0000\n",
            "Epoch 355/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6204679.5000 - val_loss: 6287861.5000\n",
            "Epoch 356/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6195909.0000 - val_loss: 6279022.5000\n",
            "Epoch 357/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6187143.5000 - val_loss: 6270189.5000\n",
            "Epoch 358/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6178385.5000 - val_loss: 6261363.5000\n",
            "Epoch 359/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6169633.0000 - val_loss: 6252545.5000\n",
            "Epoch 360/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6160889.5000 - val_loss: 6243734.0000\n",
            "Epoch 361/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6152153.0000 - val_loss: 6234929.5000\n",
            "Epoch 362/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6143422.5000 - val_loss: 6226130.5000\n",
            "Epoch 363/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6134698.0000 - val_loss: 6217338.0000\n",
            "Epoch 364/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6125979.5000 - val_loss: 6208550.5000\n",
            "Epoch 365/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6117266.5000 - val_loss: 6199769.0000\n",
            "Epoch 366/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6108559.5000 - val_loss: 6190993.5000\n",
            "Epoch 367/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6099859.5000 - val_loss: 6182224.0000\n",
            "Epoch 368/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6091164.5000 - val_loss: 6173460.0000\n",
            "Epoch 369/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6082475.5000 - val_loss: 6164704.5000\n",
            "Epoch 370/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6073797.0000 - val_loss: 6155957.5000\n",
            "Epoch 371/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6065126.0000 - val_loss: 6147218.5000\n",
            "Epoch 372/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6056461.5000 - val_loss: 6138484.0000\n",
            "Epoch 373/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6047803.5000 - val_loss: 6129758.0000\n",
            "Epoch 374/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 6039152.0000 - val_loss: 6121037.5000\n",
            "Epoch 375/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6030506.0000 - val_loss: 6112322.0000\n",
            "Epoch 376/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 6021867.0000 - val_loss: 6103614.0000\n",
            "Epoch 377/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6013233.5000 - val_loss: 6094911.5000\n",
            "Epoch 378/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 6004607.0000 - val_loss: 6086215.5000\n",
            "Epoch 379/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5995988.0000 - val_loss: 6077526.5000\n",
            "Epoch 380/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5987374.5000 - val_loss: 6068843.0000\n",
            "Epoch 381/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5978766.0000 - val_loss: 6060165.5000\n",
            "Epoch 382/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5970165.0000 - val_loss: 6051494.5000\n",
            "Epoch 383/500\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 5961569.5000 - val_loss: 6042830.0000\n",
            "Epoch 384/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5952980.0000 - val_loss: 6034171.5000\n",
            "Epoch 385/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5944396.5000 - val_loss: 6025518.5000\n",
            "Epoch 386/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5935820.5000 - val_loss: 6016872.5000\n",
            "Epoch 387/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5927249.5000 - val_loss: 6008232.5000\n",
            "Epoch 388/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5918684.5000 - val_loss: 5999598.0000\n",
            "Epoch 389/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5910127.5000 - val_loss: 5990971.0000\n",
            "Epoch 390/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5901575.0000 - val_loss: 5982349.0000\n",
            "Epoch 391/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5893029.5000 - val_loss: 5973734.5000\n",
            "Epoch 392/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5884489.5000 - val_loss: 5965126.0000\n",
            "Epoch 393/500\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5875956.5000 - val_loss: 5956522.5000\n",
            "Epoch 394/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5867429.5000 - val_loss: 5947927.0000\n",
            "Epoch 395/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5858908.5000 - val_loss: 5939336.0000\n",
            "Epoch 396/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5850393.0000 - val_loss: 5930752.0000\n",
            "Epoch 397/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5841885.5000 - val_loss: 5922174.0000\n",
            "Epoch 398/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5833382.0000 - val_loss: 5913603.0000\n",
            "Epoch 399/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5824886.0000 - val_loss: 5905037.0000\n",
            "Epoch 400/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5816396.0000 - val_loss: 5896479.5000\n",
            "Epoch 401/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5807911.5000 - val_loss: 5887928.5000\n",
            "Epoch 402/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5799434.5000 - val_loss: 5879383.0000\n",
            "Epoch 403/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5790963.5000 - val_loss: 5870843.0000\n",
            "Epoch 404/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5782497.5000 - val_loss: 5862309.5000\n",
            "Epoch 405/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5774037.5000 - val_loss: 5853783.0000\n",
            "Epoch 406/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5765586.0000 - val_loss: 5845263.5000\n",
            "Epoch 407/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5757138.0000 - val_loss: 5836749.0000\n",
            "Epoch 408/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5748697.5000 - val_loss: 5828241.5000\n",
            "Epoch 409/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5740263.5000 - val_loss: 5819740.0000\n",
            "Epoch 410/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5731835.5000 - val_loss: 5811246.5000\n",
            "Epoch 411/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5723419.5000 - val_loss: 5802766.0000\n",
            "Epoch 412/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5715012.0000 - val_loss: 5794290.5000\n",
            "Epoch 413/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5706611.0000 - val_loss: 5785822.0000\n",
            "Epoch 414/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5698214.5000 - val_loss: 5777359.5000\n",
            "Epoch 415/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5689826.0000 - val_loss: 5768904.0000\n",
            "Epoch 416/500\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5681443.5000 - val_loss: 5760454.0000\n",
            "Epoch 417/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5673067.0000 - val_loss: 5752010.5000\n",
            "Epoch 418/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5664696.5000 - val_loss: 5743574.0000\n",
            "Epoch 419/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5656332.5000 - val_loss: 5735143.0000\n",
            "Epoch 420/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5647975.0000 - val_loss: 5726718.5000\n",
            "Epoch 421/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5639623.0000 - val_loss: 5718300.5000\n",
            "Epoch 422/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5631276.5000 - val_loss: 5709889.5000\n",
            "Epoch 423/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5622937.5000 - val_loss: 5701483.5000\n",
            "Epoch 424/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5614604.5000 - val_loss: 5693084.0000\n",
            "Epoch 425/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5606277.0000 - val_loss: 5684692.0000\n",
            "Epoch 426/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5597956.0000 - val_loss: 5676304.0000\n",
            "Epoch 427/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5589641.0000 - val_loss: 5667923.5000\n",
            "Epoch 428/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 5581332.5000 - val_loss: 5659548.5000\n",
            "Epoch 429/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5573030.0000 - val_loss: 5651180.0000\n",
            "Epoch 430/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5564733.5000 - val_loss: 5642820.5000\n",
            "Epoch 431/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5556443.5000 - val_loss: 5634465.5000\n",
            "Epoch 432/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5548159.5000 - val_loss: 5626116.5000\n",
            "Epoch 433/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5539883.5000 - val_loss: 5617773.0000\n",
            "Epoch 434/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5531611.0000 - val_loss: 5609437.0000\n",
            "Epoch 435/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5523345.0000 - val_loss: 5601108.0000\n",
            "Epoch 436/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5515086.5000 - val_loss: 5592784.0000\n",
            "Epoch 437/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5506833.0000 - val_loss: 5584467.0000\n",
            "Epoch 438/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5498586.5000 - val_loss: 5576156.5000\n",
            "Epoch 439/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5490345.5000 - val_loss: 5567852.0000\n",
            "Epoch 440/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5482111.5000 - val_loss: 5559554.0000\n",
            "Epoch 441/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5473883.0000 - val_loss: 5551262.5000\n",
            "Epoch 442/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5465660.5000 - val_loss: 5542976.5000\n",
            "Epoch 443/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5457445.0000 - val_loss: 5534699.0000\n",
            "Epoch 444/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5449235.0000 - val_loss: 5526426.0000\n",
            "Epoch 445/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5441031.5000 - val_loss: 5518159.5000\n",
            "Epoch 446/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5432834.5000 - val_loss: 5509900.5000\n",
            "Epoch 447/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5424642.0000 - val_loss: 5501645.5000\n",
            "Epoch 448/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5416458.5000 - val_loss: 5493398.0000\n",
            "Epoch 449/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5408279.5000 - val_loss: 5485157.5000\n",
            "Epoch 450/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5400107.5000 - val_loss: 5476926.0000\n",
            "Epoch 451/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5391946.5000 - val_loss: 5468705.0000\n",
            "Epoch 452/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5383794.5000 - val_loss: 5460492.0000\n",
            "Epoch 453/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5375648.5000 - val_loss: 5452286.0000\n",
            "Epoch 454/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5367509.0000 - val_loss: 5444084.5000\n",
            "Epoch 455/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 5359374.0000 - val_loss: 5435890.0000\n",
            "Epoch 456/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5351247.5000 - val_loss: 5427701.5000\n",
            "Epoch 457/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5343125.5000 - val_loss: 5419520.5000\n",
            "Epoch 458/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5335011.0000 - val_loss: 5411345.5000\n",
            "Epoch 459/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5326902.0000 - val_loss: 5403176.0000\n",
            "Epoch 460/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5318799.0000 - val_loss: 5395013.0000\n",
            "Epoch 461/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5310702.0000 - val_loss: 5386857.0000\n",
            "Epoch 462/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5302612.0000 - val_loss: 5378708.0000\n",
            "Epoch 463/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5294526.5000 - val_loss: 5370565.0000\n",
            "Epoch 464/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5286448.0000 - val_loss: 5362428.5000\n",
            "Epoch 465/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5278376.5000 - val_loss: 5354298.0000\n",
            "Epoch 466/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5270311.0000 - val_loss: 5346174.5000\n",
            "Epoch 467/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5262250.0000 - val_loss: 5338056.0000\n",
            "Epoch 468/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5254197.0000 - val_loss: 5329944.5000\n",
            "Epoch 469/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5246150.0000 - val_loss: 5321839.0000\n",
            "Epoch 470/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5238109.0000 - val_loss: 5313742.0000\n",
            "Epoch 471/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5230073.0000 - val_loss: 5305649.5000\n",
            "Epoch 472/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5222044.5000 - val_loss: 5297562.5000\n",
            "Epoch 473/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5214021.5000 - val_loss: 5289482.5000\n",
            "Epoch 474/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5206005.0000 - val_loss: 5281409.5000\n",
            "Epoch 475/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5197994.5000 - val_loss: 5273342.0000\n",
            "Epoch 476/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5189990.0000 - val_loss: 5265280.5000\n",
            "Epoch 477/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5181993.0000 - val_loss: 5257226.5000\n",
            "Epoch 478/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 5174000.0000 - val_loss: 5249177.5000\n",
            "Epoch 479/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5166015.5000 - val_loss: 5241137.5000\n",
            "Epoch 480/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5158035.0000 - val_loss: 5233103.0000\n",
            "Epoch 481/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5150062.0000 - val_loss: 5225075.5000\n",
            "Epoch 482/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5142094.5000 - val_loss: 5217053.0000\n",
            "Epoch 483/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5134134.5000 - val_loss: 5209037.0000\n",
            "Epoch 484/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5126178.5000 - val_loss: 5201027.5000\n",
            "Epoch 485/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5118229.5000 - val_loss: 5193025.0000\n",
            "Epoch 486/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5110287.0000 - val_loss: 5185031.5000\n",
            "Epoch 487/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5102350.5000 - val_loss: 5177043.5000\n",
            "Epoch 488/500\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 5094420.0000 - val_loss: 5169062.5000\n",
            "Epoch 489/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 5086503.0000 - val_loss: 5161092.5000\n",
            "Epoch 490/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5078591.0000 - val_loss: 5153130.0000\n",
            "Epoch 491/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5070688.5000 - val_loss: 5145173.5000\n",
            "Epoch 492/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5062789.5000 - val_loss: 5137223.5000\n",
            "Epoch 493/500\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 5054898.5000 - val_loss: 5129279.5000\n",
            "Epoch 494/500\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 5047013.0000 - val_loss: 5121342.0000\n",
            "Epoch 495/500\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 5039132.5000 - val_loss: 5113409.0000\n",
            "Epoch 496/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 5031260.0000 - val_loss: 5105484.0000\n",
            "Epoch 497/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 5023393.0000 - val_loss: 5097564.5000\n",
            "Epoch 498/500\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 5015532.5000 - val_loss: 5089653.0000\n",
            "Epoch 499/500\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 5007677.5000 - val_loss: 5081747.5000\n",
            "Epoch 500/500\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4999829.5000 - val_loss: 5073848.0000\n"
          ]
        }
      ],
      "source": [
        "c1 = tf.Variable(2.6676, name=\"c1\", trainable=True, dtype=tf.float32)\n",
        "c2 = tf.Variable(7000, name=\"c2\", trainable=True, dtype=tf.float32)\n",
        "c3 = tf.Variable(20000, name=\"c3\", trainable=True, dtype=tf.float32)\n",
        "b3 = tf.Variable(1.06, name=\"b3\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "splitr = 0.8\n",
        "\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
        "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
        "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
        "    squared_difference3 = tf.square(\n",
        "        y_pred[:, 3] + (c1 * y_pred[:, 1] + b3 * y_pred[:, 2] + c2))\n",
        "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "model.add(Dense(30))\n",
        "model.compile(loss=loss_fn, optimizer='adam')\n",
        "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJL101rPyuoT",
        "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 588ms/step\n"
          ]
        }
      ],
      "source": [
        "forecast_without_mc = forecastX\n",
        "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
        "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9dQELcJ8wbp",
        "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1, 228)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forecastX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS2kyIKG1Kbr",
        "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 228)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forecast_without_mc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0u6VIzaDyuoT"
      },
      "outputs": [],
      "source": [
        "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
        "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUEcw0LX07oU",
        "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 258)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat_without_mc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "31OWVbSh_305"
      },
      "outputs": [],
      "source": [
        "fforecast = inv_yhat_without_mc[:,-150:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BlpGH2FOAiRF"
      },
      "outputs": [],
      "source": [
        "final_forecast = fforecast[:,0:149:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CXkgkj_LBk_t"
      },
      "outputs": [],
      "source": [
        "# code to replace all negative value with 0\n",
        "final_forecast[final_forecast<0] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[9.88122642e-01, 6.82768285e-01, 5.37486374e-01, 1.59527734e-01,\n",
              "        2.32272699e-01, 2.32263297e-01, 5.80550320e-02, 1.30492568e-01,\n",
              "        1.15947120e-01, 1.30350500e-01, 1.15803815e-01, 4.34205271e-02,\n",
              "        8.68431553e-02, 1.59279495e-01, 1.01467229e-01, 1.30542010e-01,\n",
              "        1.01338215e-01, 2.46393681e-01, 4.49649662e-01, 8.41311216e-01,\n",
              "        1.00137901e+00, 1.06023252e+00, 3.33948255e-01, 3.28982700e-03,\n",
              "        8.21864100e-03, 0.00000000e+00, 1.01321310e-01, 1.75536100e-03,\n",
              "        1.50761910e-02, 0.00000000e+00, 8.68426189e-02, 1.76133000e-04,\n",
              "        1.71493690e-02, 0.00000000e+00, 7.24165365e-02, 0.00000000e+00,\n",
              "        1.50379540e-02, 8.09951100e-03, 8.69115740e-02, 0.00000000e+00,\n",
              "        9.76083800e-04, 0.00000000e+00, 1.94958791e-01, 0.00000000e+00,\n",
              "        1.15028644e+00, 7.81622708e-01, 1.04415691e+00, 0.00000000e+00,\n",
              "        0.00000000e+00, 0.00000000e+00]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_set = np.array(training_set)\n",
        "test = np.array(test)\n",
        "final_forecast = np.array(final_forecast.squeeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5413697238704225\n",
            "0.45066697398651345\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
        "rsme = math.sqrt(MSE)\n",
        "print(rsme)  \n",
        "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
        "mae = MAE\n",
        "print(mae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
