{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCGKeZ2gyuoQ"
      },
      "source": [
        "_Importing Required Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-6LN-zXiLcM",
        "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)Note: you may need to restart the kernel to use updated packages.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
            "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
            "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install hampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "By_d9uXpaFvZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from hampel import hampel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyOjBMFayuoR"
      },
      "source": [
        "## Pretraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5QqIY_GyuoR"
      },
      "source": [
        "The `horton_intermittency.dat` feeds the model with the dynamics of the Horton Chaotics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9dV4a8yfyuoR"
      },
      "outputs": [],
      "source": [
        "data = np.genfromtxt('horton_intermittency.dat')\n",
        "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
        "training_set = training_set.iloc[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7easoxByuoR"
      },
      "source": [
        "## Computing the Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SnyolJTyuoR"
      },
      "source": [
        "_Calculating the value of_ $\\frac{dx}{dt}$, $\\frac{d^2x}{dt^2}$, _and_ $\\frac{d^3x}{dt^3}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmIbVfIvyuoR",
        "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "1       -0.000011\n",
            "2        0.003571\n",
            "3        0.005754\n",
            "4        0.006818\n",
            "5       -0.000807\n",
            "           ...   \n",
            "9996    -0.129763\n",
            "9997    -0.118735\n",
            "9998    -0.105414\n",
            "9999    -0.090338\n",
            "10000   -0.074048\n",
            "Name: 1, Length: 10000, dtype: float64\n",
            "2        0.003582\n",
            "3        0.002183\n",
            "4        0.001064\n",
            "5       -0.007625\n",
            "6       -0.006999\n",
            "           ...   \n",
            "9996     0.008219\n",
            "9997     0.011028\n",
            "9998     0.013321\n",
            "9999     0.015076\n",
            "10000    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n",
            "2        0.003582\n",
            "3        0.002183\n",
            "4        0.001064\n",
            "5       -0.007625\n",
            "6       -0.006999\n",
            "           ...   \n",
            "9996     0.008219\n",
            "9997     0.011028\n",
            "9998     0.013321\n",
            "9999     0.015076\n",
            "10000    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "t_diff = 1\n",
        "print(training_set.max())\n",
        "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
        "print(gradient_t)\n",
        "gradient_tt = (gradient_t.diff()/t_diff).iloc[1:] # d2x/dt2\n",
        "print(gradient_tt)\n",
        "gradient_ttt = (gradient_tt.diff()/t_diff).iloc[1:] # d3x/dt3\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2eVeeoxyuoS"
      },
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0J-NKyIEyuoS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       3.013502\n",
              "1       2.832119\n",
              "2       2.042342\n",
              "3       1.794970\n",
              "4       1.789537\n",
              "          ...   \n",
              "2010    0.092451\n",
              "2011    0.097335\n",
              "2012    0.105332\n",
              "2013    0.103997\n",
              "2014    0.105429\n",
              "Name: flux, Length: 2015, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"differential-protons-7-day.csv\")\n",
        "training_set = data.iloc[:, 1]\n",
        "training_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CbNUhJ74UqF",
        "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       3.013502\n",
              "1       2.832119\n",
              "2       2.042342\n",
              "3       1.794970\n",
              "4       1.789537\n",
              "          ...   \n",
              "1979    0.150448\n",
              "1980    0.142514\n",
              "1981    0.136499\n",
              "1982    0.135064\n",
              "1983    0.144762\n",
              "Name: flux, Length: 1984, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = training_set.tail(30)\n",
        "test\n",
        "training_set = training_set.head(1984) # (2013 - 30) + 1\n",
        "training_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0TwTcq0yuoS",
        "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      -0.000011\n",
            "1       0.003571\n",
            "2       0.005754\n",
            "3       0.006818\n",
            "4      -0.000807\n",
            "          ...   \n",
            "9995   -0.129763\n",
            "9996   -0.118735\n",
            "9997   -0.105414\n",
            "9998   -0.090338\n",
            "9999   -0.074048\n",
            "Name: 1, Length: 10000, dtype: float64\n",
            "0       0.003582\n",
            "1       0.002183\n",
            "2       0.001064\n",
            "3      -0.007625\n",
            "4      -0.006999\n",
            "          ...   \n",
            "9994    0.008219\n",
            "9995    0.011028\n",
            "9996    0.013321\n",
            "9997    0.015076\n",
            "9998    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n",
            "0      -0.001400\n",
            "1      -0.001118\n",
            "2      -0.008690\n",
            "3       0.000626\n",
            "4       0.000763\n",
            "          ...   \n",
            "9993    0.003290\n",
            "9994    0.002810\n",
            "9995    0.002293\n",
            "9996    0.001755\n",
            "9997    0.001214\n",
            "Name: 1, Length: 9998, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "training_set = training_set.reset_index(drop=True) # sets a list of integer ranging from 0 to length of training_set as index\n",
        "gradient_t = gradient_t.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_t as index\n",
        "gradient_tt = gradient_tt.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_tt as index\n",
        "gradient_ttt = gradient_ttt.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_ttt as index\n",
        "print(gradient_t)\n",
        "print(gradient_tt)\n",
        "print(gradient_ttt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O2biznZQyuoS"
      },
      "outputs": [],
      "source": [
        "df = pd.concat((training_set, gradient_t), axis=1) ##########[:-1]\n",
        "gradient_tt.columns = [\"grad_tt\"]\n",
        "df = pd.concat((df, gradient_tt), axis=1) ################[:-1]\n",
        "gradient_tt.columns = [\"grad_ttt\"]\n",
        "df = pd.concat((df, gradient_ttt), axis=1) ################[:-1]\n",
        "df.columns = ['y_t', 'grad_t', 'grad_tt', 'grad_ttt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sk_a5v3tyuoS",
        "outputId": "17563625-e550-45ae-faab-fafa353e44da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_t</th>\n",
              "      <th>grad_t</th>\n",
              "      <th>grad_tt</th>\n",
              "      <th>grad_ttt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.013502</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>0.003582</td>\n",
              "      <td>-0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.832119</td>\n",
              "      <td>0.003571</td>\n",
              "      <td>0.002183</td>\n",
              "      <td>-0.001118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.042342</td>\n",
              "      <td>0.005754</td>\n",
              "      <td>0.001064</td>\n",
              "      <td>-0.008690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.794970</td>\n",
              "      <td>0.006818</td>\n",
              "      <td>-0.007625</td>\n",
              "      <td>0.000626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.789537</td>\n",
              "      <td>-0.000807</td>\n",
              "      <td>-0.006999</td>\n",
              "      <td>0.000763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.129763</td>\n",
              "      <td>0.011028</td>\n",
              "      <td>0.002293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.118735</td>\n",
              "      <td>0.013321</td>\n",
              "      <td>0.001755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.105414</td>\n",
              "      <td>0.015076</td>\n",
              "      <td>0.001214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.090338</td>\n",
              "      <td>0.016290</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.074048</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           y_t    grad_t   grad_tt  grad_ttt\n",
              "0     3.013502 -0.000011  0.003582 -0.001400\n",
              "1     2.832119  0.003571  0.002183 -0.001118\n",
              "2     2.042342  0.005754  0.001064 -0.008690\n",
              "3     1.794970  0.006818 -0.007625  0.000626\n",
              "4     1.789537 -0.000807 -0.006999  0.000763\n",
              "...        ...       ...       ...       ...\n",
              "9995       NaN -0.129763  0.011028  0.002293\n",
              "9996       NaN -0.118735  0.013321  0.001755\n",
              "9997       NaN -0.105414  0.015076  0.001214\n",
              "9998       NaN -0.090338  0.016290       NaN\n",
              "9999       NaN -0.074048       NaN       NaN\n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df # DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5esyHu5aFvg"
      },
      "source": [
        "## Plot of the External Forcing from Chaotic Differential Equation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "hGnE43tOh-4p",
        "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.iloc[:, 0].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ym4xWUUxaFvg",
        "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "c1=2.6676\n",
        "c2=7000\n",
        "c3=20000\n",
        "b3=1.06\n",
        "L = df.iloc[:, 3] + (c1 * df.iloc[:, 1] + b3 * df.iloc[:, 2] + c2 + c3*np.tanh(df.iloc[:,0]))\n",
        "L.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyEywnwaFvh"
      },
      "source": [
        "## Preprocessing the data into supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6V9dXqzdaFvh"
      },
      "outputs": [],
      "source": [
        "# split a sequence into samples\n",
        "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n_in, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n_out)\n",
        "    for i in range(0, n_out):\n",
        "      cols.append(df.shift(-i))\n",
        "      if i == 0:\n",
        "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "      else:\n",
        "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "       agg.dropna(inplace=True)\n",
        "    return agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrzSrT1HnyfH",
        "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     var1(t-105)  var1(t-104)  var1(t-103)  var1(t-102)  var1(t-101)  \\\n",
            "105     3.013502     2.832119     2.042342     1.794970     1.789537   \n",
            "106     2.832119     2.042342     1.794970     1.789537     1.877289   \n",
            "107     2.042342     1.794970     1.789537     1.877289     1.983688   \n",
            "108     1.794970     1.789537     1.877289     1.983688     2.153054   \n",
            "109     1.789537     1.877289     1.983688     2.153054     2.331594   \n",
            "\n",
            "     var1(t-100)  var1(t-99)  var1(t-98)  var1(t-97)  var1(t-96)  ...  \\\n",
            "105     1.877289    1.983688    2.153054    2.331594    2.405767  ...   \n",
            "106     1.983688    2.153054    2.331594    2.405767    1.515924  ...   \n",
            "107     2.153054    2.331594    2.405767    1.515924    2.041262  ...   \n",
            "108     2.331594    2.405767    1.515924    2.041262    2.062020  ...   \n",
            "109     2.405767    1.515924    2.041262    2.062020    1.730290  ...   \n",
            "\n",
            "     var3(t+27)  var4(t+27)  var1(t+28)  var2(t+28)  var3(t+28)  var4(t+28)  \\\n",
            "105    0.006519   -0.004200    2.283268    0.138074    0.002319   -0.003929   \n",
            "106    0.002319   -0.003929    2.266654    0.140393   -0.001610   -0.003574   \n",
            "107   -0.001610   -0.003574    1.614438    0.138783   -0.005185   -0.003153   \n",
            "108   -0.005185   -0.003153    2.383587    0.133598   -0.008337   -0.002680   \n",
            "109   -0.008337   -0.002680    1.732917    0.125261   -0.011017   -0.002174   \n",
            "\n",
            "     var1(t+29)  var2(t+29)  var3(t+29)  var4(t+29)  \n",
            "105    2.266654    0.140393   -0.001610   -0.003574  \n",
            "106    1.614438    0.138783   -0.005185   -0.003153  \n",
            "107    2.383587    0.133598   -0.008337   -0.002680  \n",
            "108    1.732917    0.125261   -0.011017   -0.002174  \n",
            "109    2.341734    0.114243   -0.013191   -0.001649  \n",
            "\n",
            "[5 rows x 228 columns]\n",
            "Index(['var1(t-105)', 'var1(t-104)', 'var1(t-103)', 'var1(t-102)',\n",
            "       'var1(t-101)', 'var1(t-100)', 'var1(t-99)', 'var1(t-98)', 'var1(t-97)',\n",
            "       'var1(t-96)',\n",
            "       ...\n",
            "       'var3(t+27)', 'var4(t+27)', 'var1(t+28)', 'var2(t+28)', 'var3(t+28)',\n",
            "       'var4(t+28)', 'var1(t+29)', 'var2(t+29)', 'var3(t+29)', 'var4(t+29)'],\n",
            "      dtype='object', length=228)\n"
          ]
        }
      ],
      "source": [
        "data = Supervised(df.values, n_in = 105, n_out = 30)\n",
        "\n",
        "\n",
        "cols_to_drop = []\n",
        "for i in range(2, 106):\n",
        "    cols_to_drop.extend([f'var2(t-{i})', f'var3(t-{i})', f'var4(t-{i})'])\n",
        "\n",
        "data.drop(cols_to_drop, axis=1, inplace=True)\n",
        "\n",
        "print(data.head())\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AfPf60oy6Pe4"
      },
      "outputs": [],
      "source": [
        "train = np.array(data[0:len(data)-1])\n",
        "forecast = np.array(data.tail(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WSAafzI37KiT"
      },
      "outputs": [],
      "source": [
        "trainy = train[:,-90:]\n",
        "trainX = train[:,:-90]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2SrOqVJA7f50"
      },
      "outputs": [],
      "source": [
        "forecasty = forecast[:,-90:]\n",
        "forecastX = forecast[:,:-90]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qno_k8Nw7saY",
        "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1849, 1, 138) (1849, 90) (1, 1, 138)\n"
          ]
        }
      ],
      "source": [
        "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
        "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
        "print(trainX.shape, trainy.shape, forecastX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Jp2DvNuNFx",
        "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "24/24 [==============================] - 8s 63ms/step - loss: 9795680.0000 - val_loss: 9794702.0000\n",
            "Epoch 2/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9782955.0000 - val_loss: 9787386.0000\n",
            "Epoch 3/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 9767539.0000 - val_loss: 9776520.0000\n",
            "Epoch 4/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9749038.0000 - val_loss: 9762431.0000\n",
            "Epoch 5/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9730146.0000 - val_loss: 9746372.0000\n",
            "Epoch 6/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 9711975.0000 - val_loss: 9729122.0000\n",
            "Epoch 7/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 9693965.0000 - val_loss: 9711231.0000\n",
            "Epoch 8/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9676257.0000 - val_loss: 9693139.0000\n",
            "Epoch 9/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9658966.0000 - val_loss: 9675124.0000\n",
            "Epoch 10/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9642111.0000 - val_loss: 9657338.0000\n",
            "Epoch 11/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9625671.0000 - val_loss: 9639852.0000\n",
            "Epoch 12/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9609604.0000 - val_loss: 9622687.0000\n",
            "Epoch 13/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9593870.0000 - val_loss: 9605844.0000\n",
            "Epoch 14/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9578427.0000 - val_loss: 9589305.0000\n",
            "Epoch 15/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 9563240.0000 - val_loss: 9573056.0000\n",
            "Epoch 16/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9548279.0000 - val_loss: 9557074.0000\n",
            "Epoch 17/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9533518.0000 - val_loss: 9541340.0000\n",
            "Epoch 18/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9518936.0000 - val_loss: 9525833.0000\n",
            "Epoch 19/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9504515.0000 - val_loss: 9510537.0000\n",
            "Epoch 20/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9490238.0000 - val_loss: 9495436.0000\n",
            "Epoch 21/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 9476095.0000 - val_loss: 9480512.0000\n",
            "Epoch 22/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9462072.0000 - val_loss: 9465756.0000\n",
            "Epoch 23/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 9448159.0000 - val_loss: 9451153.0000\n",
            "Epoch 24/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9434349.0000 - val_loss: 9436694.0000\n",
            "Epoch 25/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 9420634.0000 - val_loss: 9422367.0000\n",
            "Epoch 26/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 9407008.0000 - val_loss: 9408165.0000\n",
            "Epoch 27/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 9393461.0000 - val_loss: 9394081.0000\n",
            "Epoch 28/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9379992.0000 - val_loss: 9380104.0000\n",
            "Epoch 29/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 9366596.0000 - val_loss: 9366230.0000\n",
            "Epoch 30/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9353267.0000 - val_loss: 9352453.0000\n",
            "Epoch 31/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9340004.0000 - val_loss: 9338767.0000\n",
            "Epoch 32/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9326800.0000 - val_loss: 9325166.0000\n",
            "Epoch 33/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9313655.0000 - val_loss: 9311647.0000\n",
            "Epoch 34/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 9300565.0000 - val_loss: 9298204.0000\n",
            "Epoch 35/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 9287526.0000 - val_loss: 9284834.0000\n",
            "Epoch 36/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 9274538.0000 - val_loss: 9271533.0000\n",
            "Epoch 37/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9261596.0000 - val_loss: 9258298.0000\n",
            "Epoch 38/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9248704.0000 - val_loss: 9245127.0000\n",
            "Epoch 39/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9235851.0000 - val_loss: 9232015.0000\n",
            "Epoch 40/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9223043.0000 - val_loss: 9218961.0000\n",
            "Epoch 41/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9210275.0000 - val_loss: 9205959.0000\n",
            "Epoch 42/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9197545.0000 - val_loss: 9193013.0000\n",
            "Epoch 43/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 9184855.0000 - val_loss: 9180115.0000\n",
            "Epoch 44/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9172199.0000 - val_loss: 9167266.0000\n",
            "Epoch 45/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9159580.0000 - val_loss: 9154463.0000\n",
            "Epoch 46/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9146995.0000 - val_loss: 9141705.0000\n",
            "Epoch 47/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9134442.0000 - val_loss: 9128989.0000\n",
            "Epoch 48/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9121922.0000 - val_loss: 9116316.0000\n",
            "Epoch 49/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9109432.0000 - val_loss: 9103683.0000\n",
            "Epoch 50/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 9096974.0000 - val_loss: 9091087.0000\n",
            "Epoch 51/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 9084543.0000 - val_loss: 9078529.0000\n",
            "Epoch 52/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9072142.0000 - val_loss: 9066006.0000\n",
            "Epoch 53/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9059769.0000 - val_loss: 9053518.0000\n",
            "Epoch 54/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9047423.0000 - val_loss: 9041065.0000\n",
            "Epoch 55/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9035104.0000 - val_loss: 9028645.0000\n",
            "Epoch 56/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 9022810.0000 - val_loss: 9016256.0000\n",
            "Epoch 57/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 9010541.0000 - val_loss: 9003897.0000\n",
            "Epoch 58/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8998298.0000 - val_loss: 8991570.0000\n",
            "Epoch 59/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 8986078.0000 - val_loss: 8979271.0000\n",
            "Epoch 60/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8973881.0000 - val_loss: 8967000.0000\n",
            "Epoch 61/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8961709.0000 - val_loss: 8954757.0000\n",
            "Epoch 62/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8949557.0000 - val_loss: 8942540.0000\n",
            "Epoch 63/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8937428.0000 - val_loss: 8930350.0000\n",
            "Epoch 64/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8925322.0000 - val_loss: 8918184.0000\n",
            "Epoch 65/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8913237.0000 - val_loss: 8906046.0000\n",
            "Epoch 66/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 8901172.0000 - val_loss: 8893929.0000\n",
            "Epoch 67/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8889128.0000 - val_loss: 8881838.0000\n",
            "Epoch 68/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 8877104.0000 - val_loss: 8869769.0000\n",
            "Epoch 69/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 8865099.0000 - val_loss: 8857725.0000\n",
            "Epoch 70/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8853114.0000 - val_loss: 8845701.0000\n",
            "Epoch 71/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 8841148.0000 - val_loss: 8833698.0000\n",
            "Epoch 72/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8829200.0000 - val_loss: 8821718.0000\n",
            "Epoch 73/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 8817273.0000 - val_loss: 8809759.0000\n",
            "Epoch 74/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8805361.0000 - val_loss: 8797820.0000\n",
            "Epoch 75/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8793469.0000 - val_loss: 8785901.0000\n",
            "Epoch 76/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8781593.0000 - val_loss: 8774001.0000\n",
            "Epoch 77/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8769736.0000 - val_loss: 8762122.0000\n",
            "Epoch 78/500\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 8757895.0000 - val_loss: 8750261.0000\n",
            "Epoch 79/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8746071.0000 - val_loss: 8738418.0000\n",
            "Epoch 80/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8734264.0000 - val_loss: 8726594.0000\n",
            "Epoch 81/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8722473.0000 - val_loss: 8714788.0000\n",
            "Epoch 82/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 8710698.0000 - val_loss: 8703001.0000\n",
            "Epoch 83/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8698939.0000 - val_loss: 8691229.0000\n",
            "Epoch 84/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 8687196.0000 - val_loss: 8679475.0000\n",
            "Epoch 85/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 8675468.0000 - val_loss: 8667739.0000\n",
            "Epoch 86/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8663757.0000 - val_loss: 8656017.0000\n",
            "Epoch 87/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8652060.0000 - val_loss: 8644313.0000\n",
            "Epoch 88/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8640378.0000 - val_loss: 8632626.0000\n",
            "Epoch 89/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8628711.0000 - val_loss: 8620954.0000\n",
            "Epoch 90/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8617058.0000 - val_loss: 8609298.0000\n",
            "Epoch 91/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8605419.0000 - val_loss: 8597657.0000\n",
            "Epoch 92/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 8593796.0000 - val_loss: 8586032.0000\n",
            "Epoch 93/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 8582185.0000 - val_loss: 8574420.0000\n",
            "Epoch 94/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8570591.0000 - val_loss: 8562825.0000\n",
            "Epoch 95/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8559009.0000 - val_loss: 8551244.0000\n",
            "Epoch 96/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 8547439.0000 - val_loss: 8539678.0000\n",
            "Epoch 97/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 8535885.0000 - val_loss: 8528125.0000\n",
            "Epoch 98/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 8524345.0000 - val_loss: 8516587.0000\n",
            "Epoch 99/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 8512817.0000 - val_loss: 8505062.0000\n",
            "Epoch 100/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8501300.0000 - val_loss: 8493551.0000\n",
            "Epoch 101/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8489799.0000 - val_loss: 8482055.0000\n",
            "Epoch 102/500\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 8478312.0000 - val_loss: 8470571.0000\n",
            "Epoch 103/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8466836.0000 - val_loss: 8459102.0000\n",
            "Epoch 104/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8455372.0000 - val_loss: 8447644.0000\n",
            "Epoch 105/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8443921.0000 - val_loss: 8436201.0000\n",
            "Epoch 106/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8432482.0000 - val_loss: 8424770.0000\n",
            "Epoch 107/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8421057.0000 - val_loss: 8413352.0000\n",
            "Epoch 108/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8409643.0000 - val_loss: 8401947.0000\n",
            "Epoch 109/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8398241.0000 - val_loss: 8390554.0000\n",
            "Epoch 110/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8386851.5000 - val_loss: 8379173.5000\n",
            "Epoch 111/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8375475.5000 - val_loss: 8367805.5000\n",
            "Epoch 112/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8364109.0000 - val_loss: 8356449.0000\n",
            "Epoch 113/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8352755.0000 - val_loss: 8345105.5000\n",
            "Epoch 114/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 8341412.5000 - val_loss: 8333773.5000\n",
            "Epoch 115/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8330083.5000 - val_loss: 8322454.0000\n",
            "Epoch 116/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8318764.0000 - val_loss: 8311146.5000\n",
            "Epoch 117/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8307456.0000 - val_loss: 8299850.0000\n",
            "Epoch 118/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8296159.5000 - val_loss: 8288564.5000\n",
            "Epoch 119/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8284876.5000 - val_loss: 8277291.5000\n",
            "Epoch 120/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8273601.5000 - val_loss: 8266029.5000\n",
            "Epoch 121/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8262338.0000 - val_loss: 8254779.5000\n",
            "Epoch 122/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8251086.5000 - val_loss: 8243539.5000\n",
            "Epoch 123/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 8239847.0000 - val_loss: 8232311.5000\n",
            "Epoch 124/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8228616.0000 - val_loss: 8221094.5000\n",
            "Epoch 125/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8217398.0000 - val_loss: 8209888.0000\n",
            "Epoch 126/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8206189.0000 - val_loss: 8198693.5000\n",
            "Epoch 127/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8194992.5000 - val_loss: 8187509.0000\n",
            "Epoch 128/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8183805.0000 - val_loss: 8176335.0000\n",
            "Epoch 129/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8172630.5000 - val_loss: 8165172.5000\n",
            "Epoch 130/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8161465.0000 - val_loss: 8154020.5000\n",
            "Epoch 131/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8150309.0000 - val_loss: 8142879.0000\n",
            "Epoch 132/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 8139164.5000 - val_loss: 8131748.0000\n",
            "Epoch 133/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8128031.5000 - val_loss: 8120627.0000\n",
            "Epoch 134/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 8116906.5000 - val_loss: 8109517.5000\n",
            "Epoch 135/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 8105793.5000 - val_loss: 8098417.5000\n",
            "Epoch 136/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8094689.0000 - val_loss: 8087327.0000\n",
            "Epoch 137/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8083597.0000 - val_loss: 8076248.0000\n",
            "Epoch 138/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8072513.5000 - val_loss: 8065179.0000\n",
            "Epoch 139/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8061439.5000 - val_loss: 8054119.0000\n",
            "Epoch 140/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 8050377.0000 - val_loss: 8043070.5000\n",
            "Epoch 141/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 8039323.0000 - val_loss: 8032030.5000\n",
            "Epoch 142/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 8028280.0000 - val_loss: 8021001.5000\n",
            "Epoch 143/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 8017245.5000 - val_loss: 8009982.5000\n",
            "Epoch 144/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 8006222.5000 - val_loss: 7998972.5000\n",
            "Epoch 145/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7995208.5000 - val_loss: 7987973.5000\n",
            "Epoch 146/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7984204.0000 - val_loss: 7976983.0000\n",
            "Epoch 147/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7973210.0000 - val_loss: 7966003.0000\n",
            "Epoch 148/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7962224.5000 - val_loss: 7955032.0000\n",
            "Epoch 149/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7951250.0000 - val_loss: 7944071.0000\n",
            "Epoch 150/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7940283.5000 - val_loss: 7933119.5000\n",
            "Epoch 151/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7929326.5000 - val_loss: 7922177.5000\n",
            "Epoch 152/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 7918381.5000 - val_loss: 7911245.0000\n",
            "Epoch 153/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 7907442.0000 - val_loss: 7900322.0000\n",
            "Epoch 154/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7896516.0000 - val_loss: 7889408.0000\n",
            "Epoch 155/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7885597.0000 - val_loss: 7878504.0000\n",
            "Epoch 156/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7874689.0000 - val_loss: 7867608.5000\n",
            "Epoch 157/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7863789.0000 - val_loss: 7856723.0000\n",
            "Epoch 158/500\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 7852898.0000 - val_loss: 7845846.5000\n",
            "Epoch 159/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7842015.5000 - val_loss: 7834979.5000\n",
            "Epoch 160/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 7831145.0000 - val_loss: 7824122.0000\n",
            "Epoch 161/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7820281.0000 - val_loss: 7813273.0000\n",
            "Epoch 162/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7809427.5000 - val_loss: 7802433.0000\n",
            "Epoch 163/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7798584.0000 - val_loss: 7791602.0000\n",
            "Epoch 164/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7787748.0000 - val_loss: 7780780.5000\n",
            "Epoch 165/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7776921.5000 - val_loss: 7769968.0000\n",
            "Epoch 166/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7766104.0000 - val_loss: 7759165.0000\n",
            "Epoch 167/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7755295.0000 - val_loss: 7748370.0000\n",
            "Epoch 168/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7744497.5000 - val_loss: 7737585.0000\n",
            "Epoch 169/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7733705.0000 - val_loss: 7726808.0000\n",
            "Epoch 170/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7722923.5000 - val_loss: 7716040.0000\n",
            "Epoch 171/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 7712152.0000 - val_loss: 7705281.0000\n",
            "Epoch 172/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7701387.0000 - val_loss: 7694531.0000\n",
            "Epoch 173/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 7690632.0000 - val_loss: 7683789.5000\n",
            "Epoch 174/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7679888.0000 - val_loss: 7673057.0000\n",
            "Epoch 175/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7669151.5000 - val_loss: 7662333.0000\n",
            "Epoch 176/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7658420.0000 - val_loss: 7651618.0000\n",
            "Epoch 177/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7647701.5000 - val_loss: 7640912.5000\n",
            "Epoch 178/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7636990.0000 - val_loss: 7630215.0000\n",
            "Epoch 179/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7626289.0000 - val_loss: 7619526.0000\n",
            "Epoch 180/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7615594.5000 - val_loss: 7608846.0000\n",
            "Epoch 181/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7604911.0000 - val_loss: 7598175.0000\n",
            "Epoch 182/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7594234.5000 - val_loss: 7587511.5000\n",
            "Epoch 183/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7583567.5000 - val_loss: 7576857.0000\n",
            "Epoch 184/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7572908.0000 - val_loss: 7566211.0000\n",
            "Epoch 185/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7562257.5000 - val_loss: 7555573.5000\n",
            "Epoch 186/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7551615.5000 - val_loss: 7544945.0000\n",
            "Epoch 187/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7540983.0000 - val_loss: 7534324.0000\n",
            "Epoch 188/500\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 7530359.0000 - val_loss: 7523712.5000\n",
            "Epoch 189/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7519743.0000 - val_loss: 7513109.5000\n",
            "Epoch 190/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7509135.5000 - val_loss: 7502514.5000\n",
            "Epoch 191/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7498536.5000 - val_loss: 7491928.5000\n",
            "Epoch 192/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 7487945.5000 - val_loss: 7481350.0000\n",
            "Epoch 193/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 7477363.0000 - val_loss: 7470781.5000\n",
            "Epoch 194/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 7466791.5000 - val_loss: 7460219.0000\n",
            "Epoch 195/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7456226.5000 - val_loss: 7449667.0000\n",
            "Epoch 196/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7445669.0000 - val_loss: 7439122.0000\n",
            "Epoch 197/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7435119.5000 - val_loss: 7428587.0000\n",
            "Epoch 198/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7424580.0000 - val_loss: 7418059.5000\n",
            "Epoch 199/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7414048.5000 - val_loss: 7407540.0000\n",
            "Epoch 200/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 7403526.0000 - val_loss: 7397028.0000\n",
            "Epoch 201/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7393010.5000 - val_loss: 7386526.0000\n",
            "Epoch 202/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7382504.0000 - val_loss: 7376030.5000\n",
            "Epoch 203/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7372006.0000 - val_loss: 7365545.0000\n",
            "Epoch 204/500\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 7361516.5000 - val_loss: 7355067.0000\n",
            "Epoch 205/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7351034.5000 - val_loss: 7344596.5000\n",
            "Epoch 206/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 7340562.5000 - val_loss: 7334135.5000\n",
            "Epoch 207/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 7330096.0000 - val_loss: 7323682.0000\n",
            "Epoch 208/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 7319640.0000 - val_loss: 7313237.0000\n",
            "Epoch 209/500\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 7309191.5000 - val_loss: 7302800.0000\n",
            "Epoch 210/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 7298752.0000 - val_loss: 7292370.5000\n",
            "Epoch 211/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7288319.5000 - val_loss: 7281951.0000\n",
            "Epoch 212/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7277896.0000 - val_loss: 7271538.0000\n",
            "Epoch 213/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 7267480.5000 - val_loss: 7261133.5000\n",
            "Epoch 214/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 7257072.0000 - val_loss: 7250736.5000\n",
            "Epoch 215/500\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 7246674.0000 - val_loss: 7240350.0000\n",
            "Epoch 216/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 7236281.0000 - val_loss: 7229969.5000\n",
            "Epoch 217/500\n",
            "24/24 [==============================] - 1s 34ms/step - loss: 7225900.0000 - val_loss: 7219598.0000\n",
            "Epoch 218/500\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 7215523.5000 - val_loss: 7209233.5000\n",
            "Epoch 219/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 7205157.0000 - val_loss: 7198878.0000\n",
            "Epoch 220/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 7194798.5000 - val_loss: 7188530.5000\n",
            "Epoch 221/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7184448.5000 - val_loss: 7178190.0000\n",
            "Epoch 222/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 7174106.0000 - val_loss: 7167859.0000\n",
            "Epoch 223/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 7163771.0000 - val_loss: 7157536.0000\n",
            "Epoch 224/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 7153446.0000 - val_loss: 7147220.5000\n",
            "Epoch 225/500\n",
            "24/24 [==============================] - 1s 32ms/step - loss: 7143127.5000 - val_loss: 7136912.5000\n",
            "Epoch 226/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 7132817.0000 - val_loss: 7126614.0000\n",
            "Epoch 227/500\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 7122516.0000 - val_loss: 7116322.0000\n",
            "Epoch 228/500\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 7112222.0000 - val_loss: 7106039.0000\n",
            "Epoch 229/500\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 7101936.5000 - val_loss: 7095763.5000\n",
            "Epoch 230/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 7091657.5000 - val_loss: 7085496.0000\n",
            "Epoch 231/500\n",
            "24/24 [==============================] - 1s 36ms/step - loss: 7081389.5000 - val_loss: 7075236.5000\n",
            "Epoch 232/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 7071128.0000 - val_loss: 7064985.5000\n",
            "Epoch 233/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 7060873.5000 - val_loss: 7054742.0000\n",
            "Epoch 234/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 7050627.5000 - val_loss: 7044506.5000\n",
            "Epoch 235/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 7040390.0000 - val_loss: 7034278.0000\n",
            "Epoch 236/500\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 7030161.0000 - val_loss: 7024057.5000\n",
            "Epoch 237/500\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 7019938.0000 - val_loss: 7013848.0000\n",
            "Epoch 238/500\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 7009725.0000 - val_loss: 7003643.0000\n",
            "Epoch 239/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 6999518.5000 - val_loss: 6993447.5000\n",
            "Epoch 240/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6989322.0000 - val_loss: 6983259.5000\n",
            "Epoch 241/500\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 6979132.0000 - val_loss: 6973080.0000\n",
            "Epoch 242/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6968950.5000 - val_loss: 6962908.0000\n",
            "Epoch 243/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6958776.5000 - val_loss: 6952742.5000\n",
            "Epoch 244/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6948610.5000 - val_loss: 6942587.0000\n",
            "Epoch 245/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 6938451.5000 - val_loss: 6932438.5000\n",
            "Epoch 246/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6928301.5000 - val_loss: 6922298.0000\n",
            "Epoch 247/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6918160.0000 - val_loss: 6912164.5000\n",
            "Epoch 248/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6908025.0000 - val_loss: 6902040.0000\n",
            "Epoch 249/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6897898.5000 - val_loss: 6891923.5000\n",
            "Epoch 250/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6887780.5000 - val_loss: 6881814.0000\n",
            "Epoch 251/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 6877670.0000 - val_loss: 6871713.0000\n",
            "Epoch 252/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6867568.0000 - val_loss: 6861620.0000\n",
            "Epoch 253/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6857474.0000 - val_loss: 6851535.0000\n",
            "Epoch 254/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6847387.0000 - val_loss: 6841457.0000\n",
            "Epoch 255/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 6837309.0000 - val_loss: 6831387.5000\n",
            "Epoch 256/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 6827237.0000 - val_loss: 6821325.0000\n",
            "Epoch 257/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 6817174.5000 - val_loss: 6811271.0000\n",
            "Epoch 258/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 6807118.5000 - val_loss: 6801224.5000\n",
            "Epoch 259/500\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 6797071.0000 - val_loss: 6791185.5000\n",
            "Epoch 260/500\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 6787030.5000 - val_loss: 6781155.0000\n",
            "Epoch 261/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 6777000.0000 - val_loss: 6771132.0000\n",
            "Epoch 262/500\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 6766975.0000 - val_loss: 6761117.0000\n",
            "Epoch 263/500\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 6756958.5000 - val_loss: 6751109.0000\n",
            "Epoch 264/500\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 6746950.0000 - val_loss: 6741110.5000\n",
            "Epoch 265/500\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 6736950.5000 - val_loss: 6731118.5000\n",
            "Epoch 266/500\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 6726959.5000 - val_loss: 6721134.5000\n",
            "Epoch 267/500\n",
            "24/24 [==============================] - 1s 29ms/step - loss: 6716972.0000 - val_loss: 6711158.5000\n",
            "Epoch 268/500\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 6706997.0000 - val_loss: 6701191.0000\n",
            "Epoch 269/500\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 6697028.5000 - val_loss: 6691230.5000\n",
            "Epoch 270/500\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 6687067.5000 - val_loss: 6681277.5000\n",
            "Epoch 271/500\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 6677113.5000 - val_loss: 6671333.0000\n",
            "Epoch 272/500\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 6667168.0000 - val_loss: 6661396.0000\n",
            "Epoch 273/500\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 6657231.0000 - val_loss: 6651466.5000\n",
            "Epoch 274/500\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 6647300.5000 - val_loss: 6641544.5000\n",
            "Epoch 275/500\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 6637379.0000 - val_loss: 6631630.0000\n",
            "Epoch 276/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 6627463.5000 - val_loss: 6621723.0000\n",
            "Epoch 277/500\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 6617556.5000 - val_loss: 6611825.0000\n",
            "Epoch 278/500\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 6607658.0000 - val_loss: 6601934.0000\n",
            "Epoch 279/500\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 6597766.5000 - val_loss: 6592051.0000\n",
            "Epoch 280/500\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 6587883.5000 - val_loss: 6582176.0000\n",
            "Epoch 281/500\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 6578008.5000 - val_loss: 6572309.0000\n",
            "Epoch 282/500\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 6568140.0000 - val_loss: 6562449.5000\n",
            "Epoch 283/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 6558280.5000 - val_loss: 6552597.5000\n",
            "Epoch 284/500\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 6548429.5000 - val_loss: 6542754.0000\n",
            "Epoch 285/500\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 6538585.0000 - val_loss: 6532917.5000\n",
            "Epoch 286/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6528750.0000 - val_loss: 6523089.0000\n",
            "Epoch 287/500\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 6518920.5000 - val_loss: 6513268.0000\n",
            "Epoch 288/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6509100.0000 - val_loss: 6503455.0000\n",
            "Epoch 289/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6499286.0000 - val_loss: 6493649.0000\n",
            "Epoch 290/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6489479.0000 - val_loss: 6483850.5000\n",
            "Epoch 291/500\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 6479682.5000 - val_loss: 6474059.5000\n",
            "Epoch 292/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6469891.5000 - val_loss: 6464276.0000\n",
            "Epoch 293/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6460107.0000 - val_loss: 6454501.0000\n",
            "Epoch 294/500\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 6450333.0000 - val_loss: 6444735.0000\n",
            "Epoch 295/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6440566.0000 - val_loss: 6434975.0000\n",
            "Epoch 296/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 6430807.0000 - val_loss: 6425223.5000\n",
            "Epoch 297/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6421056.0000 - val_loss: 6415480.5000\n",
            "Epoch 298/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6411313.0000 - val_loss: 6405744.0000\n",
            "Epoch 299/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6401578.0000 - val_loss: 6396017.0000\n",
            "Epoch 300/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6391850.0000 - val_loss: 6386296.5000\n",
            "Epoch 301/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6382131.0000 - val_loss: 6376583.5000\n",
            "Epoch 302/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6372418.5000 - val_loss: 6366878.5000\n",
            "Epoch 303/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6362713.5000 - val_loss: 6357181.5000\n",
            "Epoch 304/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6353017.0000 - val_loss: 6347491.0000\n",
            "Epoch 305/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6343327.5000 - val_loss: 6337808.5000\n",
            "Epoch 306/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6333644.0000 - val_loss: 6328133.0000\n",
            "Epoch 307/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6323970.0000 - val_loss: 6318465.5000\n",
            "Epoch 308/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 6314302.0000 - val_loss: 6308805.0000\n",
            "Epoch 309/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6304642.0000 - val_loss: 6299152.5000\n",
            "Epoch 310/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6294990.5000 - val_loss: 6289508.5000\n",
            "Epoch 311/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6285346.5000 - val_loss: 6279872.5000\n",
            "Epoch 312/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6275712.5000 - val_loss: 6270244.0000\n",
            "Epoch 313/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6266084.5000 - val_loss: 6260624.0000\n",
            "Epoch 314/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6256465.0000 - val_loss: 6251011.5000\n",
            "Epoch 315/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6246854.0000 - val_loss: 6241406.0000\n",
            "Epoch 316/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6237250.0000 - val_loss: 6231809.5000\n",
            "Epoch 317/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6227653.5000 - val_loss: 6222220.0000\n",
            "Epoch 318/500\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 6218065.0000 - val_loss: 6212638.5000\n",
            "Epoch 319/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6208483.5000 - val_loss: 6203063.5000\n",
            "Epoch 320/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6198910.5000 - val_loss: 6193496.0000\n",
            "Epoch 321/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6189344.0000 - val_loss: 6183936.0000\n",
            "Epoch 322/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6179784.5000 - val_loss: 6174383.5000\n",
            "Epoch 323/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6170233.0000 - val_loss: 6164839.0000\n",
            "Epoch 324/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 6160688.5000 - val_loss: 6155301.5000\n",
            "Epoch 325/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6151153.0000 - val_loss: 6145771.0000\n",
            "Epoch 326/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6141623.0000 - val_loss: 6136249.5000\n",
            "Epoch 327/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6132102.5000 - val_loss: 6126734.5000\n",
            "Epoch 328/500\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 6122589.0000 - val_loss: 6117228.0000\n",
            "Epoch 329/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 6113083.5000 - val_loss: 6107729.0000\n",
            "Epoch 330/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6103585.5000 - val_loss: 6098237.5000\n",
            "Epoch 331/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6094094.5000 - val_loss: 6088753.0000\n",
            "Epoch 332/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6084611.5000 - val_loss: 6079276.5000\n",
            "Epoch 333/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6075135.0000 - val_loss: 6069805.5000\n",
            "Epoch 334/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 6065667.0000 - val_loss: 6060344.5000\n",
            "Epoch 335/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6056206.0000 - val_loss: 6050889.5000\n",
            "Epoch 336/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6046752.5000 - val_loss: 6041443.0000\n",
            "Epoch 337/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6037309.5000 - val_loss: 6032006.0000\n",
            "Epoch 338/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 6027873.5000 - val_loss: 6022578.0000\n",
            "Epoch 339/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 6018447.0000 - val_loss: 6013158.5000\n",
            "Epoch 340/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 6009029.5000 - val_loss: 6003746.5000\n",
            "Epoch 341/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5999620.0000 - val_loss: 5994344.0000\n",
            "Epoch 342/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5990216.5000 - val_loss: 5984947.0000\n",
            "Epoch 343/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5980822.0000 - val_loss: 5975559.0000\n",
            "Epoch 344/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5971436.5000 - val_loss: 5966179.0000\n",
            "Epoch 345/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5962056.0000 - val_loss: 5956804.5000\n",
            "Epoch 346/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5952684.5000 - val_loss: 5947439.0000\n",
            "Epoch 347/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5943319.5000 - val_loss: 5938080.5000\n",
            "Epoch 348/500\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 5933962.5000 - val_loss: 5928729.0000\n",
            "Epoch 349/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5924612.5000 - val_loss: 5919385.5000\n",
            "Epoch 350/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5915270.0000 - val_loss: 5910048.5000\n",
            "Epoch 351/500\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 5905935.5000 - val_loss: 5900719.0000\n",
            "Epoch 352/500\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 5896607.5000 - val_loss: 5891398.5000\n",
            "Epoch 353/500\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 5887287.0000 - val_loss: 5882083.0000\n",
            "Epoch 354/500\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 5877974.5000 - val_loss: 5872776.5000\n",
            "Epoch 355/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5868668.5000 - val_loss: 5863476.5000\n",
            "Epoch 356/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5859370.0000 - val_loss: 5854184.0000\n",
            "Epoch 357/500\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 5850080.0000 - val_loss: 5844899.5000\n",
            "Epoch 358/500\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 5840797.0000 - val_loss: 5835621.5000\n",
            "Epoch 359/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5831521.0000 - val_loss: 5826351.0000\n",
            "Epoch 360/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5822252.0000 - val_loss: 5817088.5000\n",
            "Epoch 361/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5812991.0000 - val_loss: 5807834.0000\n",
            "Epoch 362/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5803737.5000 - val_loss: 5798585.0000\n",
            "Epoch 363/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5794490.0000 - val_loss: 5789344.5000\n",
            "Epoch 364/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5785251.5000 - val_loss: 5780111.0000\n",
            "Epoch 365/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5776018.5000 - val_loss: 5770885.0000\n",
            "Epoch 366/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 5766796.0000 - val_loss: 5761667.0000\n",
            "Epoch 367/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5757578.0000 - val_loss: 5752455.0000\n",
            "Epoch 368/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5748369.0000 - val_loss: 5743250.5000\n",
            "Epoch 369/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5739167.0000 - val_loss: 5734055.0000\n",
            "Epoch 370/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5729972.5000 - val_loss: 5724865.5000\n",
            "Epoch 371/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5720786.0000 - val_loss: 5715684.5000\n",
            "Epoch 372/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5711607.5000 - val_loss: 5706513.5000\n",
            "Epoch 373/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5702439.5000 - val_loss: 5697354.0000\n",
            "Epoch 374/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5693282.0000 - val_loss: 5688201.0000\n",
            "Epoch 375/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5684133.0000 - val_loss: 5679057.5000\n",
            "Epoch 376/500\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 5674991.5000 - val_loss: 5669922.0000\n",
            "Epoch 377/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5665856.0000 - val_loss: 5660792.5000\n",
            "Epoch 378/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5656730.5000 - val_loss: 5651672.0000\n",
            "Epoch 379/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5647611.0000 - val_loss: 5642558.0000\n",
            "Epoch 380/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5638499.0000 - val_loss: 5633451.5000\n",
            "Epoch 381/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5629394.0000 - val_loss: 5624353.0000\n",
            "Epoch 382/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5620297.0000 - val_loss: 5615260.5000\n",
            "Epoch 383/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5611207.5000 - val_loss: 5606176.5000\n",
            "Epoch 384/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 5602125.5000 - val_loss: 5597099.0000\n",
            "Epoch 385/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 5593050.0000 - val_loss: 5588029.5000\n",
            "Epoch 386/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5583982.0000 - val_loss: 5578967.0000\n",
            "Epoch 387/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5574922.0000 - val_loss: 5569912.0000\n",
            "Epoch 388/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5565869.5000 - val_loss: 5560864.5000\n",
            "Epoch 389/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 5556823.0000 - val_loss: 5551824.5000\n",
            "Epoch 390/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5547786.0000 - val_loss: 5542791.5000\n",
            "Epoch 391/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5538753.5000 - val_loss: 5533765.0000\n",
            "Epoch 392/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5529731.0000 - val_loss: 5524747.0000\n",
            "Epoch 393/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5520715.0000 - val_loss: 5515736.0000\n",
            "Epoch 394/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5511706.0000 - val_loss: 5506733.5000\n",
            "Epoch 395/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5502704.0000 - val_loss: 5497736.5000\n",
            "Epoch 396/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5493710.5000 - val_loss: 5488748.0000\n",
            "Epoch 397/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5484723.5000 - val_loss: 5479766.0000\n",
            "Epoch 398/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5475745.0000 - val_loss: 5470792.5000\n",
            "Epoch 399/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5466772.5000 - val_loss: 5461826.0000\n",
            "Epoch 400/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5457808.0000 - val_loss: 5452866.0000\n",
            "Epoch 401/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5448851.0000 - val_loss: 5443914.0000\n",
            "Epoch 402/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5439901.5000 - val_loss: 5434969.5000\n",
            "Epoch 403/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5430959.0000 - val_loss: 5426031.5000\n",
            "Epoch 404/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5422024.5000 - val_loss: 5417102.5000\n",
            "Epoch 405/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5413095.0000 - val_loss: 5408179.0000\n",
            "Epoch 406/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5404175.5000 - val_loss: 5399264.5000\n",
            "Epoch 407/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 5395263.0000 - val_loss: 5390357.5000\n",
            "Epoch 408/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5386360.0000 - val_loss: 5381462.5000\n",
            "Epoch 409/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 5377468.5000 - val_loss: 5372576.5000\n",
            "Epoch 410/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5368586.5000 - val_loss: 5363700.0000\n",
            "Epoch 411/500\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 5359711.5000 - val_loss: 5354830.0000\n",
            "Epoch 412/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5350844.5000 - val_loss: 5345967.0000\n",
            "Epoch 413/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5341983.5000 - val_loss: 5337113.0000\n",
            "Epoch 414/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5333131.5000 - val_loss: 5328264.5000\n",
            "Epoch 415/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5324286.0000 - val_loss: 5319424.0000\n",
            "Epoch 416/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5315449.5000 - val_loss: 5310591.5000\n",
            "Epoch 417/500\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 5306616.5000 - val_loss: 5301765.5000\n",
            "Epoch 418/500\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 5297794.5000 - val_loss: 5292947.0000\n",
            "Epoch 419/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5288978.5000 - val_loss: 5284136.5000\n",
            "Epoch 420/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5280170.0000 - val_loss: 5275332.5000\n",
            "Epoch 421/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5271368.0000 - val_loss: 5266536.5000\n",
            "Epoch 422/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 5262575.0000 - val_loss: 5257747.5000\n",
            "Epoch 423/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5253788.0000 - val_loss: 5248965.5000\n",
            "Epoch 424/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 5245008.5000 - val_loss: 5240191.5000\n",
            "Epoch 425/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 5236236.5000 - val_loss: 5231424.0000\n",
            "Epoch 426/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5227472.0000 - val_loss: 5222665.0000\n",
            "Epoch 427/500\n",
            "24/24 [==============================] - 1s 42ms/step - loss: 5218715.5000 - val_loss: 5213912.0000\n",
            "Epoch 428/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5209965.0000 - val_loss: 5205167.0000\n",
            "Epoch 429/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5201223.5000 - val_loss: 5196430.0000\n",
            "Epoch 430/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5192488.5000 - val_loss: 5187699.0000\n",
            "Epoch 431/500\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 5183760.0000 - val_loss: 5178977.0000\n",
            "Epoch 432/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5175040.0000 - val_loss: 5170261.5000\n",
            "Epoch 433/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5166327.0000 - val_loss: 5161552.5000\n",
            "Epoch 434/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5157621.5000 - val_loss: 5152851.5000\n",
            "Epoch 435/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5148923.0000 - val_loss: 5144158.0000\n",
            "Epoch 436/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5140231.5000 - val_loss: 5135472.0000\n",
            "Epoch 437/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5131548.0000 - val_loss: 5126792.5000\n",
            "Epoch 438/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5122872.0000 - val_loss: 5118121.5000\n",
            "Epoch 439/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5114203.0000 - val_loss: 5109456.5000\n",
            "Epoch 440/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5105541.0000 - val_loss: 5100800.0000\n",
            "Epoch 441/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5096887.5000 - val_loss: 5092150.5000\n",
            "Epoch 442/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5088241.0000 - val_loss: 5083511.5000\n",
            "Epoch 443/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 5079606.5000 - val_loss: 5074884.0000\n",
            "Epoch 444/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5070982.5000 - val_loss: 5066264.5000\n",
            "Epoch 445/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 5062366.0000 - val_loss: 5057653.0000\n",
            "Epoch 446/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5053756.5000 - val_loss: 5049049.5000\n",
            "Epoch 447/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 5045155.0000 - val_loss: 5040452.0000\n",
            "Epoch 448/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5036560.5000 - val_loss: 5031862.0000\n",
            "Epoch 449/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 5027973.5000 - val_loss: 5023279.5000\n",
            "Epoch 450/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 5019394.0000 - val_loss: 5014705.0000\n",
            "Epoch 451/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5010821.5000 - val_loss: 5006137.5000\n",
            "Epoch 452/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 5002256.5000 - val_loss: 4997576.5000\n",
            "Epoch 453/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 4993698.5000 - val_loss: 4989023.0000\n",
            "Epoch 454/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 4985149.0000 - val_loss: 4980476.5000\n",
            "Epoch 455/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 4976606.0000 - val_loss: 4971938.5000\n",
            "Epoch 456/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4968070.0000 - val_loss: 4963408.5000\n",
            "Epoch 457/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4959541.0000 - val_loss: 4954884.0000\n",
            "Epoch 458/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4951020.5000 - val_loss: 4946368.0000\n",
            "Epoch 459/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 4942506.5000 - val_loss: 4937859.0000\n",
            "Epoch 460/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 4934000.0000 - val_loss: 4929357.0000\n",
            "Epoch 461/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 4925500.0000 - val_loss: 4920862.5000\n",
            "Epoch 462/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4917009.0000 - val_loss: 4912375.5000\n",
            "Epoch 463/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4908524.5000 - val_loss: 4903895.0000\n",
            "Epoch 464/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4900047.5000 - val_loss: 4895423.5000\n",
            "Epoch 465/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4891578.5000 - val_loss: 4886957.5000\n",
            "Epoch 466/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4883116.5000 - val_loss: 4878500.0000\n",
            "Epoch 467/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 4874660.5000 - val_loss: 4870049.5000\n",
            "Epoch 468/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4866213.0000 - val_loss: 4861606.5000\n",
            "Epoch 469/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4857772.5000 - val_loss: 4853171.0000\n",
            "Epoch 470/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4849339.0000 - val_loss: 4844742.0000\n",
            "Epoch 471/500\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 4840913.5000 - val_loss: 4836320.5000\n",
            "Epoch 472/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 4832495.0000 - val_loss: 4827907.0000\n",
            "Epoch 473/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 4824084.0000 - val_loss: 4819499.0000\n",
            "Epoch 474/500\n",
            "24/24 [==============================] - 0s 7ms/step - loss: 4815681.0000 - val_loss: 4811099.5000\n",
            "Epoch 475/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4807285.0000 - val_loss: 4802712.0000\n",
            "Epoch 476/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4798901.5000 - val_loss: 4794335.0000\n",
            "Epoch 477/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4790528.0000 - val_loss: 4785966.5000\n",
            "Epoch 478/500\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 4782161.5000 - val_loss: 4777604.0000\n",
            "Epoch 479/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 4773803.0000 - val_loss: 4769250.0000\n",
            "Epoch 480/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4765451.5000 - val_loss: 4760902.0000\n",
            "Epoch 481/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4757107.5000 - val_loss: 4752562.5000\n",
            "Epoch 482/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 4748769.5000 - val_loss: 4744230.5000\n",
            "Epoch 483/500\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 4740440.5000 - val_loss: 4735905.5000\n",
            "Epoch 484/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4732118.5000 - val_loss: 4727586.5000\n",
            "Epoch 485/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4723803.5000 - val_loss: 4719277.0000\n",
            "Epoch 486/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4715495.5000 - val_loss: 4710973.5000\n",
            "Epoch 487/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4707195.0000 - val_loss: 4702677.5000\n",
            "Epoch 488/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 4698902.5000 - val_loss: 4694389.0000\n",
            "Epoch 489/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 4690617.0000 - val_loss: 4686107.5000\n",
            "Epoch 490/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4682338.5000 - val_loss: 4677834.0000\n",
            "Epoch 491/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4674066.5000 - val_loss: 4669567.5000\n",
            "Epoch 492/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4665802.5000 - val_loss: 4661308.0000\n",
            "Epoch 493/500\n",
            "24/24 [==============================] - 0s 8ms/step - loss: 4657548.0000 - val_loss: 4653056.0000\n",
            "Epoch 494/500\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 4649298.0000 - val_loss: 4644812.0000\n",
            "Epoch 495/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 4641055.5000 - val_loss: 4636574.0000\n",
            "Epoch 496/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 4632822.0000 - val_loss: 4628344.0000\n",
            "Epoch 497/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 4624594.5000 - val_loss: 4620121.0000\n",
            "Epoch 498/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 4616374.5000 - val_loss: 4611905.5000\n",
            "Epoch 499/500\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 4608162.5000 - val_loss: 4603697.5000\n",
            "Epoch 500/500\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 4599957.0000 - val_loss: 4595497.0000\n"
          ]
        }
      ],
      "source": [
        "c1 = tf.Variable(2.6676, name=\"c1\", trainable=True, dtype=tf.float32)\n",
        "c2 = tf.Variable(7000, name=\"c2\", trainable=True, dtype=tf.float32)\n",
        "c3 = tf.Variable(20000, name=\"c3\", trainable=True, dtype=tf.float32)\n",
        "b3 = tf.Variable(1.06, name=\"b3\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "splitr = 0.8\n",
        "\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
        "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
        "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
        "    squared_difference3 = tf.square(\n",
        "        y_pred[:, 3] + (c1 * y_pred[:, 1] + b3 * y_pred[:, 2] + c2))\n",
        "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "model.add(Dense(30))\n",
        "model.compile(loss=loss_fn, optimizer='adam')\n",
        "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJL101rPyuoT",
        "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 992ms/step\n"
          ]
        }
      ],
      "source": [
        "forecast_without_mc = forecastX\n",
        "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
        "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9dQELcJ8wbp",
        "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1, 138)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forecastX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS2kyIKG1Kbr",
        "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 138)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forecast_without_mc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0u6VIzaDyuoT"
      },
      "outputs": [],
      "source": [
        "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
        "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUEcw0LX07oU",
        "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 168)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat_without_mc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "31OWVbSh_305"
      },
      "outputs": [],
      "source": [
        "fforecast = inv_yhat_without_mc[:,-90:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BlpGH2FOAiRF"
      },
      "outputs": [],
      "source": [
        "final_forecast = fforecast[:,0:89:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CXkgkj_LBk_t"
      },
      "outputs": [],
      "source": [
        "# code to replace all negative value with 0\n",
        "final_forecast[final_forecast<0] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.18136074, 0.17272779, 0.16611105, 0.16446078, 0.1679724 ,\n",
              "        0.1747825 , 0.16211247, 0.16987774, 0.16827214, 0.        ,\n",
              "        0.18338291, 0.00280962, 0.01102827, 0.        , 0.17215103,\n",
              "        0.00121395, 0.01629014, 0.        , 0.16928862, 0.        ,\n",
              "        0.        , 0.        , 0.29787114, 0.57145315, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.62884921, 0.        ]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_set = np.array(training_set)\n",
        "test = np.array(test)\n",
        "final_forecast = np.array(final_forecast.squeeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.15712574004230204\n",
            "0.11108331199819309\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
        "rsme = math.sqrt(MSE)\n",
        "print(rsme)  \n",
        "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
        "mae = MAE\n",
        "print(mae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
