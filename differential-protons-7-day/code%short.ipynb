{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCGKeZ2gyuoQ"
      },
      "source": [
        "_Importing Required Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-6LN-zXiLcM",
        "outputId": "4de610a4-f8b8-4f49-c6c0-89de299ccedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hampel in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.5)\n",
            "Requirement already satisfied: numpy in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.26.4)\n",
            "Requirement already satisfied: pandas in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from hampel) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas->hampel) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anurag dutta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->hampel) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
            "[notice] To update, run: C:\\Users\\Anurag Dutta\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install hampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "By_d9uXpaFvZ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from hampel import hampel\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from numpy import array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyOjBMFayuoR"
      },
      "source": [
        "## Pretraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5QqIY_GyuoR"
      },
      "source": [
        "The `horton_intermittency.dat` feeds the model with the dynamics of the Horton Chaotics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9dV4a8yfyuoR"
      },
      "outputs": [],
      "source": [
        "data = np.genfromtxt('horton_intermittency.dat')\n",
        "training_set = pd.DataFrame(data).reset_index(drop=True)\n",
        "training_set = training_set.iloc[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7easoxByuoR"
      },
      "source": [
        "## Computing the Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SnyolJTyuoR"
      },
      "source": [
        "_Calculating the value of_ $\\frac{dx}{dt}$, $\\frac{d^2x}{dt^2}$, _and_ $\\frac{d^3x}{dt^3}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmIbVfIvyuoR",
        "outputId": "aa4e3136-c854-465d-d2e9-81cfd546e440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "1       -0.000011\n",
            "2        0.003571\n",
            "3        0.005754\n",
            "4        0.006818\n",
            "5       -0.000807\n",
            "           ...   \n",
            "9996    -0.129763\n",
            "9997    -0.118735\n",
            "9998    -0.105414\n",
            "9999    -0.090338\n",
            "10000   -0.074048\n",
            "Name: 1, Length: 10000, dtype: float64\n",
            "2        0.003582\n",
            "3        0.002183\n",
            "4        0.001064\n",
            "5       -0.007625\n",
            "6       -0.006999\n",
            "           ...   \n",
            "9996     0.008219\n",
            "9997     0.011028\n",
            "9998     0.013321\n",
            "9999     0.015076\n",
            "10000    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n",
            "2        0.003582\n",
            "3        0.002183\n",
            "4        0.001064\n",
            "5       -0.007625\n",
            "6       -0.006999\n",
            "           ...   \n",
            "9996     0.008219\n",
            "9997     0.011028\n",
            "9998     0.013321\n",
            "9999     0.015076\n",
            "10000    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "t_diff = 1\n",
        "print(training_set.max())\n",
        "gradient_t = (training_set.diff()/t_diff).iloc[1:] # dx/dt\n",
        "print(gradient_t)\n",
        "gradient_tt = (gradient_t.diff()/t_diff).iloc[1:] # d2x/dt2\n",
        "print(gradient_tt)\n",
        "gradient_ttt = (gradient_tt.diff()/t_diff).iloc[1:] # d3x/dt3\n",
        "print(gradient_tt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2eVeeoxyuoS"
      },
      "source": [
        "## Loading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0J-NKyIEyuoS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       3.013502\n",
              "1       2.832119\n",
              "2       2.042342\n",
              "3       1.794970\n",
              "4       1.789537\n",
              "          ...   \n",
              "2010    0.092451\n",
              "2011    0.097335\n",
              "2012    0.105332\n",
              "2013    0.103997\n",
              "2014    0.105429\n",
              "Name: flux, Length: 2015, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"differential-protons-7-day.csv\")\n",
        "training_set = data.iloc[:, 1]\n",
        "training_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CbNUhJ74UqF",
        "outputId": "20f562d8-8247-49cc-b9c3-00eca5e13e2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       3.013502\n",
              "1       2.832119\n",
              "2       2.042342\n",
              "3       1.794970\n",
              "4       1.789537\n",
              "          ...   \n",
              "1999    0.124249\n",
              "2000    0.117553\n",
              "2001    0.118642\n",
              "2002    0.121266\n",
              "2003    0.123413\n",
              "Name: flux, Length: 2004, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = training_set.tail(10)\n",
        "test\n",
        "training_set = training_set.head(2004) # (2013 - 10) + 1\n",
        "training_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0TwTcq0yuoS",
        "outputId": "37252ed8-d88e-4044-fa7a-922411990b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0      -0.000011\n",
            "1       0.003571\n",
            "2       0.005754\n",
            "3       0.006818\n",
            "4      -0.000807\n",
            "          ...   \n",
            "9995   -0.129763\n",
            "9996   -0.118735\n",
            "9997   -0.105414\n",
            "9998   -0.090338\n",
            "9999   -0.074048\n",
            "Name: 1, Length: 10000, dtype: float64\n",
            "0       0.003582\n",
            "1       0.002183\n",
            "2       0.001064\n",
            "3      -0.007625\n",
            "4      -0.006999\n",
            "          ...   \n",
            "9994    0.008219\n",
            "9995    0.011028\n",
            "9996    0.013321\n",
            "9997    0.015076\n",
            "9998    0.016290\n",
            "Name: 1, Length: 9999, dtype: float64\n",
            "0      -0.001400\n",
            "1      -0.001118\n",
            "2      -0.008690\n",
            "3       0.000626\n",
            "4       0.000763\n",
            "          ...   \n",
            "9993    0.003290\n",
            "9994    0.002810\n",
            "9995    0.002293\n",
            "9996    0.001755\n",
            "9997    0.001214\n",
            "Name: 1, Length: 9998, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "training_set = training_set.reset_index(drop=True) # sets a list of integer ranging from 0 to length of training_set as index\n",
        "gradient_t = gradient_t.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_t as index\n",
        "gradient_tt = gradient_tt.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_tt as index\n",
        "gradient_ttt = gradient_ttt.reset_index(drop=True) # sets a list of integer ranging from 0 to length of gradient_ttt as index\n",
        "print(gradient_t)\n",
        "print(gradient_tt)\n",
        "print(gradient_ttt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O2biznZQyuoS"
      },
      "outputs": [],
      "source": [
        "df = pd.concat((training_set, gradient_t), axis=1) ##########[:-1]\n",
        "gradient_tt.columns = [\"grad_tt\"]\n",
        "df = pd.concat((df, gradient_tt), axis=1) ################[:-1]\n",
        "gradient_tt.columns = [\"grad_ttt\"]\n",
        "df = pd.concat((df, gradient_ttt), axis=1) ################[:-1]\n",
        "df.columns = ['y_t', 'grad_t', 'grad_tt', 'grad_ttt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sk_a5v3tyuoS",
        "outputId": "17563625-e550-45ae-faab-fafa353e44da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_t</th>\n",
              "      <th>grad_t</th>\n",
              "      <th>grad_tt</th>\n",
              "      <th>grad_ttt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.013502</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>0.003582</td>\n",
              "      <td>-0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.832119</td>\n",
              "      <td>0.003571</td>\n",
              "      <td>0.002183</td>\n",
              "      <td>-0.001118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.042342</td>\n",
              "      <td>0.005754</td>\n",
              "      <td>0.001064</td>\n",
              "      <td>-0.008690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.794970</td>\n",
              "      <td>0.006818</td>\n",
              "      <td>-0.007625</td>\n",
              "      <td>0.000626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.789537</td>\n",
              "      <td>-0.000807</td>\n",
              "      <td>-0.006999</td>\n",
              "      <td>0.000763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.129763</td>\n",
              "      <td>0.011028</td>\n",
              "      <td>0.002293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.118735</td>\n",
              "      <td>0.013321</td>\n",
              "      <td>0.001755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.105414</td>\n",
              "      <td>0.015076</td>\n",
              "      <td>0.001214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.090338</td>\n",
              "      <td>0.016290</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.074048</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           y_t    grad_t   grad_tt  grad_ttt\n",
              "0     3.013502 -0.000011  0.003582 -0.001400\n",
              "1     2.832119  0.003571  0.002183 -0.001118\n",
              "2     2.042342  0.005754  0.001064 -0.008690\n",
              "3     1.794970  0.006818 -0.007625  0.000626\n",
              "4     1.789537 -0.000807 -0.006999  0.000763\n",
              "...        ...       ...       ...       ...\n",
              "9995       NaN -0.129763  0.011028  0.002293\n",
              "9996       NaN -0.118735  0.013321  0.001755\n",
              "9997       NaN -0.105414  0.015076  0.001214\n",
              "9998       NaN -0.090338  0.016290       NaN\n",
              "9999       NaN -0.074048       NaN       NaN\n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df # DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5esyHu5aFvg"
      },
      "source": [
        "## Plot of the External Forcing from Chaotic Differential Equation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "hGnE43tOh-4p",
        "outputId": "fc396503-b624-4fa5-dfbe-f460207405c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.iloc[:, 0].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ym4xWUUxaFvg",
        "outputId": "ae6a3495-8ce9-437e-ba81-3ed31deedeae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "c1=2.6676\n",
        "c2=7000\n",
        "c3=20000\n",
        "b3=1.06\n",
        "L = df.iloc[:, 3] + (c1 * df.iloc[:, 1] + b3 * df.iloc[:, 2] + c2 + c3*np.tanh(df.iloc[:,0]))\n",
        "L.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VyEywnwaFvh"
      },
      "source": [
        "## Preprocessing the data into supervised learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6V9dXqzdaFvh"
      },
      "outputs": [],
      "source": [
        "# split a sequence into samples\n",
        "def Supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n_in, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n_out)\n",
        "    for i in range(0, n_out):\n",
        "      cols.append(df.shift(-i))\n",
        "      if i == 0:\n",
        "        names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "      else:\n",
        "        names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "       agg.dropna(inplace=True)\n",
        "    return agg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrzSrT1HnyfH",
        "outputId": "7e75f928-3e47-499d-eac1-51908015ef78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    var1(t-35)  var1(t-34)  var1(t-33)  var1(t-32)  var1(t-31)  var1(t-30)  \\\n",
            "35    3.013502    2.832119    2.042342    1.794970    1.789537    1.877289   \n",
            "36    2.832119    2.042342    1.794970    1.789537    1.877289    1.983688   \n",
            "37    2.042342    1.794970    1.789537    1.877289    1.983688    2.153054   \n",
            "38    1.794970    1.789537    1.877289    1.983688    2.153054    2.331594   \n",
            "39    1.789537    1.877289    1.983688    2.153054    2.331594    2.405767   \n",
            "\n",
            "    var1(t-29)  var1(t-28)  var1(t-27)  var1(t-26)  ...  var3(t+7)  var4(t+7)  \\\n",
            "35    1.983688    2.153054    2.331594    2.405767  ...   0.010170  -0.000639   \n",
            "36    2.153054    2.331594    2.405767    1.515924  ...   0.009532  -0.000842   \n",
            "37    2.331594    2.405767    1.515924    2.041262  ...   0.008689  -0.001007   \n",
            "38    2.405767    1.515924    2.041262    2.062020  ...   0.007682   0.019338   \n",
            "39    1.515924    2.041262    2.062020    1.730290  ...   0.027020  -0.003387   \n",
            "\n",
            "    var1(t+8)  var2(t+8)  var3(t+8)  var4(t+8)  var1(t+9)  var2(t+9)  \\\n",
            "35   0.978849  -0.006297   0.009532  -0.000842   1.000817   0.003235   \n",
            "36   1.000817   0.003235   0.008689  -0.001007   1.183258   0.011924   \n",
            "37   1.183258   0.011924   0.007682   0.019338   1.189826   0.019606   \n",
            "38   1.189826   0.019606   0.027020  -0.003387   1.342348   0.046626   \n",
            "39   1.342348   0.046626   0.023633  -0.003749   1.283285   0.070258   \n",
            "\n",
            "    var3(t+9)  var4(t+9)  \n",
            "35   0.008689  -0.001007  \n",
            "36   0.007682   0.019338  \n",
            "37   0.027020  -0.003387  \n",
            "38   0.023633  -0.003749  \n",
            "39   0.019884  -0.003982  \n",
            "\n",
            "[5 rows x 78 columns]\n",
            "Index(['var1(t-35)', 'var1(t-34)', 'var1(t-33)', 'var1(t-32)', 'var1(t-31)',\n",
            "       'var1(t-30)', 'var1(t-29)', 'var1(t-28)', 'var1(t-27)', 'var1(t-26)',\n",
            "       'var1(t-25)', 'var1(t-24)', 'var1(t-23)', 'var1(t-22)', 'var1(t-21)',\n",
            "       'var1(t-20)', 'var1(t-19)', 'var1(t-18)', 'var1(t-17)', 'var1(t-16)',\n",
            "       'var1(t-15)', 'var1(t-14)', 'var1(t-13)', 'var1(t-12)', 'var1(t-11)',\n",
            "       'var1(t-10)', 'var1(t-9)', 'var1(t-8)', 'var1(t-7)', 'var1(t-6)',\n",
            "       'var1(t-5)', 'var1(t-4)', 'var1(t-3)', 'var1(t-2)', 'var1(t-1)',\n",
            "       'var2(t-1)', 'var3(t-1)', 'var4(t-1)', 'var1(t)', 'var2(t)', 'var3(t)',\n",
            "       'var4(t)', 'var1(t+1)', 'var2(t+1)', 'var3(t+1)', 'var4(t+1)',\n",
            "       'var1(t+2)', 'var2(t+2)', 'var3(t+2)', 'var4(t+2)', 'var1(t+3)',\n",
            "       'var2(t+3)', 'var3(t+3)', 'var4(t+3)', 'var1(t+4)', 'var2(t+4)',\n",
            "       'var3(t+4)', 'var4(t+4)', 'var1(t+5)', 'var2(t+5)', 'var3(t+5)',\n",
            "       'var4(t+5)', 'var1(t+6)', 'var2(t+6)', 'var3(t+6)', 'var4(t+6)',\n",
            "       'var1(t+7)', 'var2(t+7)', 'var3(t+7)', 'var4(t+7)', 'var1(t+8)',\n",
            "       'var2(t+8)', 'var3(t+8)', 'var4(t+8)', 'var1(t+9)', 'var2(t+9)',\n",
            "       'var3(t+9)', 'var4(t+9)'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "data = Supervised(df.values, n_in = 35, n_out = 10)\n",
        "\n",
        "\n",
        "cols_to_drop = []\n",
        "for i in range(2, 36):\n",
        "    cols_to_drop.extend([f'var2(t-{i})', f'var3(t-{i})', f'var4(t-{i})'])\n",
        "\n",
        "data.drop(cols_to_drop, axis=1, inplace=True)\n",
        "\n",
        "print(data.head())\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AfPf60oy6Pe4"
      },
      "outputs": [],
      "source": [
        "train = np.array(data[0:len(data)-1])\n",
        "forecast = np.array(data.tail(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WSAafzI37KiT"
      },
      "outputs": [],
      "source": [
        "trainy = train[:,-30:]\n",
        "trainX = train[:,:-30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2SrOqVJA7f50"
      },
      "outputs": [],
      "source": [
        "forecasty = forecast[:,-30:]\n",
        "forecastX = forecast[:,:-30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qno_k8Nw7saY",
        "outputId": "c4a88db5-d8c6-489f-cdb2-06b24e293cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1959, 1, 48) (1959, 30) (1, 1, 48)\n"
          ]
        }
      ],
      "source": [
        "trainX = trainX.reshape((trainX.shape[0], 1, trainX.shape[1]))\n",
        "forecastX = forecastX.reshape((forecastX.shape[0], 1, forecastX.shape[1]))\n",
        "print(trainX.shape, trainy.shape, forecastX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Jp2DvNuNFx",
        "outputId": "d0e5b3c4-64f1-438c-eade-8dfeaac8e285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "25/25 [==============================] - 4s 40ms/step - loss: 9796936.0000 - val_loss: 9797175.0000\n",
            "Epoch 2/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 9789756.0000 - val_loss: 9793708.0000\n",
            "Epoch 3/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 9780107.0000 - val_loss: 9788647.0000\n",
            "Epoch 4/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9767901.0000 - val_loss: 9781641.0000\n",
            "Epoch 5/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9753882.0000 - val_loss: 9772693.0000\n",
            "Epoch 6/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9739005.0000 - val_loss: 9762029.0000\n",
            "Epoch 7/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9723614.0000 - val_loss: 9749877.0000\n",
            "Epoch 8/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9707623.0000 - val_loss: 9736413.0000\n",
            "Epoch 9/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9691080.0000 - val_loss: 9721824.0000\n",
            "Epoch 10/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9674108.0000 - val_loss: 9706297.0000\n",
            "Epoch 11/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9656849.0000 - val_loss: 9690027.0000\n",
            "Epoch 12/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9639428.0000 - val_loss: 9673191.0000\n",
            "Epoch 13/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9621951.0000 - val_loss: 9655945.0000\n",
            "Epoch 14/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9604499.0000 - val_loss: 9638427.0000\n",
            "Epoch 15/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9587132.0000 - val_loss: 9620741.0000\n",
            "Epoch 16/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9569890.0000 - val_loss: 9602975.0000\n",
            "Epoch 17/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9552797.0000 - val_loss: 9585197.0000\n",
            "Epoch 18/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9535867.0000 - val_loss: 9567455.0000\n",
            "Epoch 19/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9519109.0000 - val_loss: 9549785.0000\n",
            "Epoch 20/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9502524.0000 - val_loss: 9532216.0000\n",
            "Epoch 21/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9486108.0000 - val_loss: 9514765.0000\n",
            "Epoch 22/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9469856.0000 - val_loss: 9497445.0000\n",
            "Epoch 23/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9453767.0000 - val_loss: 9480267.0000\n",
            "Epoch 24/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 9437832.0000 - val_loss: 9463232.0000\n",
            "Epoch 25/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 9422041.0000 - val_loss: 9446344.0000\n",
            "Epoch 26/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9406391.0000 - val_loss: 9429603.0000\n",
            "Epoch 27/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9390877.0000 - val_loss: 9413008.0000\n",
            "Epoch 28/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9375488.0000 - val_loss: 9396556.0000\n",
            "Epoch 29/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9360219.0000 - val_loss: 9380246.0000\n",
            "Epoch 30/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9345067.0000 - val_loss: 9364073.0000\n",
            "Epoch 31/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9330022.0000 - val_loss: 9348033.0000\n",
            "Epoch 32/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9315082.0000 - val_loss: 9332123.0000\n",
            "Epoch 33/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9300241.0000 - val_loss: 9316338.0000\n",
            "Epoch 34/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9285495.0000 - val_loss: 9300675.0000\n",
            "Epoch 35/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 9270841.0000 - val_loss: 9285130.0000\n",
            "Epoch 36/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9256270.0000 - val_loss: 9269699.0000\n",
            "Epoch 37/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9241785.0000 - val_loss: 9254376.0000\n",
            "Epoch 38/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9227377.0000 - val_loss: 9239160.0000\n",
            "Epoch 39/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9213046.0000 - val_loss: 9224045.0000\n",
            "Epoch 40/500\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 9198787.0000 - val_loss: 9209030.0000\n",
            "Epoch 41/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9184598.0000 - val_loss: 9194109.0000\n",
            "Epoch 42/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9170477.0000 - val_loss: 9179280.0000\n",
            "Epoch 43/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9156420.0000 - val_loss: 9164539.0000\n",
            "Epoch 44/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 9142427.0000 - val_loss: 9149884.0000\n",
            "Epoch 45/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 9128493.0000 - val_loss: 9135313.0000\n",
            "Epoch 46/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 9114617.0000 - val_loss: 9120820.0000\n",
            "Epoch 47/500\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 9100796.0000 - val_loss: 9106406.0000\n",
            "Epoch 48/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 9087032.0000 - val_loss: 9092067.0000\n",
            "Epoch 49/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 9073320.0000 - val_loss: 9077800.0000\n",
            "Epoch 50/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 9059657.0000 - val_loss: 9063603.0000\n",
            "Epoch 51/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 9046045.0000 - val_loss: 9049473.0000\n",
            "Epoch 52/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 9032481.0000 - val_loss: 9035410.0000\n",
            "Epoch 53/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9018962.0000 - val_loss: 9021411.0000\n",
            "Epoch 54/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 9005489.0000 - val_loss: 9007473.0000\n",
            "Epoch 55/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8992059.0000 - val_loss: 8993595.0000\n",
            "Epoch 56/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8978671.0000 - val_loss: 8979776.0000\n",
            "Epoch 57/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8965326.0000 - val_loss: 8966013.0000\n",
            "Epoch 58/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8952020.0000 - val_loss: 8952305.0000\n",
            "Epoch 59/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8938755.0000 - val_loss: 8938649.0000\n",
            "Epoch 60/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8925528.0000 - val_loss: 8925046.0000\n",
            "Epoch 61/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8912337.0000 - val_loss: 8911494.0000\n",
            "Epoch 62/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8899183.0000 - val_loss: 8897991.0000\n",
            "Epoch 63/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8886066.0000 - val_loss: 8884536.0000\n",
            "Epoch 64/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8872981.0000 - val_loss: 8871126.0000\n",
            "Epoch 65/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8859934.0000 - val_loss: 8857762.0000\n",
            "Epoch 66/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8846916.0000 - val_loss: 8844443.0000\n",
            "Epoch 67/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8833932.0000 - val_loss: 8831167.0000\n",
            "Epoch 68/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8820980.0000 - val_loss: 8817932.0000\n",
            "Epoch 69/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8808059.0000 - val_loss: 8804740.0000\n",
            "Epoch 70/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8795168.0000 - val_loss: 8791586.0000\n",
            "Epoch 71/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8782308.0000 - val_loss: 8778472.0000\n",
            "Epoch 72/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8769477.0000 - val_loss: 8765396.0000\n",
            "Epoch 73/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8756672.0000 - val_loss: 8752357.0000\n",
            "Epoch 74/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8743899.0000 - val_loss: 8739355.0000\n",
            "Epoch 75/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8731150.0000 - val_loss: 8726388.0000\n",
            "Epoch 76/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8718432.0000 - val_loss: 8713456.0000\n",
            "Epoch 77/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8705738.0000 - val_loss: 8700559.0000\n",
            "Epoch 78/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8693070.0000 - val_loss: 8687695.0000\n",
            "Epoch 79/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8680428.0000 - val_loss: 8674862.0000\n",
            "Epoch 80/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8667811.0000 - val_loss: 8662063.0000\n",
            "Epoch 81/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8655219.0000 - val_loss: 8649294.0000\n",
            "Epoch 82/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8642651.0000 - val_loss: 8636556.0000\n",
            "Epoch 83/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8630108.0000 - val_loss: 8623850.0000\n",
            "Epoch 84/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8617588.0000 - val_loss: 8611171.0000\n",
            "Epoch 85/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8605092.0000 - val_loss: 8598523.0000\n",
            "Epoch 86/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8592617.0000 - val_loss: 8585901.0000\n",
            "Epoch 87/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8580165.0000 - val_loss: 8573308.0000\n",
            "Epoch 88/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8567737.0000 - val_loss: 8560743.0000\n",
            "Epoch 89/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 8555328.0000 - val_loss: 8548204.0000\n",
            "Epoch 90/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 8542942.0000 - val_loss: 8535692.0000\n",
            "Epoch 91/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8530577.0000 - val_loss: 8523206.0000\n",
            "Epoch 92/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8518231.0000 - val_loss: 8510744.0000\n",
            "Epoch 93/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8505909.0000 - val_loss: 8498309.0000\n",
            "Epoch 94/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8493606.0000 - val_loss: 8485897.0000\n",
            "Epoch 95/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8481323.0000 - val_loss: 8473509.0000\n",
            "Epoch 96/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8469059.0000 - val_loss: 8461146.0000\n",
            "Epoch 97/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8456813.0000 - val_loss: 8448806.0000\n",
            "Epoch 98/500\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8444590.0000 - val_loss: 8436488.0000\n",
            "Epoch 99/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8432383.0000 - val_loss: 8424194.0000\n",
            "Epoch 100/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8420196.0000 - val_loss: 8411923.0000\n",
            "Epoch 101/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8408027.0000 - val_loss: 8399672.0000\n",
            "Epoch 102/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8395877.0000 - val_loss: 8387443.5000\n",
            "Epoch 103/500\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8383744.0000 - val_loss: 8375236.0000\n",
            "Epoch 104/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8371630.5000 - val_loss: 8363050.0000\n",
            "Epoch 105/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8359533.5000 - val_loss: 8350884.0000\n",
            "Epoch 106/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8347454.0000 - val_loss: 8338739.0000\n",
            "Epoch 107/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8335391.5000 - val_loss: 8326614.0000\n",
            "Epoch 108/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8323346.5000 - val_loss: 8314508.5000\n",
            "Epoch 109/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 8311318.5000 - val_loss: 8302423.0000\n",
            "Epoch 110/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8299305.0000 - val_loss: 8290356.0000\n",
            "Epoch 111/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 8287311.0000 - val_loss: 8278308.5000\n",
            "Epoch 112/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 8275333.5000 - val_loss: 8266279.0000\n",
            "Epoch 113/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 8263370.5000 - val_loss: 8254268.5000\n",
            "Epoch 114/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 8251424.0000 - val_loss: 8242277.0000\n",
            "Epoch 115/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 8239492.0000 - val_loss: 8230302.5000\n",
            "Epoch 116/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 8227576.0000 - val_loss: 8218346.5000\n",
            "Epoch 117/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8215677.5000 - val_loss: 8206408.5000\n",
            "Epoch 118/500\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 8203794.0000 - val_loss: 8194487.5000\n",
            "Epoch 119/500\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 8191925.0000 - val_loss: 8182583.0000\n",
            "Epoch 120/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 8180072.0000 - val_loss: 8170696.0000\n",
            "Epoch 121/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8168233.5000 - val_loss: 8158826.0000\n",
            "Epoch 122/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8156410.5000 - val_loss: 8146972.0000\n",
            "Epoch 123/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8144598.0000 - val_loss: 8135134.5000\n",
            "Epoch 124/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8132804.0000 - val_loss: 8123314.5000\n",
            "Epoch 125/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8121024.0000 - val_loss: 8111509.5000\n",
            "Epoch 126/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8109259.0000 - val_loss: 8099720.0000\n",
            "Epoch 127/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 8097506.0000 - val_loss: 8087947.0000\n",
            "Epoch 128/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 8085766.5000 - val_loss: 8076188.5000\n",
            "Epoch 129/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8074044.0000 - val_loss: 8064447.5000\n",
            "Epoch 130/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8062335.0000 - val_loss: 8052719.0000\n",
            "Epoch 131/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8050639.0000 - val_loss: 8041008.5000\n",
            "Epoch 132/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8038955.5000 - val_loss: 8029310.0000\n",
            "Epoch 133/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8027286.5000 - val_loss: 8017628.0000\n",
            "Epoch 134/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 8015630.0000 - val_loss: 8005960.5000\n",
            "Epoch 135/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 8003986.5000 - val_loss: 7994306.5000\n",
            "Epoch 136/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7992358.5000 - val_loss: 7982668.5000\n",
            "Epoch 137/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7980743.5000 - val_loss: 7971044.0000\n",
            "Epoch 138/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7969139.0000 - val_loss: 7959434.0000\n",
            "Epoch 139/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7957549.0000 - val_loss: 7947837.5000\n",
            "Epoch 140/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7945971.0000 - val_loss: 7936253.5000\n",
            "Epoch 141/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7934408.0000 - val_loss: 7924685.0000\n",
            "Epoch 142/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7922856.0000 - val_loss: 7913130.5000\n",
            "Epoch 143/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7911317.0000 - val_loss: 7901589.0000\n",
            "Epoch 144/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7899789.0000 - val_loss: 7890060.5000\n",
            "Epoch 145/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7888275.0000 - val_loss: 7878545.5000\n",
            "Epoch 146/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 7876773.5000 - val_loss: 7867043.5000\n",
            "Epoch 147/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7865284.0000 - val_loss: 7855555.5000\n",
            "Epoch 148/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7853806.0000 - val_loss: 7844079.0000\n",
            "Epoch 149/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7842340.5000 - val_loss: 7832616.0000\n",
            "Epoch 150/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7830887.5000 - val_loss: 7821166.5000\n",
            "Epoch 151/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7819447.0000 - val_loss: 7809728.5000\n",
            "Epoch 152/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7808017.5000 - val_loss: 7798304.5000\n",
            "Epoch 153/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7796600.0000 - val_loss: 7786892.5000\n",
            "Epoch 154/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7785193.0000 - val_loss: 7775492.5000\n",
            "Epoch 155/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7773799.0000 - val_loss: 7764106.0000\n",
            "Epoch 156/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7762417.5000 - val_loss: 7752729.5000\n",
            "Epoch 157/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7751046.0000 - val_loss: 7741366.0000\n",
            "Epoch 158/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7739687.5000 - val_loss: 7730016.0000\n",
            "Epoch 159/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7728338.5000 - val_loss: 7718677.0000\n",
            "Epoch 160/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7717002.5000 - val_loss: 7707349.5000\n",
            "Epoch 161/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7705677.0000 - val_loss: 7696035.5000\n",
            "Epoch 162/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7694363.5000 - val_loss: 7684731.5000\n",
            "Epoch 163/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7683061.0000 - val_loss: 7673440.0000\n",
            "Epoch 164/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7671770.0000 - val_loss: 7662160.5000\n",
            "Epoch 165/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7660488.5000 - val_loss: 7650892.5000\n",
            "Epoch 166/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7649220.5000 - val_loss: 7639636.0000\n",
            "Epoch 167/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7637962.5000 - val_loss: 7628390.0000\n",
            "Epoch 168/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7626715.0000 - val_loss: 7617156.0000\n",
            "Epoch 169/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7615479.0000 - val_loss: 7605932.5000\n",
            "Epoch 170/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7604252.0000 - val_loss: 7594722.0000\n",
            "Epoch 171/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7593039.0000 - val_loss: 7583521.5000\n",
            "Epoch 172/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7581835.0000 - val_loss: 7572333.0000\n",
            "Epoch 173/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7570642.0000 - val_loss: 7561155.5000\n",
            "Epoch 174/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7559460.0000 - val_loss: 7549987.5000\n",
            "Epoch 175/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7548289.0000 - val_loss: 7538831.5000\n",
            "Epoch 176/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7537128.0000 - val_loss: 7527686.0000\n",
            "Epoch 177/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7525976.5000 - val_loss: 7516552.0000\n",
            "Epoch 178/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7514836.5000 - val_loss: 7505429.0000\n",
            "Epoch 179/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7503707.5000 - val_loss: 7494316.5000\n",
            "Epoch 180/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7492587.0000 - val_loss: 7483213.5000\n",
            "Epoch 181/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7481480.0000 - val_loss: 7472123.0000\n",
            "Epoch 182/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7470380.5000 - val_loss: 7461042.5000\n",
            "Epoch 183/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7459291.5000 - val_loss: 7449971.5000\n",
            "Epoch 184/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7448216.0000 - val_loss: 7438912.5000\n",
            "Epoch 185/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7437148.5000 - val_loss: 7427863.5000\n",
            "Epoch 186/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7426091.0000 - val_loss: 7416825.0000\n",
            "Epoch 187/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7415044.0000 - val_loss: 7405796.5000\n",
            "Epoch 188/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7404007.5000 - val_loss: 7394779.0000\n",
            "Epoch 189/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7392981.5000 - val_loss: 7383771.0000\n",
            "Epoch 190/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 7381963.5000 - val_loss: 7372773.0000\n",
            "Epoch 191/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7370958.0000 - val_loss: 7361786.0000\n",
            "Epoch 192/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7359960.5000 - val_loss: 7350809.0000\n",
            "Epoch 193/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 7348975.0000 - val_loss: 7339842.5000\n",
            "Epoch 194/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7337998.5000 - val_loss: 7328885.0000\n",
            "Epoch 195/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7327031.0000 - val_loss: 7317939.0000\n",
            "Epoch 196/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7316075.5000 - val_loss: 7307003.0000\n",
            "Epoch 197/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 7305129.5000 - val_loss: 7296076.5000\n",
            "Epoch 198/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7294192.0000 - val_loss: 7285159.0000\n",
            "Epoch 199/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7283264.5000 - val_loss: 7274253.0000\n",
            "Epoch 200/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7272348.0000 - val_loss: 7263356.0000\n",
            "Epoch 201/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7261439.5000 - val_loss: 7252469.5000\n",
            "Epoch 202/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7250541.5000 - val_loss: 7241592.0000\n",
            "Epoch 203/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 7239654.0000 - val_loss: 7230725.0000\n",
            "Epoch 204/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7228775.0000 - val_loss: 7219867.0000\n",
            "Epoch 205/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7217908.0000 - val_loss: 7209019.5000\n",
            "Epoch 206/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7207047.5000 - val_loss: 7198181.0000\n",
            "Epoch 207/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7196199.0000 - val_loss: 7187354.0000\n",
            "Epoch 208/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7185359.5000 - val_loss: 7176535.0000\n",
            "Epoch 209/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7174529.5000 - val_loss: 7165726.5000\n",
            "Epoch 210/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7163709.5000 - val_loss: 7154926.5000\n",
            "Epoch 211/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 7152899.0000 - val_loss: 7144137.0000\n",
            "Epoch 212/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7142097.0000 - val_loss: 7133356.5000\n",
            "Epoch 213/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7131304.5000 - val_loss: 7122586.0000\n",
            "Epoch 214/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7120521.5000 - val_loss: 7111825.0000\n",
            "Epoch 215/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7109749.0000 - val_loss: 7101073.5000\n",
            "Epoch 216/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7098985.5000 - val_loss: 7090331.0000\n",
            "Epoch 217/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7088231.0000 - val_loss: 7079598.5000\n",
            "Epoch 218/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7077487.0000 - val_loss: 7068875.0000\n",
            "Epoch 219/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7066752.0000 - val_loss: 7058161.0000\n",
            "Epoch 220/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7056026.0000 - val_loss: 7047456.5000\n",
            "Epoch 221/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7045309.0000 - val_loss: 7036761.0000\n",
            "Epoch 222/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 7034601.5000 - val_loss: 7026075.5000\n",
            "Epoch 223/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7023903.5000 - val_loss: 7015398.5000\n",
            "Epoch 224/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 7013214.0000 - val_loss: 7004731.5000\n",
            "Epoch 225/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 7002534.0000 - val_loss: 6994073.5000\n",
            "Epoch 226/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6991864.0000 - val_loss: 6983424.5000\n",
            "Epoch 227/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6981204.0000 - val_loss: 6972785.5000\n",
            "Epoch 228/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6970551.0000 - val_loss: 6962155.0000\n",
            "Epoch 229/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6959908.5000 - val_loss: 6951533.5000\n",
            "Epoch 230/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6949276.5000 - val_loss: 6940922.0000\n",
            "Epoch 231/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6938652.0000 - val_loss: 6930319.0000\n",
            "Epoch 232/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6928037.0000 - val_loss: 6919725.0000\n",
            "Epoch 233/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6917431.0000 - val_loss: 6909141.5000\n",
            "Epoch 234/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 6906835.0000 - val_loss: 6898566.0000\n",
            "Epoch 235/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6896247.5000 - val_loss: 6888000.0000\n",
            "Epoch 236/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6885668.0000 - val_loss: 6877442.0000\n",
            "Epoch 237/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6875099.5000 - val_loss: 6866893.5000\n",
            "Epoch 238/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6864538.5000 - val_loss: 6856354.5000\n",
            "Epoch 239/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6853988.0000 - val_loss: 6845825.5000\n",
            "Epoch 240/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6843445.0000 - val_loss: 6835304.0000\n",
            "Epoch 241/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 6832913.5000 - val_loss: 6824791.5000\n",
            "Epoch 242/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6822388.5000 - val_loss: 6814289.5000\n",
            "Epoch 243/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6811873.0000 - val_loss: 6803795.0000\n",
            "Epoch 244/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6801367.0000 - val_loss: 6793309.5000\n",
            "Epoch 245/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6790870.0000 - val_loss: 6782833.5000\n",
            "Epoch 246/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6780381.5000 - val_loss: 6772366.5000\n",
            "Epoch 247/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6769903.0000 - val_loss: 6761907.5000\n",
            "Epoch 248/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6759432.5000 - val_loss: 6751458.5000\n",
            "Epoch 249/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6748971.0000 - val_loss: 6741018.0000\n",
            "Epoch 250/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6738518.5000 - val_loss: 6730586.0000\n",
            "Epoch 251/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6728076.5000 - val_loss: 6720164.5000\n",
            "Epoch 252/500\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 6717641.5000 - val_loss: 6709749.5000\n",
            "Epoch 253/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6707216.5000 - val_loss: 6699345.0000\n",
            "Epoch 254/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6696800.0000 - val_loss: 6688949.0000\n",
            "Epoch 255/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 6686391.5000 - val_loss: 6678561.5000\n",
            "Epoch 256/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6675991.0000 - val_loss: 6668182.0000\n",
            "Epoch 257/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6665603.0000 - val_loss: 6657813.5000\n",
            "Epoch 258/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6655221.0000 - val_loss: 6647452.0000\n",
            "Epoch 259/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6644849.5000 - val_loss: 6637100.0000\n",
            "Epoch 260/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6634487.0000 - val_loss: 6626756.5000\n",
            "Epoch 261/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6624131.0000 - val_loss: 6616422.5000\n",
            "Epoch 262/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6613786.0000 - val_loss: 6606096.5000\n",
            "Epoch 263/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6603448.5000 - val_loss: 6595779.5000\n",
            "Epoch 264/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6593121.5000 - val_loss: 6585470.5000\n",
            "Epoch 265/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6582800.5000 - val_loss: 6575171.5000\n",
            "Epoch 266/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 6572490.5000 - val_loss: 6564881.0000\n",
            "Epoch 267/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6562189.5000 - val_loss: 6554598.0000\n",
            "Epoch 268/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6551896.5000 - val_loss: 6544325.0000\n",
            "Epoch 269/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6541611.5000 - val_loss: 6534060.0000\n",
            "Epoch 270/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6531336.5000 - val_loss: 6523804.0000\n",
            "Epoch 271/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 6521069.0000 - val_loss: 6513557.0000\n",
            "Epoch 272/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6510811.5000 - val_loss: 6503317.5000\n",
            "Epoch 273/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6500562.0000 - val_loss: 6493088.0000\n",
            "Epoch 274/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6490321.0000 - val_loss: 6482866.5000\n",
            "Epoch 275/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6480090.5000 - val_loss: 6472653.5000\n",
            "Epoch 276/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6469866.5000 - val_loss: 6462449.0000\n",
            "Epoch 277/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6459653.5000 - val_loss: 6452254.0000\n",
            "Epoch 278/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6449447.5000 - val_loss: 6442067.5000\n",
            "Epoch 279/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6439250.5000 - val_loss: 6431889.0000\n",
            "Epoch 280/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6429061.5000 - val_loss: 6421719.5000\n",
            "Epoch 281/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6418882.0000 - val_loss: 6411558.5000\n",
            "Epoch 282/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6408710.0000 - val_loss: 6401405.5000\n",
            "Epoch 283/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 6398550.0000 - val_loss: 6391262.0000\n",
            "Epoch 284/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6388395.0000 - val_loss: 6381127.0000\n",
            "Epoch 285/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6378251.0000 - val_loss: 6371001.0000\n",
            "Epoch 286/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6368114.0000 - val_loss: 6360883.0000\n",
            "Epoch 287/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6357986.5000 - val_loss: 6350773.5000\n",
            "Epoch 288/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6347867.5000 - val_loss: 6340672.0000\n",
            "Epoch 289/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6337757.5000 - val_loss: 6330579.5000\n",
            "Epoch 290/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6327655.0000 - val_loss: 6320495.5000\n",
            "Epoch 291/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6317562.5000 - val_loss: 6310421.0000\n",
            "Epoch 292/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6307478.0000 - val_loss: 6300354.0000\n",
            "Epoch 293/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6297402.5000 - val_loss: 6290295.5000\n",
            "Epoch 294/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6287334.5000 - val_loss: 6280245.5000\n",
            "Epoch 295/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6277276.0000 - val_loss: 6270204.5000\n",
            "Epoch 296/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6267225.5000 - val_loss: 6260172.0000\n",
            "Epoch 297/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6257185.0000 - val_loss: 6250148.0000\n",
            "Epoch 298/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6247151.5000 - val_loss: 6240132.5000\n",
            "Epoch 299/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6237128.0000 - val_loss: 6230125.5000\n",
            "Epoch 300/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6227110.5000 - val_loss: 6220127.5000\n",
            "Epoch 301/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 6217105.0000 - val_loss: 6210137.5000\n",
            "Epoch 302/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6207106.5000 - val_loss: 6200155.5000\n",
            "Epoch 303/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6197116.0000 - val_loss: 6190182.0000\n",
            "Epoch 304/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6187135.0000 - val_loss: 6180217.5000\n",
            "Epoch 305/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6177161.5000 - val_loss: 6170261.5000\n",
            "Epoch 306/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6167196.5000 - val_loss: 6160313.5000\n",
            "Epoch 307/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6157241.5000 - val_loss: 6150374.0000\n",
            "Epoch 308/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6147293.0000 - val_loss: 6140443.5000\n",
            "Epoch 309/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6137355.0000 - val_loss: 6130521.0000\n",
            "Epoch 310/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6127424.0000 - val_loss: 6120606.5000\n",
            "Epoch 311/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 6117502.0000 - val_loss: 6110701.5000\n",
            "Epoch 312/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 6107589.5000 - val_loss: 6100805.0000\n",
            "Epoch 313/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 6097685.5000 - val_loss: 6090916.5000\n",
            "Epoch 314/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 6087790.0000 - val_loss: 6081037.0000\n",
            "Epoch 315/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6077902.5000 - val_loss: 6071166.5000\n",
            "Epoch 316/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 6068024.0000 - val_loss: 6061303.5000\n",
            "Epoch 317/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6058154.0000 - val_loss: 6051450.0000\n",
            "Epoch 318/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6048293.0000 - val_loss: 6041603.5000\n",
            "Epoch 319/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 6038439.0000 - val_loss: 6031765.5000\n",
            "Epoch 320/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 6028594.0000 - val_loss: 6021936.5000\n",
            "Epoch 321/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6018759.0000 - val_loss: 6012115.5000\n",
            "Epoch 322/500\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 6008930.0000 - val_loss: 6002302.0000\n",
            "Epoch 323/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5999109.5000 - val_loss: 5992498.5000\n",
            "Epoch 324/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5989298.0000 - val_loss: 5982701.5000\n",
            "Epoch 325/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5979495.0000 - val_loss: 5972914.5000\n",
            "Epoch 326/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5969700.0000 - val_loss: 5963134.0000\n",
            "Epoch 327/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5959914.0000 - val_loss: 5953363.5000\n",
            "Epoch 328/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5950136.0000 - val_loss: 5943600.5000\n",
            "Epoch 329/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5940366.0000 - val_loss: 5933845.5000\n",
            "Epoch 330/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5930605.0000 - val_loss: 5924100.0000\n",
            "Epoch 331/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5920853.0000 - val_loss: 5914363.0000\n",
            "Epoch 332/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5911109.0000 - val_loss: 5904633.5000\n",
            "Epoch 333/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5901374.0000 - val_loss: 5894912.5000\n",
            "Epoch 334/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5891647.5000 - val_loss: 5885200.5000\n",
            "Epoch 335/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5881928.5000 - val_loss: 5875498.0000\n",
            "Epoch 336/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5872220.0000 - val_loss: 5865803.0000\n",
            "Epoch 337/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5862519.0000 - val_loss: 5856117.0000\n",
            "Epoch 338/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5852828.0000 - val_loss: 5846440.5000\n",
            "Epoch 339/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5843146.0000 - val_loss: 5836772.0000\n",
            "Epoch 340/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5833471.0000 - val_loss: 5827112.0000\n",
            "Epoch 341/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5823805.0000 - val_loss: 5817459.5000\n",
            "Epoch 342/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5814147.0000 - val_loss: 5807816.0000\n",
            "Epoch 343/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5804498.0000 - val_loss: 5798180.0000\n",
            "Epoch 344/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5794856.5000 - val_loss: 5788552.5000\n",
            "Epoch 345/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5785223.0000 - val_loss: 5778933.0000\n",
            "Epoch 346/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5775598.5000 - val_loss: 5769320.5000\n",
            "Epoch 347/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5765982.0000 - val_loss: 5759718.0000\n",
            "Epoch 348/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5756372.0000 - val_loss: 5750123.0000\n",
            "Epoch 349/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5746771.0000 - val_loss: 5740535.0000\n",
            "Epoch 350/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5737178.5000 - val_loss: 5730956.5000\n",
            "Epoch 351/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5727594.5000 - val_loss: 5721386.0000\n",
            "Epoch 352/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5718018.5000 - val_loss: 5711823.5000\n",
            "Epoch 353/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5708451.0000 - val_loss: 5702269.5000\n",
            "Epoch 354/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5698892.0000 - val_loss: 5692723.0000\n",
            "Epoch 355/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5689341.5000 - val_loss: 5683185.5000\n",
            "Epoch 356/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5679799.5000 - val_loss: 5673657.0000\n",
            "Epoch 357/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5670265.0000 - val_loss: 5664136.0000\n",
            "Epoch 358/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5660740.0000 - val_loss: 5654623.5000\n",
            "Epoch 359/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5651222.5000 - val_loss: 5645119.5000\n",
            "Epoch 360/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5641714.0000 - val_loss: 5635624.0000\n",
            "Epoch 361/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5632212.5000 - val_loss: 5626137.0000\n",
            "Epoch 362/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5622722.5000 - val_loss: 5616659.0000\n",
            "Epoch 363/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5613240.0000 - val_loss: 5607189.0000\n",
            "Epoch 364/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5603766.5000 - val_loss: 5597728.0000\n",
            "Epoch 365/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5594301.5000 - val_loss: 5588276.0000\n",
            "Epoch 366/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5584846.5000 - val_loss: 5578833.5000\n",
            "Epoch 367/500\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 5575399.5000 - val_loss: 5569399.0000\n",
            "Epoch 368/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5565961.0000 - val_loss: 5559973.0000\n",
            "Epoch 369/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5556531.0000 - val_loss: 5550555.5000\n",
            "Epoch 370/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5547109.5000 - val_loss: 5541145.5000\n",
            "Epoch 371/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5537696.0000 - val_loss: 5531744.0000\n",
            "Epoch 372/500\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 5528290.0000 - val_loss: 5522350.5000\n",
            "Epoch 373/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5518893.0000 - val_loss: 5512964.5000\n",
            "Epoch 374/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 5509503.0000 - val_loss: 5503587.5000\n",
            "Epoch 375/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5500121.5000 - val_loss: 5494218.0000\n",
            "Epoch 376/500\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 5490748.0000 - val_loss: 5484856.0000\n",
            "Epoch 377/500\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5481382.5000 - val_loss: 5475502.5000\n",
            "Epoch 378/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5472025.5000 - val_loss: 5466156.5000\n",
            "Epoch 379/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5462676.5000 - val_loss: 5456819.0000\n",
            "Epoch 380/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5453335.5000 - val_loss: 5447489.5000\n",
            "Epoch 381/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 5444002.0000 - val_loss: 5438168.0000\n",
            "Epoch 382/500\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 5434677.0000 - val_loss: 5428855.0000\n",
            "Epoch 383/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5425360.0000 - val_loss: 5419548.5000\n",
            "Epoch 384/500\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 5416050.5000 - val_loss: 5410251.0000\n",
            "Epoch 385/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5406751.0000 - val_loss: 5400962.5000\n",
            "Epoch 386/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5397458.5000 - val_loss: 5391681.5000\n",
            "Epoch 387/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 5388175.5000 - val_loss: 5382409.0000\n",
            "Epoch 388/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5378899.0000 - val_loss: 5373145.0000\n",
            "Epoch 389/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5369633.0000 - val_loss: 5363889.5000\n",
            "Epoch 390/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5360374.5000 - val_loss: 5354643.0000\n",
            "Epoch 391/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5351125.0000 - val_loss: 5345405.5000\n",
            "Epoch 392/500\n",
            "25/25 [==============================] - 1s 35ms/step - loss: 5341884.0000 - val_loss: 5336175.5000\n",
            "Epoch 393/500\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 5332651.0000 - val_loss: 5326955.0000\n",
            "Epoch 394/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 5323428.5000 - val_loss: 5317742.5000\n",
            "Epoch 395/500\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5314215.5000 - val_loss: 5308540.0000\n",
            "Epoch 396/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5305009.0000 - val_loss: 5299346.5000\n",
            "Epoch 397/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 5295813.5000 - val_loss: 5290161.5000\n",
            "Epoch 398/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 5286626.0000 - val_loss: 5280984.5000\n",
            "Epoch 399/500\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 5277447.5000 - val_loss: 5271816.5000\n",
            "Epoch 400/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5268277.0000 - val_loss: 5262655.5000\n",
            "Epoch 401/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 5259113.5000 - val_loss: 5253503.0000\n",
            "Epoch 402/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5249958.5000 - val_loss: 5244359.0000\n",
            "Epoch 403/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5240811.5000 - val_loss: 5235221.5000\n",
            "Epoch 404/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 5231672.0000 - val_loss: 5226093.0000\n",
            "Epoch 405/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 5222541.0000 - val_loss: 5216972.5000\n",
            "Epoch 406/500\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 5213418.5000 - val_loss: 5207860.0000\n",
            "Epoch 407/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5204303.5000 - val_loss: 5198755.0000\n",
            "Epoch 408/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5195196.0000 - val_loss: 5189658.0000\n",
            "Epoch 409/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 5186097.5000 - val_loss: 5180569.5000\n",
            "Epoch 410/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5177007.0000 - val_loss: 5171488.0000\n",
            "Epoch 411/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5167924.5000 - val_loss: 5162416.0000\n",
            "Epoch 412/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5158849.5000 - val_loss: 5153351.0000\n",
            "Epoch 413/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5149782.5000 - val_loss: 5144294.0000\n",
            "Epoch 414/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 5140723.5000 - val_loss: 5135245.0000\n",
            "Epoch 415/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5131673.5000 - val_loss: 5126204.0000\n",
            "Epoch 416/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5122630.0000 - val_loss: 5117171.5000\n",
            "Epoch 417/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5113595.5000 - val_loss: 5108146.0000\n",
            "Epoch 418/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5104568.0000 - val_loss: 5099129.0000\n",
            "Epoch 419/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5095549.5000 - val_loss: 5090122.0000\n",
            "Epoch 420/500\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 5086540.5000 - val_loss: 5081121.5000\n",
            "Epoch 421/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5077539.5000 - val_loss: 5072130.5000\n",
            "Epoch 422/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 5068547.5000 - val_loss: 5063148.5000\n",
            "Epoch 423/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 5059564.5000 - val_loss: 5054174.5000\n",
            "Epoch 424/500\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5050589.5000 - val_loss: 5045211.0000\n",
            "Epoch 425/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 5041624.5000 - val_loss: 5036255.5000\n",
            "Epoch 426/500\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 5032669.5000 - val_loss: 5027309.5000\n",
            "Epoch 427/500\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 5023723.0000 - val_loss: 5018374.0000\n",
            "Epoch 428/500\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 5014785.5000 - val_loss: 5009445.0000\n",
            "Epoch 429/500\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 5005855.5000 - val_loss: 5000524.5000\n",
            "Epoch 430/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 4996934.0000 - val_loss: 4991612.5000\n",
            "Epoch 431/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 4988019.5000 - val_loss: 4982707.0000\n",
            "Epoch 432/500\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 4979114.5000 - val_loss: 4973811.5000\n",
            "Epoch 433/500\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 4970216.5000 - val_loss: 4964922.5000\n",
            "Epoch 434/500\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 4961327.5000 - val_loss: 4956041.5000\n",
            "Epoch 435/500\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 4952444.5000 - val_loss: 4947168.5000\n",
            "Epoch 436/500\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 4943571.5000 - val_loss: 4938304.0000\n",
            "Epoch 437/500\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 4934706.0000 - val_loss: 4929447.0000\n",
            "Epoch 438/500\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 4925848.0000 - val_loss: 4920598.0000\n",
            "Epoch 439/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 4916998.0000 - val_loss: 4911757.5000\n",
            "Epoch 440/500\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4908157.0000 - val_loss: 4902924.5000\n",
            "Epoch 441/500\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 4899322.5000 - val_loss: 4894099.5000\n",
            "Epoch 442/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 4890496.5000 - val_loss: 4885282.5000\n",
            "Epoch 443/500\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 4881678.5000 - val_loss: 4876473.5000\n",
            "Epoch 444/500\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 4872870.0000 - val_loss: 4867672.0000\n",
            "Epoch 445/500\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4864067.5000 - val_loss: 4858879.0000\n",
            "Epoch 446/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 4855274.0000 - val_loss: 4850093.5000\n",
            "Epoch 447/500\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 4846487.5000 - val_loss: 4841316.5000\n",
            "Epoch 448/500\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4837711.0000 - val_loss: 4832547.5000\n",
            "Epoch 449/500\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 4828940.5000 - val_loss: 4823786.0000\n",
            "Epoch 450/500\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 4820178.5000 - val_loss: 4815033.0000\n",
            "Epoch 451/500\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4811425.0000 - val_loss: 4806288.0000\n",
            "Epoch 452/500\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 4802680.0000 - val_loss: 4797552.5000\n",
            "Epoch 453/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 4793943.5000 - val_loss: 4788826.0000\n",
            "Epoch 454/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 4785217.5000 - val_loss: 4780108.5000\n",
            "Epoch 455/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4776501.5000 - val_loss: 4771400.5000\n",
            "Epoch 456/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 4767794.5000 - val_loss: 4762702.5000\n",
            "Epoch 457/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4759096.5000 - val_loss: 4754013.5000\n",
            "Epoch 458/500\n",
            "25/25 [==============================] - 0s 17ms/step - loss: 4750407.0000 - val_loss: 4745332.5000\n",
            "Epoch 459/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 4741726.0000 - val_loss: 4736659.0000\n",
            "Epoch 460/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4733053.0000 - val_loss: 4727993.5000\n",
            "Epoch 461/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4724387.5000 - val_loss: 4719336.0000\n",
            "Epoch 462/500\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 4715730.0000 - val_loss: 4710687.0000\n",
            "Epoch 463/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4707080.0000 - val_loss: 4702045.5000\n",
            "Epoch 464/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4698438.5000 - val_loss: 4693412.0000\n",
            "Epoch 465/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4689805.5000 - val_loss: 4684787.0000\n",
            "Epoch 466/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 4681179.5000 - val_loss: 4676169.0000\n",
            "Epoch 467/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4672561.5000 - val_loss: 4667559.0000\n",
            "Epoch 468/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 4663952.5000 - val_loss: 4658957.5000\n",
            "Epoch 469/500\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 4655349.5000 - val_loss: 4650363.0000\n",
            "Epoch 470/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4646757.0000 - val_loss: 4641777.5000\n",
            "Epoch 471/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 4638171.0000 - val_loss: 4633199.0000\n",
            "Epoch 472/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4629593.0000 - val_loss: 4624629.5000\n",
            "Epoch 473/500\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 4621023.5000 - val_loss: 4616066.5000\n",
            "Epoch 474/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4612461.5000 - val_loss: 4607513.0000\n",
            "Epoch 475/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4603908.0000 - val_loss: 4598966.5000\n",
            "Epoch 476/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4595361.5000 - val_loss: 4590428.5000\n",
            "Epoch 477/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4586823.5000 - val_loss: 4581898.0000\n",
            "Epoch 478/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4578293.0000 - val_loss: 4573376.0000\n",
            "Epoch 479/500\n",
            "25/25 [==============================] - 0s 15ms/step - loss: 4569771.5000 - val_loss: 4564861.5000\n",
            "Epoch 480/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4561258.0000 - val_loss: 4556354.0000\n",
            "Epoch 481/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4552751.5000 - val_loss: 4547856.5000\n",
            "Epoch 482/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4544254.0000 - val_loss: 4539367.0000\n",
            "Epoch 483/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4535765.5000 - val_loss: 4530887.5000\n",
            "Epoch 484/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4527287.5000 - val_loss: 4522417.5000\n",
            "Epoch 485/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4518820.0000 - val_loss: 4513959.0000\n",
            "Epoch 486/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4510362.0000 - val_loss: 4505508.0000\n",
            "Epoch 487/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4501912.0000 - val_loss: 4497066.0000\n",
            "Epoch 488/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4493470.0000 - val_loss: 4488631.0000\n",
            "Epoch 489/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4485036.0000 - val_loss: 4480204.0000\n",
            "Epoch 490/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4476610.5000 - val_loss: 4471785.5000\n",
            "Epoch 491/500\n",
            "25/25 [==============================] - 0s 16ms/step - loss: 4468192.5000 - val_loss: 4463374.5000\n",
            "Epoch 492/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4459782.0000 - val_loss: 4454972.0000\n",
            "Epoch 493/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4451379.5000 - val_loss: 4446576.5000\n",
            "Epoch 494/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4442984.5000 - val_loss: 4438189.0000\n",
            "Epoch 495/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4434598.5000 - val_loss: 4429810.0000\n",
            "Epoch 496/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4426220.5000 - val_loss: 4421438.5000\n",
            "Epoch 497/500\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 4417849.5000 - val_loss: 4413075.0000\n",
            "Epoch 498/500\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 4409487.0000 - val_loss: 4404719.5000\n",
            "Epoch 499/500\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 4401132.5000 - val_loss: 4396371.5000\n",
            "Epoch 500/500\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 4392785.5000 - val_loss: 4388031.5000\n"
          ]
        }
      ],
      "source": [
        "c1 = tf.Variable(2.6676, name=\"c1\", trainable=True, dtype=tf.float32)\n",
        "c2 = tf.Variable(7000, name=\"c2\", trainable=True, dtype=tf.float32)\n",
        "c3 = tf.Variable(20000, name=\"c3\", trainable=True, dtype=tf.float32)\n",
        "b3 = tf.Variable(1.06, name=\"b3\", trainable=True, dtype=tf.float32)\n",
        "\n",
        "splitr = 0.8\n",
        "\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    squared_difference = tf.square(y_true[:, 0] - y_pred[:, 0])\n",
        "    #squared_difference2 = tf.square(y_true[:, 2]-y_pred[:, 2])\n",
        "    #squared_difference1 = tf.square(y_true[:, 1]-y_pred[:, 1])\n",
        "    squared_difference3 = tf.square(\n",
        "        y_pred[:, 3] + (c1 * y_pred[:, 1] + b3 * y_pred[:, 2] + c2))\n",
        "    return tf.reduce_mean(squared_difference, axis=-1) + 0.2*tf.reduce_mean(squared_difference3, axis=-1)\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(trainX.shape[1], trainX.shape[2])))\n",
        "model.add(Dense(30))\n",
        "model.compile(loss=loss_fn, optimizer='adam')\n",
        "history = model.fit(trainX[:int(splitr*trainX.shape[0])], trainy[:int(splitr*trainX.shape[0])], epochs=500, batch_size=64, validation_data=(trainX[int(splitr*trainX.shape[0]):trainX.shape[0]], trainy[int(splitr*trainX.shape[0]):trainX.shape[0]]), shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJL101rPyuoT",
        "outputId": "239ff2b1-c186-423a-d316-939dfdd7c793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ],
      "source": [
        "forecast_without_mc = forecastX\n",
        "yhat_without_mc = model.predict(forecast_without_mc) # Step Ahead Prediction\n",
        "forecast_without_mc = forecast_without_mc.reshape((forecast_without_mc.shape[0], forecast_without_mc.shape[2])) # Historical Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9dQELcJ8wbp",
        "outputId": "4dc7671b-b1a8-48d5-8744-a86f98446109"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1, 48)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forecastX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS2kyIKG1Kbr",
        "outputId": "f31b3485-8e26-452f-9298-ea8bf7e80ad1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 48)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forecast_without_mc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0u6VIzaDyuoT"
      },
      "outputs": [],
      "source": [
        "inv_yhat_without_mc = np.concatenate((forecast_without_mc, yhat_without_mc), axis=1) # Concatenation of predicted values with Historical Data\n",
        "#inv_yhat_without_mc = scaler.inverse_transform(inv_yhat_without_mc) # Transform labels back to original encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUEcw0LX07oU",
        "outputId": "cfc32397-9c37-4b43-d087-584bb31c3dcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 78)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inv_yhat_without_mc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "31OWVbSh_305"
      },
      "outputs": [],
      "source": [
        "fforecast = inv_yhat_without_mc[:,-30:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "BlpGH2FOAiRF"
      },
      "outputs": [],
      "source": [
        "final_forecast = fforecast[:,0:29:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CXkgkj_LBk_t"
      },
      "outputs": [],
      "source": [
        "# code to replace all negative value with 0\n",
        "final_forecast[final_forecast<0] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.21007511, 1.48980665, 0.35162324,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.33969641]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_set = np.array(training_set)\n",
        "test = np.array(test)\n",
        "final_forecast = np.array(final_forecast.squeeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.46182602507839965\n",
            "0.26142256036400796\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "MSE = np.square(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
        "rsme = math.sqrt(MSE)\n",
        "print(rsme)  \n",
        "MAE = np.abs(np.subtract(np.array(test),np.array(final_forecast))).mean()   \n",
        "mae = MAE\n",
        "print(mae)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
